\documentclass[10pt, a4paper]{article}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{parskip}
\usepackage{pgfplots}
\usepackage{comment}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
%\usepackage{mdframed}
%\usepackage{thmbox}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[top=105pt, bottom=75pt, left=75pt, right=75pt]{geometry}
\setlength{\headsep}{15pt}
\setlength{\footskip}{45pt}

\usepackage{xcolor}
\usepackage{lipsum}

\usepackage{ifthen}
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{cd}
\usetikzlibrary{babel}
\tikzcdset{scale cd/.style={every label/.append style={scale=#1},
    cells={nodes={scale=#1}}}}

\usepackage{adjustbox}

\graphicspath{ {./images/} }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{tcolorbox}
\tcbuselibrary{skins, breakable}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% with separate title
\xdefinecolor{thmTopColor}{RGB}{102, 102, 238}
\xdefinecolor{thmBackColor}{RGB}{245, 245, 255}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\newtheorem{thm}{Theorem}[section]

\newenvironment{thmbox}[1]{%
  \tcolorbox[%
  empty,
  parbox=false,
  noparskip,
  enhanced,
  breakable,
  sharp corners,
  boxrule=-1pt,
  left=2ex,
  right=0ex,
  top=0ex,
  boxsep=1ex,
  before skip=2.5ex plus 2pt,
  after skip=2.5ex plus 2pt,
  colback=thmBackColor,
  colframe=white,
  coltitle=black,
  colbacktitle=thmBackColor,
  fonttitle=\bfseries,
  title=#1,
  titlerule=1pt,
  titlerule style=thmTopColor,
  overlay unbroken and last={%
    \draw[color=thmTopColor, line width=1.25pt]
    ($(frame.north west)+(.5em, -4.1ex)$)
    -- ($(frame.south west)+(.5em, 1ex)$) -- ++(2em, 0);
  }]
}{\endtcolorbox}

\newenvironment{theorem}[1][]{% before
  \refstepcounter{thm}%
  \ifthenelse{\equal{#1}{}}{%
    \begin{thmbox}{Theorem \thethm.}\itshape\hspace{-.75ex}%
  }{%
    \begin{thmbox}{Theorem \thethm%
        \hspace{.75ex}(\textnormal{#1}).}\itshape\hspace{-.75ex}
    }}
  {\end{thmbox}
}

{\theoremstyle{plain}
\newtheorem{corollary}[thm]{Corollary}
\newtheorem{proposition}[thm]{Proposition}

}

{\theoremstyle{definition}
\newtheorem{defi}[thm]{Definition}
\newtheorem{aksiom}[thm]{Aksiom}
}

\newenvironment{noticeB}{%
  \tcolorbox[%
  notitle,
  empty,
  enhanced,  % delete the edge of the bottom page for a broken box
  breakable,
  coltext=black,
  colback=white, 
  fontupper=\rmfamily,
  %parbox=false,
  noparskip,
  sharp corners,
  boxrule=-1pt,  % width of the box' edges
  frame hidden,
  left=7pt,  % inner space from text to the left edge
  right=7pt,
  top=5pt,
  bottom=5pt,
  % boxsep=0pt,
  before skip=2.5ex plus 2pt,
  after skip=2.5ex plus 2pt,
  borderline west = {1.5pt}{-0.1pt}{blue!30!black}, % second argument = offset
  overlay unbroken and last={%
    \draw[color=black, line width=1.25pt]
    ($(frame.south west)+(1.pt, -0.1pt)$) -- ++(2em, 0);
  }
  ]}
{\endtcolorbox}

\newenvironment{definition}{\begin{noticeB}\begin{defi}}{%
    \end{defi}\end{noticeB}}

{\theoremstyle{remark}
\newtheorem*{remark}{Remark}
}


\newtheorem{example}[thm]{Example}
\tcolorboxenvironment{example}{%
  enhanced jigsaw,
  boxrule=-1pt,
  colframe=gray!15,
  %borderline west={2pt}{0pt}{black},  % second argument is the offset
  interior hidden,
  sharp corners,
  breakable,
  before skip=2.5ex plus 2pt,
  after skip=2.5ex plus 2pt
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newtheorem{lemma}[thm]{Lemma}
\tcolorboxenvironment{lemma}{%
  enhanced jigsaw,
  boxrule=-1pt,
  sharp corners,
  colframe=white,
  borderline west={2pt}{0pt}{orange},  % second argument is the offset
  interior hidden,
  breakable,
  before skip=2.5ex plus 2pt,
  after skip=2.5ex plus 2pt
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newenvironment{noticeC}{%
  \tcolorbox[%
  notitle,
  empty,
  enhanced,  % delete the edge of the bottom page for a broken box
  breakable,
  coltext=black, 
  fontupper=\rmfamily,
  %parbox=false,
  noparskip,
  sharp corners,
  boxrule=-1pt,  % width of the box' edges
  frame hidden,
  left=7pt,  % inner space from text to the left edge
  right=7pt,
  top=5pt,
  bottom=5pt,
  %boxsep=0pt,
  before skip=2.5ex plus 2pt,
  after skip=2.5ex plus 2pt,
  %borderline west = {1.5pt}{-0.1pt}{gray}, % second argument = offset
  overlay unbroken and last={%
    %\draw[color=gray, line width=1.25pt]
    %($(frame.west)$);
    %\draw[color=gray, line width=1.25pt]
    %($(frame.east)$);
  },
  ]}
{\endtcolorbox}

\newenvironment{myproof}%
  {\begin{noticeC}\begin{proof}}%
  {\end{proof}\end{noticeC}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\makeatletter
\newlength\xvec@height%
\newlength\xvec@depth%
\newlength\xvec@width%
\newcommand{\xvec}[2][]{%
  \ifmmode%
    \settoheight{\xvec@height}{$#2$}%
    \settodepth{\xvec@depth}{$#2$}%
    \settowidth{\xvec@width}{$#2$}%
  \else%
    \settoheight{\xvec@height}{#2}%
    \settodepth{\xvec@depth}{#2}%
    \settowidth{\xvec@width}{#2}%
  \fi%
  \def\xvec@arg{#1}%
  \def\xvec@dd{:}%
  \def\xvec@d{.}%
  \raisebox{.2ex}{\raisebox{\xvec@height}{\rlap{%
    \kern.05em%  (Because left edge of drawing is at .05em)
    \begin{tikzpicture}[scale=1]
    \pgfsetroundcap
    \draw (.05em,0)--(\xvec@width-.05em,0);
    \draw (\xvec@width-.05em,0)--(\xvec@width-.15em, .075em);
    \draw (\xvec@width-.05em,0)--(\xvec@width-.15em,-.075em);
    \ifx\xvec@arg\xvec@d%
      \fill(\xvec@width*.45,.5ex) circle (.5pt);%
    \else\ifx\xvec@arg\xvec@dd%
      \fill(\xvec@width*.30,.5ex) circle (.5pt);%
      \fill(\xvec@width*.65,.5ex) circle (.5pt);%
    \fi\fi%
    \end{tikzpicture}%
  }}}%
  #2%
}
\makeatother

% --- Override \vec with an invocation of \xvec.
\let\stdvec\vec
\renewcommand{\vec}[1]{\xvec[]{#1}}
% --- Define \dvec and \ddvec for dotted and double-dotted vectors.
\newcommand{\dvec}[1]{\xvec[.]{#1}}
\newcommand{\ddvec}[1]{\xvec[:]{#1}}
\newcommand{\stcomp}[1]{{#1}^{\mathsf{c}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\N}{\mathbb {N}}
\newcommand{\Z}{\mathbb {Z}}
\newcommand{\Q}{\mathbb {Q}}
\newcommand{\R}{\mathbb {R}}
\newcommand{\C}{\mathbb {C}}
\newcommand{\F}{\mathbb {F}}
\newcommand{\Ha}{\mathbb {H}}
\newcommand{\zap}[1]{(#1_n)_{n=1} ^{\infty}}
\newcommand{\podzap}[1]{(#1_{n_j})_{n=1 ^{\infty}}}
\newcommand{\limzap}[1]{\lim_{n \to \infty} {#1}}
\newcommand{\limf}[3]{\lim_{#1 \to #2} {#3}}
\newcommand{\rlimf}[3]{\lim_{#1 \downarrow #2} {#3}}
\newcommand{\llimf}[3]{\lim_{#1 \uparrow #2} {#3}}
\newcommand{\quot}[2]{{\raisebox{0em}{$#1$}\left/\raisebox{0em}{$#2$}\right.}}
\newcommand{\gen}[1]{\left\langle #1 \right\rangle}
\newcommand{\Mod}[1]{\ (\mathrm{mod}\ #1)}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\rang}{rang}
\newcommand{\isom}{\stackrel{\sim}{=}}
\DeclareMathOperator{\sgn}{sgn}
\newcommand{\gal}[1]{\mathrm{Gal}\, {\left(#1\right)}}
\DeclareMathOperator{\chara}{char}
\DeclareMathOperator{\ob}{Ob}
\DeclareMathOperator{\ext}{ext}
\DeclareMathOperator{\co}{co}
\DeclareMathOperator{\real}{Re}
\DeclareMathOperator{\imag}{Im}
\DeclareMathOperator{\sa}{sa}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\trace}{Tr}
\DeclareMathOperator{\cl}{cl}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\linspan}{span}
\DeclareMathOperator{\bh}{\mathcal{B} (\mathcal{H})}
\DeclareMathOperator{\rad}{rad}
\DeclareMathOperator{\inte}{Int}


\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace\hspace{0pt}}m{#1}}

\setlength{\parskip}{1em}

\begin{document}

\title{FUNCTIONAL ANALYSIS - NOTES}
\author{Gal Anton Gor≈°e}
\date{}
\maketitle

\section{Convexity}

\subsection{Locally convex spaces}

Let $\F \in \{\R, \C\}$ be a field.

\begin{definition}
    A topological vector space (TVS) is a $\F$-vector space that is also a topological space
    and the two structures are compatible. This means that the usual operations on vector spaces
    $$V \times V \to v,\ (x, y)\mapsto x + y,\qquad \F \times V \to V,\ (\lambda, x)\mapsto \lambda x$$
    are continuous maps.
\end{definition}

\begin{example}
    Normed spaces are TVS.
\end{example}

\begin{definition}
    Let $V$ be a $\F$-space. Map $p: V \to \R$ is a seminorm if:
    \begin{enumerate}
        \item $p(x) \geq 0,\ \forall x \in V$ (positivity);
        \item $p(\lambda x) = |\lambda| p(x),\ \forall x \in V,\ \forall \lambda \in \F$ (positive homogeneity);
        \item $p(x + y)\leq p(x) + q(x),\ \forall x, y \in \F$ (triangle inequality).
    \end{enumerate}
    A seminorm is therefore almost a norm, except that it's not necessarily positively definite.
\end{definition}

Let $V$ be a $\F$-vector space and $\mathcal{P}$ a family of seminorms in $V$.
Let $\mathcal{T}$ be the topology in $V$ with the following subbasis:
$$U(x_0, p, \varepsilon) = \{x \in V\ |\ p(x - x_0) < \varepsilon\};\ x_0 \in V,\ p \in \mathcal{P},\ \varepsilon > 0.$$
Basis of $\mathcal{T}$ are finite intersections of such sets.
The set $U \subseteq V$ is open iff for every $x_0 \in U$ there exist seminorms $p_1, \dots, p_n \in \mathcal{P}$
and $\varepsilon_1, \dots, \varepsilon_n > 0$ such that 
$$U \supset \bigcap_{j = 1} ^n U(x_0, p_j, \varepsilon_j).$$
The space $(V, \mathcal{T})$ is then a TVS. If $\mathcal{P}$ is a singleton 
and its element is a norm, then $(V, \mathcal{T})$ is a normed space.

\begin{definition}
    A TVS $X$ is a locally-convex space (LCS) if its topology is generated by 
    a family of seminorms $\mathcal{P}$ satisfying 
    $$\bigcap_{p \in \mathcal{P}} \{x \in X\ |\ p(x) = 0\} = \{0\}.$$
\end{definition}

Equivalently, for every $x \in X \setminus \{0\}$ there exists a seminorm $p \in \mathcal{P}$ such that $p(x) \neq 0$.

\begin{corollary}
  Let $X$ be a space with a topology generated by a family of seminorms. Then $X$ is a LCS iff it is Hausdorff.
\end{corollary}

\begin{myproof}
    Start with $(\Rightarrow)$. Let $x, y \in X$ be two distinct points. There exists a seminorm $p$
    such that $p(x - y) = b \neq 0$. Define the sets 
    $$V = U\left(x, p, \frac{b}{2}\right),\quad W = U\left(y, p, \frac{b}{2}\right).$$
    By triangle inequality property of a seminorm, $V$ and $W$ separate the points $x, y$.
    Now the converse $(\Leftarrow)$. Choose a point $X \ni x \neq 0$. Then there exist the open sets $0 \in V, x \in W$
    that separate $0$ from $x$. There exists a basis set $\bigcap_{j = 1} ^n U(0, p_j, \varepsilon_j) \subseteq V$,
    so $x \notin U(0, p_j, \varepsilon_j)$ for some index $j$. As a result, $p_j (x - 0) = p_j(x) \geq \varepsilon > 0$.
\end{myproof}

LCS generally aren't first-countable, so we need to go beyond the usual sequences.

\begin{definition}
    Partially ordered set $(I, \leq)$ is upwards-directed if 
    $$\forall i', i'' \in I:\ \exists i \in I:\ i \geq i', i \geq i''.$$
\end{definition}

\begin{example}
    \begin{enumerate}
        \item Every linearly ordered set is upwards-directed.
        \item Let $(X, \mathcal{T})$ be a topological space and $x_0 \in X$.
        Define a family of sets 
        $$\mathcal{U} = \{U^{\textrm{open}} \subseteq X\ |\ x_0 \in U\}$$
        and a relation $U \geq V \Leftrightarrow U \subseteq V$. Then $(\mathcal{U}, \leq)$ is an upwards-directed set.
        \item Let $S$ be a set and $\mathcal{F}$ a family of all finite subsets of $S$. Define $F_1 \geq F_2$ in $\mathcal{F}$
        if $F_1 \supseteq F_2$. Then $(\mathcal{F}, \leq)$ is again an upwards-directed set.
    \end{enumerate}
\end{example}

\begin{definition}
    A generalized sequence (net) is $((I, \leq), x)$, where $(I, \leq)$
    is upwards-directed and $x: I \to X$ is a function. We usually write $(x_i)_{i \in I}$ or $(x(i))_{i \in I}$.
\end{definition}

\begin{example}
    \begin{enumerate}
        \item Every sequence is a net.
        \item Let $(X, \mathcal{T})$ be a topological space, $x_0 \in X$ and $\mathcal{U}$ a collection of all open sets which contain $x_0$ (see the previous example).
        For each $U \in \mathcal{U}$ pick a $x_U \in U$. Then $(x_U)_{U \in \mathcal{U}}$ is a net.
    \end{enumerate}
\end{example}

\begin{definition}
    Let $X$ be a topological space. A net $(x_i)_{i \in I}$ converges to an $x \in X$
    if
    $$\forall U^{\textrm{open}} \subseteq X,\ x \in U:\ \exists i_0 \in I:\ \forall i \geq i_0:\ x_i \in U.$$
    We write $\lim_{i \in I} x_i = x$ or alternatively $x_i \xrightarrow[i \in I]{} x$.
    A point $x \in X$ is called a cluster point of a net $(x_i)_{i \in I}$ if 
    $$\forall U^{\textrm{open}} \subseteq X,\ x \in U:\ \forall i_0 \in I:\ \exists i \geq i_0:\ x_i \in U.$$
\end{definition}

\begin{example}
        Take a net $(x_U)_{U \in \mathcal{U}}$ from the previous example. It follows from the definition
        that $x_U \xrightarrow[U \in \mathcal{U}]{} x_0$.
\end{example}

\begin{proposition}\label{prop:1}
    \begin{enumerate}
        \item Let $X$ be a topological space and $A \subseteq X$. Then $x \in \overline{A}$ iff there exists a net $(a_i)_{i \in I}$ in $A$ such that $a_i \to x$.
        \item Let $X, Y$ be topological spaces and $f: X \to Y$. Then $f$ is continuous in $x_0 \in X$ iff $f(x_i) \to f(x_0)$ for every net $(x_i)_{i \in I}$ that converges to $x_0$.
    \end{enumerate}
\end{proposition}

\begin{myproof}
  \begin{enumerate}
    \item We begin with an implication to the left $(\Leftarrow)$.
    Take any $U^{\textrm{open}} \subseteq X$ such that $x \in U$. Since $a_i \to x$, there exists an index $i_0 \in I$,
    such that for every $i \geq i_0$ we have $a_i \in U$. Hence $a_i \in A \cap U \neq \emptyset$ and $x \in \overline{A}$.
    The converse is similar $(\Rightarrow)$. Define $\mathcal{U} = \{U^{\textrm{open}} \subseteq X\ |\ x \in U\}$.
    Since $x \in \overline{A}$, for each $U \in \mathcal{U}$, we have $A \cap U \neq \emptyset$.
    Pick $a_U \in A \cap U$. Then the net $(a_U)_{U \in \mathcal{U}}$ in $A$ converges to $x$.
    \item Start with the implication $(\Rightarrow)$. Let $f$ be a continuous function and let $(x_i)_{i \in I}$ converge to $x_0$.
    Let $f(x_0) \in U^{\textrm{open}} \subseteq Y$. Then $x_0 \in f^{-1} (U) ^{\textrm{open}} \subseteq X$, which means there exists an $i_0 \in \N$ 
    such that for every $i \geq i_0$, $x_i \in f^{-1} (U)$. But that implies that for every $i \geq i_0$, $f(x_i) \in U$, which is what we wanted.
    Now we prove the converse $(\Leftarrow)$. Let's say that for every net $(x_i)_{i \in I}$ that converges to $x_0$, we have $f(x_i) \xrightarrow{i \in I} f(x_0)$.
    So for every set $A \subseteq X$ we have $f(\overline{A}) \subseteq \overline{f(A)}$ (using the first item),
    which proves that $f$ is continuous. \qedhere
  \end{enumerate}
\end{myproof}

\begin{proposition}
    \begin{itemize}
        \item[(a)] A net $(x_i)_{i \in I}$ in a LCS converges to $x_0$ iff a net $(p(x_i - x_0))_{i \in I}$ converges to $0$ for all $p \in \mathcal{P}$.
        \item[(b)] The topology in a LCS $X$ is the coarsest (smallest) topology in which all the maps 
        $x \mapsto p(x - x_0)$ are continuous for every $x_0 \in X$ and $p \in \mathcal{P}$.
    \end{itemize}
\end{proposition}

\begin{myproof}
    \begin{itemize}
      \item[(a)] Start with the right implication $(\Rightarrow)$. Take any $p \in \mathcal{P}$.
      If we take $U = U(x_0, p, \varepsilon)$ in the definition of a limit of a net, we get 
      $$\forall \varepsilon > 0:\ \exists i_0 \in I:\ \forall i \geq i_0:\ p(x_i - x_0) \in (-\varepsilon, \varepsilon).$$
      This proves our claim. Now with the opposite direction $(\Leftarrow)$. For every $p \in \varepsilon$ and 
      $\varepsilon_p > 0$ there exists an $i_p$ such that for every $i \geq i_p$, $x_i \in U(x_0, p, \varepsilon_p)$.
      Now let $U$ be an arbitrary basis set that includes the point $x_0$. That means $U$ is the finite intersection of the sets 
      $U(x_0, p, \varepsilon_p)$. Now let $i_0$ be the greater than all indices $i_p$. By our assumption, 
      for every $i \geq i_0$ we have $x_i \in U$.
      \item[(b)] Pick any point $x_0 \in X$ and a seminorm $p \in \mathcal{P}$. Denote $$f_{x_0, p}: X \to \R,\quad f_{x_0, p}(x) = p(x - x_0).$$
      We essentially have to prove that the sets
      $$f_{x_0, p}^{-1} (V),\ V^{\textrm{open}} \subseteq \R,\ x_0 \in X,\ p \in \mathcal{P}$$
      generate a subbasis for the seminorm topology of a LCS space.
      Since $f_{p, x_0}$ are continuous functions (by the first point and proposition \ref{prop:1}),
      these are all open sets in the seminorm topology. But on the other hand, all subbasis sets $U(x_0, p, \varepsilon)$
      of the seminorm topology are of this type, so the above subbasis generates the seminorm topology, thus concluding our proof. \qedhere
    \end{itemize}
\end{myproof}

\begin{example}
    Let $X$ be a topological space.
        For every $K^\textrm{compact} \subseteq X$ we define a seminorm 
        $$p_K: C (X) \to \R,\quad f \mapsto \sup_{x \in K} |f(x)|.$$
        We endow $C (X)$ with the topology induced by the family of seminorms $\{p_K\ |\ K^{\textrm{compact}} \subseteq X\}$. 
        It's trivial to see that $C(X)$ is then a LCS. Moreover, we notice that the induced seminorm topology
        coincides with the topology of compact convergence on $X$. In the future, we will require $X$ to be locally compact Hausdorff (this implies complete regularity)
        so that $C(X)$ has nice properties.
        There are examples of not completely regular spaces $X$ such that the only elements of $C(X)$ are constant maps.
\end{example}

\begin{example}
        Let $D^{\textrm{open}} \subseteq \C$ and $\mathcal{H} (D)$ the set of all holomorphic functions on $D$.
        As in the previous point, we define $\mathcal{P} = \{p_K\ |\ K^{\textrm{compact}} \subseteq D\}$.
        This endows $\mathcal{H}(D)$ with a topology and makes $\mathcal{H}(D)$ into a LCS.
        Convergence in this topology concides with the uniform convergence on compacts in $D$.            
\end{example} 
        
\begin{example}
    Let $X$ be a normed space and let $X^*$ be its dual. For every $f \in X^*$ we define a seminorm 
        $$p_f: X \to \R,\quad x \mapsto |f(x)|.$$
        We claim that $\mathcal{P} = \{p_f\ |\ f \in X^*\}$ is a family of seminorms that induces a topology on $X$ which makes $X$ a LCS.  
        Indeed, for any $x \in X \setminus \{0\}$ define a nonzero linear functional $f: \linspan (x) \to \F$ and extend it to $F: X \to \F$ using Hahn--Banach.
        Then $p_F (x) \neq 0$.
        The induced topology is the weak topology on $X$. We denote it $\sigma(X, X^*)$. A net $(x_i)_{i \in I}$ converges to $x_0 \in X$ with regards to the weak topology
        iff $p_f (x_i - x_0) \to 0,\forall f \in X^*$ which is then equivalent to $f(x_i) \to f(x_0),\ \forall f \in X^*.$
        We use the notation $x_i \xrightarrow{*} x_0$.
\end{example}

\begin{example}
  Let $X = \R^n$. Then $X^* = \R^n$ and every linear functional $f$ is of the form 
  $f(x) = \langle x, y \rangle$ for some $y \in X$ (Riesz' representation theorem). The subbasis sets are
  $$U(0, p_y, \varepsilon) = \{x \in \R^n\ |\ |\langle x, y\rangle| < \varepsilon\}.$$
  Weak topology in this case coincides with Euclidean topology.
\end{example} 

\begin{example}
    Let $X$ be a normed space. To a $x \in X$ we assign a seminorm $$p_x: X^* \to \R,\quad f \mapsto |f(x)|.$$
    The family $\{p_x\ |\ x \in X\}$ defines a topology in $X^*$ in which $X^*$ becomes a LCS.
    This topology is called weak-* topology and is denoted by $\sigma (X^*, X)$.
    We can easily check that $f_i \xrightarrow{w^*} f$ iff $f_i (x) \to f(x)$ for all $x \in X$.
    We can compare weak-* topology on $X^*$ with its weak topology.
    By Hahn-Banach, the map $$\iota: X \hookrightarrow X^{**},\quad x \mapsto (f \mapsto f(x))$$
    is an isometry (see the argument below), which implies it is injective. This means that every seminorm in the weak-* topology is also 
    a seminorm in a weak topology on $X^*$, so the weak topology is finer (stronger) than the weak-* topology on $X^*$.
\end{example}

\begin{remark}
    Weak and weak-* topology can be defined even if $X$ is merely a LCS.
    In that case, $X^*$ is of course defined as the space of continuous linear functionals on $X$.
\end{remark}

\subsection{Banach-Alaoglu theorem}

\begin{theorem}[Banach-Alaoglu]
    Let $X$ be a normed space. Then the closed unit ball in $X^*$ (denoted by $(X^*)_1$) is compact in the weak-* topology in $X^*$.
\end{theorem}

\begin{myproof}
    To $x \in X$ we assign $D_x = \{z \in \F\ |\ |z| \leq \| x\|\}$
    and endow $D_x$ with the Euclidean topology. Then $D_x$ is clearly compact.
    The set $P = \prod_{x \in X} D_x$ is compact with regards to the product topology (Tychonoff theorem).
    Now we construct a map 
    $$\Phi: (X^*)_1 \to P,\quad f \mapsto (f(x))_{x \in X} \in P.$$
    Clearly, $\Phi$ is well-defined and injective. We start by proving that $\Phi$ is continuous.
    Let $(f_i)_{i \in I}$ be a net in $(X^*)_1$ converges to $f \in X^*$
    in a weak-* topology. Then $f_i(x) \to f(x)$ for each $x \in X$.
    By the definition of the product topology in $P$, this means that $\Phi(f_i) \mapsto \Phi(f)$ in $P$.
    Hence $\Phi$ is continuous. Since $\Phi$ is injective, it induces an inverse map 
    $$\Phi^{-1}: \im (\Phi) \to (X^*)_1$$
    that is also continuous (we read the previous argument backwards).
    Finally, we prove that $\im(\Phi)$ is closed in $P$. Suppose that $(\Phi(f_i))_{i \in I}$ converges to 
    $p = (p_x)_{x \in X} \in P$. By definition of product topology, this means that $f_i (x) \to p_x$
    for all $x \in X$. Define $$f: X \to \F,\quad x \mapsto p_x.$$
    Then $f$ is linear and $f \in (X^*)_1$. Thus $p = \Phi(f) \in \im (\Phi)$.
    This in turn implies that $(\im \Phi)^{\textrm{closed}} \subseteq P^{\textrm{compact}}$.
    But we know that $(X^*)_1 \cong \im (\Phi)$, which implies that $(X^*)_1$ is also compact.
\end{myproof}

\begin{corollary}
    Every Banach space $X$ is isometrically isomorphic to a closed subspace 
    of $C (K)$ for some compact $T_2$ space $K$.
\end{corollary}

\begin{myproof}
    Denote $K = (X^*)_1$ with weak-* topology. By the Banach-Alaoglu, $K$ is compact and $T_2$.
    We now define a map $$\Delta: X \to C(K),\quad x \mapsto (f \mapsto f(x)).$$
    First, we prove that $\Delta$ is isometric. By Hahn-Banach, for every $x \in X \setminus\{0\}$ there exists an $f \in X^*$
    such that $\|f\| = 1$ and $f(x) = \|x\|$. Then we have
    \begin{equation*}
        \| \Delta (x)\|_{\infty} = \sup_{g \in K} |g(x)| = \|x\|.
    \end{equation*} 
    Since $\Delta$ is an isometry, its image is complete and thus closed in $C(K)$.
    Obviously $\Delta$ is a linear map, so we are done.
\end{myproof}

\subsection{Minkowski gauge}

\begin{definition}
  Let $X$ be a $\F$-vector space. A set $A \subseteq X$ is 
  \begin{itemize}
    \item balanced if:
    $$\forall x \in A:\ \forall \alpha \in \F,\ |\alpha| \leq 1:\ \alpha x \in A.$$
    \item absorbing if:
    $$\forall x \in X:\ \exists \varepsilon > 0:\ \forall t \in (0, \varepsilon):\ tx \in A.$$
    \item absorbing in $a \in A$ if $A - a = \{x - a\ |\ x \in A\}$ is absorbing.
  \end{itemize}
\end{definition}

\begin{example}
  Let $X$ be a vector space and $p$ a seminorm in $X$. Then 
  $$V = \{x \in X\ |\ p(x) < 1\}$$
  is convex, balanced, absorbing in each of its points.
\end{example}

\begin{theorem}
  Let $X$ be a vector space and $V \subseteq X$ convex, balanced and absorbing in each of its points.
  Then there exists a unique seminorm $p \in X$ such that 
  $$V = \{x \in X\ |\ p(x) < 1\}.$$
\end{theorem}

\begin{myproof}
  To $V$ we associate a Minkowski gauge:
  $$p(x) = \inf \{t \geq 0\ |\ x \in t \cdot V\},$$
  where $t \cdot V = \{t \cdot v\ |\ v \in V\}$.
  First we prove that $p$ is well defined.
  Since $V$ is absorbing, we have $X = \bigcup_{n \in \N} n \cdot V$,
  so for every $x \in X$ the set $\{t \geq 0\ |\ x \in t \cdot V\}$
  is nonempty. It's also clear to see that $p(0) = 0$.
  Next we check for homogeneity. Suppose $\alpha \neq 0$.
  Then 
  \begin{align*}
    p(\alpha x) &= \inf \{t \geq 0\ |\ \alpha x \in t\cdot V\}\\
    &= \inf \left\lbrace t \geq 0\ |\ x \in \frac{t}{\alpha}\cdot V \right\rbrace\\
    &= \inf \left\lbrace t \geq 0\ |\ x \in \frac{t}{|\alpha|}\cdot V \right\rbrace\\
    &= \inf |\alpha| \left\lbrace \frac{t}{|\alpha|} \geq 0\ |\ x \in \frac{t}{|\alpha|}\cdot V \right\rbrace\\
    &= |\alpha| p(x).
  \end{align*}
  Now we do the same for triangle inequality:
  let $\alpha, \beta \geq 0$ so that $\alpha + \beta > 0$.
  Let $a, b \in V$. Then 
  $$\alpha a + \beta b = (\alpha + \beta) \left(\frac{\alpha}{\alpha + \beta} a + \frac{\beta}{\alpha + \beta} b\right) \in (\alpha + \beta) \cdot V.$$
  This means that $\alpha \cdot V + \beta \cdot V \subseteq (\alpha + \beta) \cdot V$.
  Now let $x, y \in X$ and $p(x) = \alpha, p(y) = \beta$.
  Take $\delta > 0$. Then $x \in (\alpha + \delta) \cdot V, y \in (\beta + \delta) \cdot V$.
  Then $$x + y \in (\alpha + \delta) \cdot V + (\beta + \delta) \cdot V \subseteq (\alpha + \beta + 2 \delta) \cdot V$$
  and by definition $p(x + y) \leq \alpha + \beta + 2 \delta$.
  Since $\delta > 0$ was arbitrary, we have $p(x + y) \leq \alpha + \beta = p(x) + p(y)$.
  Now that we proved that $p$ is a seminorm, we can show that 
  $$V = \{x \in X\ |\ p(x) < 1\}.$$
  The right inclusion $(\supseteq)$ is easy: if $p(x) < 1$, then $x \in (p(x) + \varepsilon) \cdot V$
  for all $\varepsilon > 0$. By choosing $\varepsilon = 1 - p(x) > 0$, we get $x \in V$.
  Now we prove the other inclusion $(\subseteq)$. Let $x \in V$.
  Since $V$ is absorbing in $x$, there exists an $\varepsilon > 0$ such that 
  $y = x + tx \in V$ for all $t \in (0, \varepsilon)$. This means that $x = \frac{1}{t + 1} y$, where $y \in V$.
  This implies that 
  $$p(x) = \frac{1}{t + 1} p(y) \leq \frac{1}{1 + t} \leq 1,$$
  which proves the equality. Lastly, we prove the $p$ is unique.
  Suppose there is some other seminorm $q$ such that 
  $$\{x \in X\ |\ p(x) < 1\} = \{x \in X\ |\ q(x) < 1\}.$$
  Suppose $p \neq q$. WLOG there exists an $x \neq 0$ such that $p(x) > q(x)$.
  By homogeneity, we can assume that $p(x) = 1 > q(x)$, contradicting our assumption.
\end{myproof}

\begin{remark}
  If $X$ is a TVS and $V$ is an open subset, then $V$ is absorbing at each of its points.
\end{remark}

\begin{corollary}
  Let $X$ be a TVS and $\mathcal{U}$ a collection of all open convex balanced subsets of $X$.
  Then $X$ is locally convex iff $\mathcal{U}$ is a basis for the neighborhood system at $0$.
\end{corollary}

\subsection{Applications of Hahn-Banach}

Recall: if $X$ is a $\R$-vector space then $p: X \to \R$
is a sublinear functional if $$p(x + y) \leq p(x) + p(y),\ \forall x, y \in X$$ and $$p(\alpha x) = \alpha x,\ \forall x \in X,\ \alpha > 0.$$

\begin{theorem}[Hahn-Banach theorem]
  \begin{itemize}
    \item[$\R$:] Suppose $X$ is a $\R$-vector space and $p: X \to \R$ is a sublinear functional.
    Given a linear functional $f$ on $Y \leq X$ such that $f(y) \leq p(y)$ for every $y \in Y$,
    $f$ extends to a linear functional $F: X \to \R$ such that $F(x) \leq p(x)$ for every $x \in X$.
    \item[$\C$:] Suppose $X$ is a $\C$-vector space and $p: X \to \R$ is a seminorm.
    Given a linear functional $f$ on $Y \leq X$ such that $|f(y)| \leq p(y)$ for every $y \in Y$,
    $f$ extends to a linear functional $F: X \to \R$ such that $|F(x)| \leq p(x)$ for every $x \in X$.
  \end{itemize}
\end{theorem}

\begin{corollary}[The extension theorem]
  Let $X$ be a normed space, $f \in X^*$ and $Y \leq X$.
  Then there exists an $F \in X^*$ such that $F\big|_Y = f$ and $\|F\| = \| f\|$.
\end{corollary}

\begin{corollary}[The separation theorem]
  Suppose $X$ is a LCS and $A, B \subseteq X$ are disjoint closed convex sets.
  If $B$ is compact then there exists an $f \in X^*$ that seperates $A$ from $B$:
  $$\exists \alpha, \beta \in \R:\ \forall a, b \in B:\ \real f(a) \leq \alpha < \beta \leq \real f(b).$$
\end{corollary}

\begin{theorem}
  Let $X$ be a LCS and $A \subseteq X$ convex. Then $\overline{A} = \overline{A}^{\textrm{weak}}$.
\end{theorem}

\begin{myproof}
  Since the weak topology is weaker than the original topology, we have $\overline{A} \subseteq \overline{A}^{\textrm{weak}}$.
  Let $x \notin \overline{A}$.
  We now seperate $\overline{A}$ and $\{x\}$: there exists $f \in X^*$
  so that there exist $\alpha, \beta \in \R$ such that we have 
  $$\real f(a) \leq \alpha < \beta \leq \real f(x)$$
  for $a \in \overline{A}$.
  This means that 
  $$\overline{A} \subseteq \{y \in X\ |\ \real f(y) \leq \alpha\} = (\real f)^{-1} (-\infty, \alpha] = C.$$
  Since $C$ is closed in weak topology, it follows from $A \subseteq C$ that $\overline{A}^{\mathrm{weak}} \subseteq \overline{C}^{\mathrm{weak}} = C.$ 
  Since $x \notin C$, we have $x \notin \overline{A}^{\mathrm{weak}}$.
\end{myproof}

\begin{corollary}
  A convex set in a LCS is closed iff it is weakly closed.
\end{corollary}

\begin{proposition}
  Let $X$ be a TVS and $f: X \to \F$ a linear functional. The following is equivalent:
  \begin{enumerate}
    \item $f$ is continuous;
    \item $f$ is continuous in $0$;
    \item $f$ is continuous in some point;
    \item $\ker f$ is closed;
    \item $x \mapsto |f(x)|$ is a seminorm.
  \end{enumerate}
  If $X$ is a LCS, then these are also equivalent to 
  \begin{enumerate}
    \setcounter{enumi}{5}
    \item $\exists \alpha_1, \dots, \alpha_n \in \R_{> 0}$ and $\exists p_1, \dots, p_n \in \mathcal{P}$ such that 
    $$|f(x)| \leq \sum_{k = 1} ^n \alpha_k p_k (x),\ \forall x \in X.$$
  \end{enumerate}
\end{proposition}

\begin{myproof}
  Equivalence of the first five statements is obvious.
  Assume that $X$ is a LCS. We prove the equivalence of (2) and (6).
  We start with $(6) \Rightarrow (2)$. Let $(x_i)_{i \in I}$ be a net in $X$ that converges to $0$.
  Then we have 
  $$0 \leq |f(x_i)| \leq \sum_{k = 1} ^n \alpha_k p_k(x_i) \xrightarrow[i \in I]{} 0.$$
  This implies that $f(x_i) \xrightarrow[i \in I]{} 0$, proving the implication.
  Now the opposite: $(2) \Rightarrow (6)$.
  We know that $f^{-1} (\inte B_1 (0)) = \{x \in X\ |\ |f(x)| < 1\}$
  is an open neighborhood of $0$ in $X$. Then there exist $p_1, \dots, p_r \in \mathcal{P}$
  and an $\varepsilon > 0$ such that 
  $$0 \in \bigcap_{i = 1} ^r U(0, p_i, \varepsilon) \subseteq f^{-1} (B_1 ^\circ (0)).$$
  If $p_i(x) < \varepsilon$ for all $i \leq r$, then $|f(x)| < 1.$ Pick any $\delta > 0$.
  Then $$p_i \left(x \cdot \frac{\varepsilon}{\sum p_i (x) + \delta}\right) = \frac{\varepsilon}{\delta + \sum p_i (x)} \cdot p_i (x) < \varepsilon,$$
  which implies 
  $$\left| f\left(x \cdot \frac{\varepsilon}{\sum p_i (x) + \delta}\right) \right| < 1.$$
  From this we get 
  $|f(x)| < \frac{1}{\varepsilon} \left(\sum p_i (x) + \delta\right)$.
  Since $\delta > 0$ was arbitrary, we get
  \begin{equation*}
    |f(x)| \leq \sum_{i = 1} ^r \frac{1}{\varepsilon} p_i(x). \qedhere 
  \end{equation*}
\end{myproof}

Recall the following theorem from measure theory.

\begin{theorem}[Riesz-Markoff theorem]
  Let $X$ be a compact $T_2$ space, $\Phi \in C(X)^*$.
  Then there exists a regular Borel measure such that 
  $$\Phi (f) = \int_X f\, d\mu,\ \forall f \in C(X).$$
  Further, $\| \Phi\| = \|\mu\| = |\mu| (X)$.
\end{theorem}

\begin{remark}
  The above also works if $K$ is locally compact and $\Phi \in C_0(X)^*$.
\end{remark}

As a corollary, we get the following proposition.

\begin{proposition}
  Let $X$ be completely regular. Endow $C(X)$ with a topology induced by its seminorms.
  If $L \in C(X)^{*}$ then there exists a compact $K \subseteq X$ and a regular Borel measure on $K$ such that 
  $$L(f) = \int_{K} f\, d\mu,\ \forall f \in C(X).$$
  Conversely, every such pair $(K, \mu)$ defines $L \in C^* (K)$ with the above map.
\end{proposition}

\begin{myproof}
  Begin with the implication $(\Leftarrow)$. Given $(K, \mu)$, we just need to prove that the induced 
  functional $L$ is continuous on $X$. We have 
  $$|L(f)| = \left| \int_K f\, d\mu \right| \leq \|\mu\| \sup_K |f| = \|\mu\| p_K (f)$$
  and $L$ is continuous. Now the converse $(\Rightarrow)$.
  Let $L \in C(X)$. By the previous proposition, there exist compact sets 
  $K_1, \dots, K_p \subseteq X$ and $\alpha_1, \dots, \alpha_p > 0$ such that 
  $$|L(f)| \leq \sum_{j = 1} ^p \alpha_j p_{K_j} (f).$$
  Let $K = \bigcup_{j = 1} ^p K_j$ and $\alpha = \max \{\alpha_1, \dots, \alpha_p\}$.
  Then $\|f\| \leq \alpha p_K (f)$ for all $f \in C(X)$.
  Observe that if $f \in C(X)$ and $f \big|_K = 0$, then $L(f) = 0$.
  We now define a map $F: C(K) \to \F$. 
  Since $X$ is completely regular, we have a Tietze-like extension theorem: for any compact $K \subseteq X$ and a continuous function $g \in C(K)$,
  there exists an extension $\widetilde{g} \in C(X)$.
  Define $F(g) := L(\widetilde{g})$.
  First we need to check if $F$ is even well defined. Suppose we have two extensions $\widetilde{g}$ and $\widetilde{\widetilde{g}}$
  of $g \in C(K)$. Since $\widetilde{g} - \widetilde{\widetilde{g}}$ is evidently zero on $K$, we have 
  $$L(\widetilde{g}) - L(\widetilde{\widetilde{g}}) = L(\widetilde{g} - \widetilde{\widetilde{g}}) = 0$$
  and $F$ really is well defined. It is also clearly linear, so we just need to check continuity:
  $$|F(g)| = |L(\widetilde{g})| \leq \alpha \cdot p_K (\widetilde{g}) = \alpha \cdot \|g\|_{\infty, K},$$
  therefore $\|F\| \leq \alpha$ and $F$ is continuous. Lastly we apply Riesz-Markoff: there exists a regular Borel Measure $\mu$
  so that $F(g) = \int_K g\, d\mu.$ If $f \in C(X)$, then $g := f\big|_K \in C(K)$
  and we have 
  \begin{equation*}
    L(f) = F(g) = \int_K g\, d\mu = \int_K f \, d\mu. \qedhere
  \end{equation*}
\end{myproof}

\subsection{Krein-Milman theorem}

\begin{definition}
  Let $X$ be a vector space and $C \subseteq X$ its convex subset.
  \begin{itemize}
    \item[(a)] A nonempty convex subset $F \subseteq C$ is a face if for any $x, y \in C$ we have
    $$(\exists t \in (0, 1):\ tx + (1 - t)y \in F) \Rightarrow x, y \in F.$$
    \item[(b)] A point $x \in C$ is a called an extreme point if $\{x\} \subseteq C$ is a face.  
  \end{itemize}
  We use the notation $\ext (C)$ for a set of all extreme points of $C$.
\end{definition}

\begin{example}
  If we take spaces of real sequences, we have
  \begin{itemize}
    \item $\ext ((\ell^\infty)_1) = \{(\pm 1, \pm 1, \dots)\}$;
    \item $\ext ((\ell^1)_1) = \{(0, 0, \dots, \pm 1, \dots)\}$;
    \item $\ext (c_0)_1 = \emptyset$.
  \end{itemize} 
\end{example}

\begin{example}
  Let us show that $\ext (L^1 [0, 1])_1 = \emptyset$. Take any $f \in (L^1 [0, 1])_1$.
  Then $\int _0 ^1 |f(t)| \, dt = 1$, so there must exist an $x \in [0, 1]$ such that 
  $\int _0 ^x |f(t)| \, dt = 1/2$. Now define 
  $g := 2 \cdot f \cdot \chi_{[0, x]}$ and $h := 2 \cdot f \cdot \chi_{[x, 1]}$. 
  Now we have $g, h \in (L^1 [0, 1])_1$ and $f = \frac{1}{2}g + \frac{1}{2} h$, so $f$ cannot be an extreme point.
\end{example}

\begin{example}
  Finally, let us prove that $\ext (C[0, 1])_1 = \{\pm 1\}$ for real valued functions.
  Take any $f \in (C[0, 1])_1$. Then define functions $g(t) = \min \{2f(t) + 1, 1\}$ and $h(t) = \max \{2 f(t) - 1, -1\}$.
  Clearly $g, h \in (C[0, 1])_1$ and $f = \frac{1}{2} g + \frac{1}{2} h$. If $f$ is an extreme point, then $g = h$, which happens only if $f = \pm 1$.
\end{example}

\begin{definition}
  For a vector space $X$ and $A \subseteq X$ define a convex hull $\co A$ as the intersection of all convex sets in $X$ that contain $A$.
  If $X$ is a TVS, then define closed convex hull $\overline{co} A$ as the intersection of all closed convex sets that contain $A$.
\end{definition}

Convex hull of a set $A$ can be written explicitly:
$$\co A = \left\lbrace \sum_{i = 0}^n \alpha_i x_i\ |\ n \in \N, \alpha_i \geq 0, \sum_{i = 0} ^n \alpha_i = 1, x_i \in A\right\rbrace.$$
If $X$ is a TVS, then define $\overline{\co} A = \overline{\co A}$.

\begin{lemma}
  Let $X$ be a TVS and $C \subseteq X$ a nonempty compact convex set.
  Then for $\Phi \in X^*$ the set 
  $$F = \{x \in C\ |\ \real \Phi (x) = \min_C \real \Phi\}$$
  is a closed face of $C$.
\end{lemma}

\begin{myproof}
  Since $C$ is compact and $x \mapsto \real \Phi(x)$
  is continuous, it attains its minimum on $C$. Hence $F$ is nonempty.
  Since $F$ is a continuous preimage of a point, it is also closed.
  By the linearity of $\Phi$, $F$ is convex. 
  Now suppose that $t \in (0, 1)$ and $x, y \in C$ are such that 
  $tx + (1 - t)y \in F$, we have 
  \begin{align*}
    \min_C \real \Phi &= \real \Phi (tx + (1 - t)y)\\
    &= t \cdot \real \Phi(x) + (1 - t) \real \Phi (y)\\
    &\geq t \cdot \min_C \real \Phi + (1 - t) \min_C \real\\
    &= \min_C \real \Phi. 
  \end{align*}
  Since we have the equality in the second-to-last line, we have 
  $\real \Phi (x) = \min_C \real \Phi$
  and $\real \Phi (y) = \min_C \real \Phi$, meaning that $x, y \in F$.
\end{myproof}

\begin{remark}
  Not all closed convex faces are of this form.
\end{remark}

\begin{theorem}[Krein-Milman]
  Let $X$ be a LCS and $C \subseteq X$ its nonempty compact convex subset.
  Then $C = \overline{\co} (\ext C)$. In particular, $\ext C \neq \emptyset.$
\end{theorem}

\begin{myproof}
  Let $\mathcal{F} = \{\textrm{closed faces in $C$}\}$ be ordered with $\supset$.
  Since $C \in \mathcal{F}$, it is nonempty. The set $\mathcal{F}$ is then partially ordered. Since any 
  increasing chain in $\mathcal{F}$ has finite intersection property, it has a nonempty intersection due to $C$ being compact.
  As a result, any incresing chain in $\mathcal{C}$ has an upper bound.
  This tells us that we can apply Zorn's lemma to obtain a maximal element $F_0 \in \mathcal{F}$.
  We prove that $F_0 \in \ext C$. Assume that there are distinct $x, y \in F_0$.
  By Hahn-Banach, there exists a $\Phi \in X^*$ such that $\Phi(x) \neq \Phi(y)$.
  WLOG we assume that $\real \Phi(x) < \real \Phi(y)$. Define a set 
  $$F_1 = \{z \in F_0\ |\ \real \Phi(z) = \min_{F_0} \real \Phi\}.$$
  Then $F_1 \subsetneq F_0$, since $y \notin F_0$. By the previous lemma,
  $F_1$ is a closed face in $F_0$, so it is a closed face in $C$, contradicting maximality of $F_0$.
  Thus we have $F_0 \in \ext C$ and $\ext C \neq \emptyset$.
  Since we have $C \supset \ext C$, we also have $C = \overline{\co} (C) \supseteq \overline{\co} (\ext C)$.
  Suppose $x \in C \setminus \overline{\co} (\ext C)$. By Hahn-Banach, there exists a $\Psi \in X^*$
  such that $\real \Psi(x) < \min _{\overline{\co} (\ext C)} \real \Psi$.
  So the set 
  $$F = \{z \in C\ |\ \real \Psi (z) = \min_C \real \Psi\}$$
  is a closed face in $C$. By the first part of this proof,
  there exists a $z \in \ext F \subseteq \ext C$. Hence 
  $$\min_C \real \Psi = \Psi (z) = \min_{\overline{\co} (\ext C)} \real \Psi > \real \Psi(x) \geq \min_C \real \Psi,$$
  which leads to a contradiction. Therefore $\overline{\co} (\ext C) = C$.
\end{myproof}

\begin{example}
  Let $\mathcal{H}$ be a Hilbert space. Then 
  $$\ext (\mathcal{H})_1 = \{v \in \mathcal{H}\ |\ \|v\| = 1\}.$$
  We prove the inclusion $(\supseteq)$. Suppose that 
  $\| v\| = 1$ and $v = tx + (1 - t)y$, where $t \in (0, 1)$ and $x, y \in (\mathcal{H})_1$.
  We have 
  \begin{align*}
    1 &= \| v\|^2\\
    &= \| tx + (1 - t)y\|^2\\
    &= \langle tx + (1 - t)y, tx + (1 - t)y \rangle\\
    &= t^2 \|x\|^2 + (1 - t)^2 \|y\|^2 + 2t(1 - t)\real \langle x, y\rangle\\
    &\leq t^2 + (1 - t)^2 + 2t(1 - t) = 1.
  \end{align*}
  We get equality in the Cauchy-Schwartz, so $x, y$ are linearly dependent and therefore equal.
\end{example}

\begin{example}
  We have the identity 
  $$\ext (\bh)_1 = \{V \in \bh\ |\ \textrm{$V$ or $V^*$ is an isometry}\}.$$
  Here, we will just prove the inclusion $(\supseteq)$.
  Let $V \in \bh$  be an isometry and suppose $V = tS + (1 - t)T$
  for $t \in (0, 1)$ and $S, T \in (\bh)_1$.
  For $x \in \mathcal{H}$ we have:
  \begin{align*}
    \| x\| &= \| V x\|\\
    &= \| tSx + (1 - t)Tx\|\\
    &\leq t \|Sx\| + (1 - t) \|Tx\|\\
    &\leq t \| S\| \|x\| + (1 - t) \|T\| \|x\|\\
    &\leq t \|x\| + (1 - t)\|x\| = \|x\|. 
  \end{align*}
  Since we have equality, we get $\|S\| = \|T\| = 1$
  and $\|Sx\| = \|Tx\| = \|x\|$. So $S, T$ are isometries.
  For every $x \in \partial (\mathcal{H})_1 = \ext (\mathcal{H})_1$, we have 
  $$Vx = t \cdot Sx + (1 - t) Tx$$ and by the previous example that implies $Tx = Sx = Vx$,
  so we really have $S = T = V$. We use the same argument if $V^*$
\end{example}

\begin{example}
  Let $X$ be a Banach space. Then $(X^*)_1$ is weak-* compact (by Banach-Alaoglu),
  so Krein-Milman gives us $(X^*)_1 = \overline{\co} (\ext (X^*)_1)$, hence $(X^*)_1$ has a lot of extreme points.
\end{example}

\begin{example}
  We prove that $c_0$ is not the dual space of a Banach space.
  It suffices to show that $\ext (c_0)_1 = \emptyset$. Let $x = (x_n)_n \in (c_0)_1$.
  then $\lim_n x_n = 0$. Thus there exists $N \in \N$ such that $|x_n| < \frac{1}{2}$ for all $n > N$.
  Now define $y, z \in c_0$ by setting $y_n = z_n = x_n$ for $n \leq N$
  and $$y_n = x_n + \frac{1}{2^n},\quad z_n = x_n - \frac{1}{2^n}$$ 
  for $n > N$. Then $y, z \in (c_0)_1$ and $x = \frac{1}{2} (y + z)$, so $x \notin \ext (c_0)_1$.
\end{example}

\begin{example}
  We prove that $ \ext (L^1 [0, 1])_1 = \emptyset$. Take $h \in \ext(L^1 [0, 1])_1$. 
  We consider two cases: if $h = 0$, then $h = \frac{1}{2} (1_{[0, 1]} - 1_{[0, 1]})$ and $h$ cannot be the extreme point.
  So assume $0 < |h| \leq 1$. Define the function 
  $$\phi (t) = \int_0 ^t |h|\, d\mu.$$
  Then $\phi$ is continuous, $\phi(0) = 0$ and $\| h\| = \phi(1) > 0$.
  Therefore, thhere must exist $t_0 \in [0, 1]$ such that $\phi(t_0) =\frac{ \|h\|}{2}$
  and we have $$h = \frac{1}{2} 1_{[0, t_0]} h + \frac{1}{2} 1_{(t_0, 1]} h,$$
  so $h$ once again cannot be an extreme point of the unit ball.  
  As a result, $L^1 [0, 1]$ is not a dual space.
\end{example}

\begin{theorem}[Milman]
  Let $X$ be a LCS, $K \subseteq X$ compact and assume $\overline{\co} K$ is compact.
  Then $\ext (\overline{\co} (K)) \subseteq K$.
\end{theorem}

\begin{myproof}
  Assume there exists $x_0 \in \ext (\overline{\co} (K)) \setminus K$.
  Then there exists a basis neighborhood $V$ of $0$ in $X$ such that 
  $(x_0 + \overline{V}) \cap K = \emptyset$ or equivalently $x_0 \notin K + \overline{V}$.
  If we write 
  $K \subseteq \bigcup_{x \in K} (x + V)$, 
  we get 
  $$K \subseteq \bigcup_{j = 1} ^{n} (x_j + V).$$
  Form $K_j = \overline{\co} (K \cap (x_j + V))$.
  Then $K_j$ is convex and compact since $K_j \subseteq \overline{\co} (K)$.
  We also have $K_j \subseteq \overline{x_j + V} = x_j + \overline{V}$ since $V$ is convex.
  Also, $K \subseteq K_1 \cup \cdots \cup K_n$.
  Next we prove that $\co (K_1 \cup \cdots \cup K_n)$ is compact.
  Define $$\Sigma = \{(t_1, \dots, t_n) \in [0, 1]^n\ |\ \sum_{j = 1} ^n t_j = 1\}$$
  and the function 
  $$f: \Sigma \times K_1 \times \cdots \times K_n \to X,\quad (t, k_1, \dots, k_n) \mapsto \sum_{j = 1} ^k t_j k_j.$$
  Denote $C := \im f$.
  Obviously, $C \subseteq \co (K_1 \cup \cdots \cup K_n)$ and $C$ is a convex compact set.
  Furthermore, $C \supset K_j$ for each $j$, so $C = \co (K_1 \cup \cdots \cup K_n)$.
  From there, we get 
  $$\overline{\co} (K) \subseteq \overline{\co} (K_1 \cup \cdots \cup K_n) = {\co} (K_1 \cup \cdots \cup K_n).$$
  But since $K_j \subseteq \overline{\co} (K)$ for all $j$, we deduce $\overline{\co} (K) = \overline{\co} (K_1 \cup \cdots \cup K_n)$.
  We know that $x_0 \in \overline{\co} (K)$, so $$x_0 = t_1 y_1 + \cdots + t_n y_n$$
  for some $t_i \in [0, 1],\ \sum t_i = 1$ and $y_j \in K_j$.
  But $x_0 \in \ext (\overline{\co})(K)$, so $y_j = x_0$ for some $j$. So we get 
  $x_0 \in K_j \subseteq x_j + \overline{V} \subseteq K + \overline{V}$,
  a contradiction.
\end{myproof}

\begin{remark}
  \begin{enumerate}
    \item In finite dimensions, the convex hull of a compact set is compact.
    In infinite dimensions this fails.
    \item The set $\ext (C)$ is not always closed, even if $C \subseteq \R^3$ is convex and compact.
  \end{enumerate}
\end{remark}

\section{$C^*$-algebras and continuous functional calculus}

\subsection{Spectrum}

Let $a$ be a complex algebra with a unit $1$ and 
$$GL (A) = \{a \in A\ |\ \textrm{$a$ is invertible}\}.$$
If $x \in A$, then we define the spectrum 
$$\sigma_A (x) = \{\lambda \in \C\ |\ x - \lambda \cdot 1 \notin GL(A)\}.$$
\begin{proposition}
  Let $A$ be a complex algebra with unity $1$ and $x, y = A$. Then 
  $$\sigma_A (xy) \cup \{0\} = \sigma_A (yx) \cup \{0\}.$$
\end{proposition}

\begin{myproof}
  Suppose $1 - xy \in GL(A)$. Formally, we have 
  $$(1 - xy)^{-1} = 1 + xy + (xy)^2 + \cdots$$
  and $$(1 - yx)^{-1} = 1 + yx + (yx)^2 + \cdots = 1 + y(1 - xy)^{-1} x.$$
  From that, we claim that indeed $1 - xy \in GL (A)$ and 
  $$(1 - xy)^{-1} = 1 + y(1 - xy)^{-1} x.$$ We can easily calculate that 
  \begin{equation*}
    (1 + y(1 - xy)^{-1} x)(1 - xy) = (1 - xy) (1 + y(1 - xy)^{-1} x) = 1. \qedhere
  \end{equation*}
\end{myproof}

\begin{example}
  Let $S, S^* \in \mathcal{B}(\ell^2)$ be right and left shift operators, respectively.
  Then $S S^* = I$, but $$S S^* (x_1, x_2, \dots) = (0, x_1, x_2, \dots).$$
  This imples that $0 \in \sigma (S S^*)$, but $0 \notin \sigma (S^* S)$.
\end{example}

\subsection{Banach and $C^*$-algebras}

\begin{definition}
  \begin{itemize}
    \item A Banach algebra is a Banach space $A$ that is also an algebra and $\|xy\| \leq \|x\| \|y\|,\ \forall x, y \in A$.
    If a Banach algebra has a $1$, we also demand $\|1\| = 1$.
    \item An involution on a Banach algebra $A$ is a skew-linear map $$*: A \to A,\quad a \mapsto a^*$$
    satisfying $$(xy)^* = y^* x^*,\quad (x^*)^* = x,\quad \|x^*\| = \|x\|.$$
    A Banach $*$-algebra $A$ that also satisfies $\|x^* x\| = \|x\|^2,\ \forall x \in A$ is a $C^*$-algebra.
  \end{itemize}
\end{definition}

The $C^*$-algebras considered here are, for the most part, unital.

\begin{proposition}
  We collect some basic properties of $C^*$-algebras.
  \begin{enumerate}
    \item If $A$ is a Banach $*$-algebra, then 
    $(x^*)^{-1} = (x^{-1})^*$ and $\sigma_A (x^*) = \overline{\sigma_A (x)}.$
    \item Let $A$ be a Banach algebra. If $\|x\| < 1$, then $1 - x \in GL (A)$ and 
    $$(1 - x)^{-1} = 1 + x + x^2 + \cdots$$ As a consequence, if $\| 1 - x\| < 1$, then $x \in GL (A)$.
    \item Let $A$ be a Banach algebra. Then $GL(A) \subseteq A$ is open and $x \mapsto x^{-1}$ is continuous in $GL (A)$.
    \item If $A$ is a Banach algebra and $x \in A$, then $\sigma_A (x)$ is a nonempty compact set.
  \end{enumerate}
\end{proposition}

\begin{remark}
  From the proof of (iii) we get the bound 
  $$\|x^{-1} - y^{-1}\| \leq \frac{\|y^{-1}\|^2}{1 - \|y^{-1}\| \|x - y\|} \|x - y\|.$$
\end{remark}

\begin{theorem}[Gelfand-Mazur]
  If $A$ is Banach algebra that is also a division ring, then $A = \C$.
\end{theorem}

\begin{myproof}
  Let $x \in A$ and $\lambda \in \sigma_A (x)$. Then $x - \lambda \cdot 1 \notin GL(A) = A \setminus \{0\}$.
  Then $x - \lambda = 0$ and $x = \lambda \in \C$.
\end{myproof}

\begin{definition}
  If $f(x) = \sum_{j = 0} ^n a_j x^j$ is a polynomial and $a \in A$ then we define 
  $f(a) = \sum _{j = 0} ^n a_j a^j \in A$.
\end{definition}

\begin{theorem}[Spectral mapping theorem for polynomials]
  Let $A$ be a complex unitary algebra and $f \in \C [x]$. Then $f(\sigma_A (a)) = \sigma_A (f(a))$
  for all $a \in A$.
\end{theorem}

\begin{myproof}
  If $\lambda \in \sigma_A (a)$ and $f(x) = \sum_{j = 0} ^n a_j x^j$, then 
  $$f(x) - f(\lambda) = \sum_{j = 1} ^n a_j (x^j - \lambda^j) = (x - \lambda) \cdot \sum_{j = 1} ^n a_j \sum_{k = 0} ^{j -1} x^k \lambda^{j - 1 - k}.$$
  From there we get 
  $$f(a) - f(\lambda) = (a - \lambda) \sum_{j = 1} ^n a_j \sum_{k = 0} ^{j - 1} a^k \lambda^{j - 1 - k}.$$
  Since $a - \lambda$ commutes with $\sum_{j = 1} ^n a_j \sum_{k = 0} ^{j - 1} a^k \lambda^{j - 1 - k}$, $f(a) - f(\lambda)$
  is not invertible and therefore $f(\lambda) \in \sigma_A (f(a))$.
  Conversely, if $\mu \notin f(\sigma_A (a))$, we factor 
  $$f(x) - \mu = a_n (x - \lambda_1) \cdots (x - \lambda_n).$$
  Since $f(\lambda) - \mu \neq 0$ for any possible $\lambda \in \sigma_A (a)$, we have $\lambda_i \notin \sigma_A (a)$ for every index $i$.
  So we have $f(a) - \mu \in GL(A)$.
\end{myproof}

\begin{definition}
  Let $A$ be a Banach algebra and $x \in A$. The spectral radius of $x$ is 
  $$r(x) = \sup_{\lambda \in \sigma_A (x)} |\lambda|.$$
\end{definition}

\begin{remark}
  It is trivial to see that $r(xy) = r(yx)$.
\end{remark}

\begin{theorem}[Spectral radius formula]
  Let $A$ be a Banach algebra and $x \in A$. Then $\lim_{n \to \infty} \|x^n\|^{\frac{1}{n}}$ exists 
  and is equal to $r(x)$.
\end{theorem}

\begin{definition}
  Let $A$ be a Banach $*$-algebra and $x \in A$.
  \begin{itemize}
    \item $x$ is normal iff $x x^* = x^* x$.
    \item $x$ is self-adjoint iff $x = x^*$.
    \item $x$ is skew self-adjoint iff $x = - x^*$.
  \end{itemize}
\end{definition}

\begin{remark}
  Every $a \in A$ can be uniquely written as a sum of a self-adjoint and skew self-adjoint element:
  $$a = \frac{a + a^*}{2} + \frac{a - a^*}{2}.$$
  Alternatively, we can uniquely write it in the form 
  $$\left(\frac{a + a^*}{2} \right) + i \cdot \left(\frac{a - a^*}{2i}\right)$$
  where both terms in parenthesis are self-adjoint.
\end{remark}

\begin{corollary}
  Let $A$ be a Banach $*$-algebra and $x \in X$ normal.
  Then $r(x^* x) \leq r(x)^2$. If $A$ is a $C^*$-algebra, then $r(x^* x) = r(x)^2$.
\end{corollary}

\begin{myproof}
  We use the spectral radius formula:
  \begin{align*}
    r(x^* x) &= \lim_{n \to \infty} \| (x^* x)^n \|^{\frac{1}{n}}\\
    &= \lim_{n \to \infty} \| (x^*)^n x^n\|^{\frac{1}{n}}\\
    &= \lim_{n \to \infty} \| (x^n)^* x^n\|^{\frac{1}{n}}\\
    &\leq \lim_{n \to \infty} \| x^n\|^{\frac{2}{n}} = r(x)^2.
  \end{align*} 
  If $A$ is a $C^*$-algebra, then we obviously have an equality in the last line of the above calculation.
\end{myproof}

\begin{proposition}
  Let $A$ be a $C^*$-algebra and $x \in A$ normal. Then $r(x) = \|x\|$.
\end{proposition}

\begin{myproof}
  First we assume $x$ is self-adjoint. Then 
  $$\|x^2\| = \| xx^*\| = \|x\|^2.$$
  By induction, we get 
  $\|x^{2^n}\| = \|x\|^{2^n}$ for every $n \in \N$.
  Hence we get 
  $$r(x) = \lim_{n \to \infty} \| x^n\|^\frac{1}{n} = \lim_{n \to \infty} \| x^{2^n} \|^{\frac{1}{2^n}} = \| x\|.$$
  If $x$ is only normal, then $$\| x\|^2 = \| x^*x\| = r(x^* x) = r(x)^2,$$
  so $\|x\| = r(x)$.
\end{myproof}

\begin{corollary}
  Let $A, B$ be $C^*$-algebras and $\Phi: A \to B$ a *-homomorphism ($\Phi(x^*) = \Phi(x)^*$).
  Then $\Phi$ is a contraction. Furthermore, if $\Phi$ is an isomorphism,
  then it is isometric.
\end{corollary}

\begin{myproof}
  Obviously, $\Phi$ maps invertible elements into invertible elements,
  so $\Phi (GL (A)) \subseteq GL (B)$. This implies $\sigma_B (\Phi(x)) \subseteq \sigma_A (x)$,
  hence $r(\Phi(x)) \leq r(x)$. Then 
  \begin{align*}
    \| \Phi(x)\|^2 &= \| \Phi(x) \Phi(x)^*\|\\
    &= \| \Phi(x) \Phi(x^*)\|\\
    &= \|\Phi(x x^*)\|
  \end{align*}
  and using the previous proposition, we get 
  $$r(\Phi(x x^*)) \leq r(x x^*) = \| x x^*\| = \|x\|^2.$$
  If $\Phi$ is a $*$-isomorphism, we apply the same logic to its inverse, so it has to be an isometry.
\end{myproof}

\begin{corollary}
  If $A$ is a $*$-algebra, then there exists at most one norm on $A$
  that makes it into a $C^*$-algebra.
\end{corollary}

\begin{myproof}
  If we consider the identity map 
  $$(A, \|\|_1) \rightarrow (A, \|\|_2),$$
  it is a $*$-isomorphism, so it preserves the norm by the previous corollary.
\end{myproof}

\begin{lemma}
  Let $A$ be a $C^*$-algebra and $x \in A$ self-adjoint. Then $\sigma_A (x) \subseteq \R$.
\end{lemma}

\begin{myproof}
  Suppose $\lambda = \alpha + i \beta \in \sigma_A (x)$ for some $\alpha, \beta \in \R$.
  Define $y = x - \alpha + it$ for $t \in \R$. Then $i(\beta + t) \in \sigma_A (y)$ and $y$ is normal.
  Hence 
  \begin{align*}
    |i(\beta + t)|^2 &= (\beta + t)^2\\
    &\leq r(y)\\
    &= \|y\|^2\\
    &= \|yy^*\|\\
    &= \| (x - \alpha)^2 + t^2\|\\
    &\leq \|x - \alpha\|^2 + t^2.
  \end{align*}
  We have $\beta^2 + 2 \beta t \leq \| x - \alpha\|^2$ and since $t \in \R$ was arbitrary, we have $\beta = 0$.
\end{myproof}

\begin{lemma}
  Let $A$ be a Banach algebra and $x \notin GL(A)$.
  If $(x_n)_n \subseteq GL(A)$ satisfies $x_n \to x$, then $\|x_n ^{-1}\| \to \infty$.
\end{lemma}

\begin{myproof}
  If the sequence $\|x_n^{-1}\|$ is bounded, then 
  $$\| 1 - x x_n^{-1}\| = \| (x_n - x) x_n^{-1}\| \leq \| x_n - x\| \cdot \|x_n^{-1}\| \to 0.$$
  In particular, there exists some $n \in \N$ such that $\| 1 - xx_n^{-1}\| < 1$,
  which implies $x x_n^{-1} \in GL (A)$ and therefore $x = (x x_n^{-1}) x_n \in GL(A)$, contradiction.
\end{myproof}

\begin{proposition}
  Let $B$ be a $C^*$-algebra and $A \subseteq B$ a unital $C^*$-subalgebra.
  Then for all $x \in A$, we have $\sigma_A (x) = \sigma_B (x)$.
\end{proposition}

\begin{myproof}
  Obviously, $GL (A) \subseteq GL(B)$. For a self adjoint $x \in A \setminus GL(A)$,
  $it \notin \sigma_A (x)$ for $t \in \R$. So there exists $(x - it)^{-1} \in A$.
  Clearly, $$x - it \in GL(A) \xrightarrow[t \to 0]{} x \notin GL(A),$$
  so $\| (x - it)^{-1}\| \to \infty$. Since the inverse function is continuous,
  this immediately yields $x \notin GL (B)$.
  For general $x \in A$: if $x \in GL(B)$, then $x^* x \in GL(B)$ 
  is self-adjoint. By the first part of the proof, $x^* x \in GL(A)$.
  It follows that 
  \begin{equation*}
    x^{-1} = (x^* x)^{-1} x^* \in A,
  \end{equation*}
  so $x \in GL(A)$.
\end{myproof}

\begin{example}
  Let $X$ be a topological space and $C_b (X)$ a set of continuous bounded complex functions on $X$,
  endowed with the sup metric. Then $C_b (X)$ is a $C^*$-algebra ($f^*(x) = \overline{f(x)}$).
  If $X$ is compact then $C(X)$ is also an $C^*$-algebra.
\end{example}

\begin{example}
  Define $C_0 (X)$ as the subset of $f \in C_b (X)$
  that vanish at infinity ($\forall \varepsilon > 0:\ \exists K \subseteq X$ compact, such that $\|f\big|_{X \setminus K}\| < \varepsilon$).
  Then $C_0 (X)$ is a nonunital $C^*$-subalgebra of $C_b (X)$. 
\end{example}

\begin{example}
  Let $(X, \mu)$ be a measure space.
  Then $L^\infty (X, \mu)$, a set of essentially bounded functions endowed with the essential supremum, is a unital $C^*$-algebra.
\end{example}

\begin{example}
  For a Hilbert space $\mathcal{H}$, $\bh$ is a non-abelian $C^*$-algebra:
  $\forall x \in \bh$ we have $\| x^* x\| = \|x\|^2$.
\end{example}

\begin{example}
  If $\Gamma$ is a group, we define 
  $$\ell^1 (\Gamma) = \{(\alpha_s)_{s \in \Gamma}\ |\ \alpha_s \in \C,\ \sum_{s \in \Gamma} |\alpha_s| < \infty\}.$$
  We can then introduce the convolution multiplication on $\ell^1 \Gamma$:
  $$(\alpha * \beta)_s = \sum_{t \in \Gamma} \alpha_{st} \beta_{t^{-1}}.$$
  This is a Banach algebra; it is even a Banach $*$-algebra with involution 
  $(\alpha^*)_s = \overline{\alpha_{s^{-1}}}$. However, it is not a $ C*$-algebra.
\end{example}

\subsection{Gelfand transform}

\begin{definition}
  Let $A$ be an abelian Banach algebra. The spectrum of $A$ is defined as
  $$\sigma (A) := \{\varphi: A \to \C\ |\ \textrm{$\varphi \neq 0$ continuous algebra homomorphism}\} \subseteq A^*$$
  endowed with a weak-* topology. Its elements are called characters.
\end{definition}

If $\varphi \in \sigma (A)$, then $\ker \varphi \cap GL(A) = \emptyset.$
For $x \in A$, we have $\varphi(x) \in \sigma_A(x)$:
\begin{align*}
  \varphi(x - \varphi(x)) &= \varphi(x) - \varphi(\varphi(x) \cdot 1)\\
  &= \varphi(x) - \varphi(x) \varphi(1)\\
  &= \varphi(x) - \varphi(x) = 0.
\end{align*}
Therefore $|\varphi(x)| \leq r(x)\leq \|x\|$, we have the bound $\|\varphi\| \leq 1$.
But since $\varphi(1) = 1$, we get $\|\varphi\| = 1$.
We know that $\sigma (A)$ is closed in $(A^*)_1$, so $\sigma(A)$ is a compact Hausdorff space by Banach-Alaoglu.

\begin{proposition}
  Let $A$ be a $C^*$-algebra and $h: A \to \C$ a non-zero homomorphism (not necessarily a *-homomorphism). 
  Then the following is true:
  \begin{enumerate}
    \item $h(a) \in \R$ for self-adjoint $a$;
    \item $h(a^*) = \overline{h(a)}$ for all $a \in A$;
    \item $h(a a^*) \geq 0$ for all $a \in A$;
    \item if $1 \in A$ and $u \in U(A)$, then $|h(u)| = 1$. 
  \end{enumerate}
\end{proposition}

\begin{myproof}
  \begin{enumerate}
    \item Since $h(a) \in \sigma_A(a)$ and self-adjoint elements have real spectrum, this is trivial.
    \item Let $a = a_1 + i a_2$, where $a_1, a_2$ are self-adjoint. Then $a^* = a_1 - i a_2$ and 
    $$h(a^*) = h(a_1 - i a_2) = h(a_1) - i h(a_2) = \overline{h(a_1) + i h(a_2)} = \overline{h(a)}.$$
    \item Follows from (b).
    \item If $u$ is unitary, then $|h(u)|^2 = h(u) h(u^*) = h(u u^*) = h(1) = 1$.
  \end{enumerate}
\end{myproof}

\begin{remark}
  The first three items also hold for non-unital algebra $A$.
\end{remark}

\begin{corollary}
  Every nonzero algebra homomorphism $h: A \to \C$ is a character.
\end{corollary}

\begin{proposition}
  Let $A$ be an abelian Banach algebra. Then the map $\varphi \mapsto \ker \varphi$
  is a bijection from $\sigma (A)$ to the set of all maximal ideals of $A$.
\end{proposition}

\begin{myproof}
  If $\varphi \in \sigma (A)$, then $\ker \varphi \lhd A$. If $\ker \varphi \subsetneq I \lhd A$, then there exists
  an element $x \in I \setminus \ker \varphi$. That is, $\varphi(x) \neq 0$.
  from $1 - \frac{x}{\varphi(x)} \in \ker \varphi$ it follows that 
  $$1 = \left(1 - \frac{x}{\varphi(x)}\right) + \frac{1}{\varphi(x)} \cdot x \in I$$
  and $\ker \varphi$ is a maximal ideal.
  Conversely, let $I \lhd A$ be a maximal ideal. Then $I \cap GL(A) = \emptyset$
  and since $GL(A)$ is open, we also have $\overline{I} \cap GL(A) = \emptyset$.
  Thus $\overline{I} \lhd A$ and $1 \notin \overline{I}$, so $I \subseteq \overline{I} \subsetneq A$.
  By maximality, $\overline{I} = I$. Then $\quot{A}{I}$ is a Banach algebra and since $I$ is maximal,
  every nonzero element in $\quot{A}{I}$ is invertible. By Gelfand-Mazur, $\quot{A}{I} \cong \C$.
  The projection $\pi: A \to \quot{A}{I} \cong \C$ is in $\sigma (A)$ and $\ker \pi = I$.
\end{myproof}

\begin{corollary}
  Let $A$ be an abelian Banach algebra and $x \in A \setminus GL(A)$.
  Then there exists $\varphi \in \sigma(A)$ such that $\varphi(x) = 0$.
  In particular, $\sigma(A) \neq 0$.
\end{corollary}

\begin{myproof}
  If $x \notin GL(A)$. Since $\langle x \rangle \subsetneq A$, it has to be included in a maximal ideal $I$ of $A$ (Zorn's lemma).
  By the previous proposition, there exists a $\varphi: A \to \C$ in $\sigma (A)$
  such that $x \in I = \ker \varphi$.
\end{myproof}

\begin{theorem}[Stone-ƒåech]
  Let $X$ be a topological space. For $x \in X$, let $\beta_x: C_b (X) \to \C$
  be an evaluation homomorphism $f \mapsto f(x)$. Then 
  $$\beta: X \to \sigma (C_b (X)),\quad x \mapsto \beta_x$$
  is a continuous map whose image is dense in the codomain and with the following universal property:
  if $\pi: X \to K^{T_2,\ \textrm{compact}}$ is continuous, then there exists a unique continuous mapping  
  $$\beta_{\pi} : \sigma (C_b (X)) \to K$$
  such that $\pi(x) = \beta_{\pi} (\beta_x)$ for all $x \in X$.
  In particular, if $X$ is compact $T_2$, then $\beta$ is a homeomorphism.
  \[\begin{tikzcd}
    X & {K^{T_2,\ \textrm{compact}}} \\
    {\sigma(C_b(X))}
    \arrow["\beta", from=1-1, to=2-1]
    \arrow["\pi", from=1-1, to=1-2]
    \arrow["{\exists! \beta_{\pi}}"', dashed, from=2-1, to=1-2]
  \end{tikzcd}\]
\end{theorem}

\begin{myproof}
  \begin{enumerate}
    \item First, we prove that $\beta$ is continuous. If $(x_i)_i$ is a net in $X$ and $x_i \to x$.
    Then $\forall f \in C_b (X)$ we have $\beta_{x_i} = f(x_i) \to f(x) = \beta_x (f)$.
    Hence $\beta_{x_i} \to \beta_x$ in weak-* topology.
    \item Next, we prove that $\im \beta$ is dense. Assume otherwise and pick $\varphi \in \sigma(C_b (X)) \setminus \overline{\beta (x)}$.
    Define $I := \ker \varphi$. For all $\psi \in \overline{\beta (x)}$ there exists $f_{\psi} \in I$ such that $f_{\psi} \in \ker \psi$.
    Hence there exists $c_\psi$ and a neighborhood $U_{\psi}$ of $\psi$ such that $| \widetilde{\psi} (f)| > c_{\psi}$ for all $\widetilde{\psi} \in U_{\psi}$.
    Thus $\overline{\beta (x)} \subseteq U_{\psi \in \overline{\beta (x)}} U_{\psi}$.
    By compactness, there exists a finite subcovering of $\overline{\beta x}$, so $\overline{\beta x} \subseteq \bigcup_{i = 1} ^n U_{\psi_j}$.
    Then there exist $f_{\psi_1}, \dots, f_{\psi_n} \in I$ and $c > 0$ such that 
    $$\sum_{i = 1} ^n \psi (|f_{\psi_i}|^2) > c,\quad \forall \psi \in \overline{\beta x}.$$
    Hence $$\sum_{i = 1} ^n |f_{\psi_i}|^2 (x) = \sum_{i = 1} ^n \beta x (|f_{\psi_i}|^2) > c,\quad \forall x \in X.$$
    So $\sum_{i = 1} ^n |f_{\psi_i} |^2 \in I$ and $(\sum |f_{\psi_i}|^2)^{-1} \in C_b (X)$. As a result, $I = C_b (X)$.
    \item If $X$ is compact and Hausdorff, so $\beta$ is surjective since $\beta x$ is dense and compact.
    Also, $\beta$ is injective since $C_b (X)$ separate points. In that case, $\beta$ is a continuous bijection between compact Hausdorff spaces, therefore a homeomorphism.
    \item Now onto the universal property: let $\pi: X \to K$, where $K$ is compact Hausdorff.
    Then there exists a continuous map $$C(K) \xrightarrow{\pi^*} C_b (X),\quad f \mapsto f \circ \pi.$$
    This induces a continuous map 
    $$\widetilde{\pi}: \sigma(C_b (X)) \to \sigma (C(K)),\quad \varphi \mapsto \varphi \circ \pi^*.$$
    Since $K$ is compact Hausdorff, the map $\beta^K : K \to \sigma(C(K))$ is a homeomorphism.
    Define $$\beta_\pi: \sigma(C_b (X)) \to K,\quad \beta_{\pi} = (\beta^K)^{-1} \circ \widetilde{\pi}.$$
    Then we have 
    $$\widetilde{\pi} (\beta_x) (g) = \beta_x (\pi^* (g)) = \pi^* (g) (x) = g(\pi(x)) = \beta_{\pi(x)} ^K (g).$$
    By left multiplying by $(\beta^K)^{-1}$, we get $\beta_{\pi} (\beta_x) = \pi (x)$. \qedhere
  \end{enumerate}

\end{myproof}

\begin{definition}
  Let $A$ be an abelian Banach algebra. The Gelfand transform of $A$ is the map 
  $$\Gamma: A \to C(\sigma(A)),\quad x \mapsto (\varphi \mapsto \varphi(x)).$$
\end{definition}

\begin{theorem}
  Let $A$ be an abelian algebra. Then $\Gamma$ is a homomorphism, contraction and for 
  $x \in A$ we have $$\Gamma(x) \in GL(C(\sigma (A))) \Leftrightarrow x \in GL(A).$$
\end{theorem}

\begin{myproof}
  Homomorphism part is routine. We prove that $\Gamma$ is a contraction by following:
  \begin{align*}
    \| \Gamma(x)\| = \sup_{\varphi \in \sigma (A)} \| \Gamma(x) \varphi\| = \sup_{\varphi} |\varphi(x)| \leq \|x\|.
  \end{align*}
  We proceed onto the equivalence. The right implication $(\Rightarrow)$ is trivial, since 
  $$\Gamma(x^{-1}) \Gamma(x) = \Gamma(x^{-1} x) = \Gamma(1) = 1.$$
  Now the converse $(\Leftarrow)$: if $x \notin GL(A)$,
  then by the lemma $\exists \varphi \in \sigma(A)$, $\varphi(x) = 0$.
  Then $\Gamma(x) (\varphi) = \varphi(x) = 0$, so the continuous map $\Gamma(x)$ is not invertible.
\end{myproof}

\begin{corollary}
  Let $A$ be an abelian Banach algebra. Then 
  we have $$\sigma (\Gamma(x)) = \sigma (x)$$
  and $$\| \Gamma(x)\| = r (\Gamma(x)) = r(x).$$
\end{corollary}

\begin{theorem}[Gelfand]
  Let $A$ be an abelian $C^*$-algebra. Then $\Gamma$ is an isometric $*$-isomorphism.
\end{theorem}

\begin{myproof}
  For a self-adjoint $x \in A$ we have $\sigma (\Gamma(x)) = \sigma(x) \subseteq \R$.
  Then $\overline{\Gamma(x)} = \Gamma(x)$. An arbitrary $x \in A$ can be written as $x = a + ib$
  for self-adjoint $a= \frac{x + x^*}{2}$ and $b = \frac{i(x^* - x)}{2}$.
  Then $$\Gamma(x^*) = \Gamma(a - ib) = \Gamma(a) - i \Gamma(b) = \overline{\Gamma(a) + i \Gamma(b)} = \overline{\Gamma(x)}.$$
  This implies that $\Gamma$ is a *-homomorphism.
  Since $A$ is abelian, each $x \in A$ is normal so 
  $$\| x\| = r(x) = r(\Gamma(x)) = \|\Gamma(x)\|$$
  and $\Gamma$ is an isometry.
  In particular, $\Gamma$ is injective. We know that $\Gamma(A)$ is closed under $*$. Since $\Gamma$
  is isometric, $\Gamma(A)$ is a closed subalgebra in $C(\sigma(A))$ that separates points.
  By Stone-Weierstrass, $\Gamma(A) = C(\sigma(A))$.
\end{myproof}

\begin{remark}
  If $A$ is a $C^*$-algebra and $x \in A$ is normal, then the $C^*$-algebra generated by $x$, $C^*(x)$, is an abelian $C^*$-algebra.
\end{remark}

\begin{corollary}
  Let $A$ be an abelian $C^*$-algebra, generated by $x \in A$. Then $\sigma (A) \cong \sigma(x)$.
\end{corollary}

\begin{myproof}
  Let $\Gamma: A \to C(\sigma(A))$ be a Gelfand transform.
  Define $$\tau: \sigma(A) \to \sigma(x),\quad \varphi \mapsto \varphi(x) = \Gamma(x) (\varphi).$$
  Clearly, $\tau$ is well-defined, since $\varphi(x) \in \sigma (x),\ \forall x$.
  Next we show that $\tau$ is onto. For $\lambda \in \sigma(x)$,
  $x - \lambda \notin GL(A)$, so there exists $\psi \in \sigma(A)$ such that $\psi(x) - \psi (\lambda) = \psi (x - \lambda) = 0$.
  We show that $\tau$ is injective. Let $\tau (\varphi_1) = \tau(\varphi_2)$.
  Then $\varphi_1(x) = \varphi_2(x)$. Since 
  $$\varphi_j (x^*) = \Gamma(x^*) (\varphi_j) = \overline{\Gamma(x)(\varphi_j)} = \overline{\varphi_j(x)},$$
  we have $\varphi_1(x^*) = \varphi_2(x^*)$. Hence $\varphi_1 (p(x, x^*)) = \varphi_2(p(x, x^*))$, for every polynomial $p$.
  Since $\{p(x, x^*)\ |\ \textrm{$p$ polynomial}\}$ is by definition dense in $A$, we have $\varphi_1 = \varphi_2$.
  Finally, we prove the continuity of $\tau$. Let $(\varphi_\alpha)_{\alpha}$ is a net in $\sigma(A)$ such that $\varphi_\alpha \to \varphi$.
  Then $\varphi_\alpha(y) \to \varphi(y)$ for all $y \in A$, so in particular $\varphi_\alpha (x) \to \varphi(x)$,
  which proves $\tau (\varphi_\alpha) \to \tau(\varphi)$. Since $\tau$ is a continuous bijection between compact
  Hausdorff spaces, it is a homeomorphism.
\end{myproof}

\begin{remark}
  Since $\varphi \in \sigma(A)$ is an algebra homomorphism, we have $\varphi(p(x, x^*)) = p(\varphi(x), \overline{\varphi(x)})$
  for a complex polynomial $p(z, \overline{z})$ in $z$ and $\overline{z}$. Using the notation from above proof, 
  we get $\Gamma (p(x, x^*)) = p \circ \tau$.
\end{remark}

If $\tau$ is defined as in the previous proof, then $$\tau^{\#}: C(\sigma(x)) \to C(\sigma(A)),\quad f \mapsto f \circ \tau$$
is a $*$-isomorphism and an isometry. We know that $A = C^*(x)$ is closure of $\{p(x, x^*)\ |\ \textrm{$p (z, \overline{z})$ polynomial}\}$
and $\Gamma (p(x, x^*)) = \tau^{\#} (p)$. We define a map $\rho: C(\sigma(x)) \to C^*(x)$
so that the following diagram commutes:
\[\begin{tikzcd}
	{C^*(x)} && {C(\sigma(A))} \\
	& {C(\sigma(x))}
	\arrow["{\tau^{\#}}"', from=2-2, to=1-3]
	\arrow["\rho", from=2-2, to=1-1]
	\arrow["\Gamma", from=1-1, to=1-3]
\end{tikzcd}\]

\subsection{Continuous functional theorem}

If $A$ is any $C^*$-algebra and $x$ is a normal element of $A$, then $C^*(x)$
is an abelian $C^*$-algebra contained in $A$. Since the spectrum $\sigma(x)$
is independent of the $C^*$ algebra $C^*(x)$ or $A$, we can define a function
$\rho: C(\sigma(x)) \to C^*(x) \subseteq A$ and use the notation $f(x) := \rho(f)$.

\begin{theorem}
  Let $A, B$ be $C^*$-algebras and let $x \in A$ be normal.
  \begin{enumerate}
    \item $f \mapsto f(x)$ is a *-homomorphism $C(\sigma(x)) \to A$ and if 
    $$f = \sum_{j, k = 0} ^n a_{jk} z^j \overline{z}^k$$ is a polynomial, then 
    $$f(x) = \sum_{j, k = 0} ^n a_{jk} x^j (x^*)^k.$$
    In particular, if $f = z$ is the identity polynomial, then $f(x) = x$.
    \item For $f \in C(\sigma(x))$, then $\sigma(f(x)) = f(\sigma(x))$.
    \item If $\Phi: A \to B$ is a *-homomorphism, then $\Phi(f(x)) = f(\Phi(x))$.
    \item If $(x_n)_n$ is a sequence of normal elements of $A$ such that $\|x_n - x\| \to 0$
    and $\Omega$ is a compact neighborhood of $\sigma(x)$, $f \in C(\Omega)$, then for a 
    large enough $n$, $\sigma(x_n) \subseteq \Omega$ and $\|f(x_n) - f(x)\| \to 0$.
  \end{enumerate}
\end{theorem}

\begin{myproof}
  The points (1), (2) follow directly from Gelfand theorem and properties of continuous functions  
  on compact sets. The point (3) is obvious for polynomials $f$ and the general case follows from Stone-Weierstrass.
  We prove the point (4). Let $C = \sup_n \|x_n\| < \infty$. First we need to show that 
  $\sigma(x_n) \subseteq \Omega$ for large enough $n$. If that weren't the case, then for every $n \in \N$ there would exist $N_n > n$
  such that there exists $\lambda_n \in \sigma(x_{N_n}) \setminus \Omega \subseteq \overline{B_C (0)}$.
  Thus there exists a convergent subsequence $(\lambda_{n_k})_k$ such that $\lambda_{n_k} \to \lambda \in U$,
  where $U$ is an open neighborhood of $\sigma(x)$
  and $\lambda \notin \sigma(x)$. But then $$\underbrace{x_{n_k} - \lambda_{n_k}}_{\notin GL(A)} \to \underbrace{x - \lambda}_{\in GL(A)},$$
  which contradicts the openness of $GL(A)$. For every $\varepsilon > 0$ there exists a polynomial $g: \Omega \to \C$ such that $\|f - g\|_{\infty} < \varepsilon$.
  Now \begin{align*}
    \limsup_{n} \|f(x_n) - g(x_n)\| &+ \|g(x_n) - g(x)\| + \|g(x) - f(x)\|\\
     &\leq 2 \cdot C \cdot \varepsilon + \limsup_{n} \|g(x_n) - g(x)\| \\
     &= 2 C\varepsilon.
  \end{align*}
  Since $\varepsilon$ was arbitrary, $\lim_{n \to \infty} \| f(x_n) - f(x)\| = 0$.
\end{myproof}

\subsection{Application of the continuous functional theorem}

\begin{definition}
  Let $A$ be a $C^*$-algebra and $x \in A$.
  \begin{itemize}
    \item $x$ is positive if $x = y^* y$ for some $y \in A$ ($x$ is a hernitian square). The set of positive elements is denoted $A_+$.
    \item $x$ is a projection if $x^2 = x^* = x$.
    \item $x$ is unitary if $x x^* = x^* x = 1$. The set of positive elements is denoted $U(A)$.
    \item $x$ is an isometry if $x^* x = 1$.
    \item $x$ is a partial isometry if $x^* x$ is a projection.
  \end{itemize}
\end{definition}

\begin{remark}
  The first three are automatically normal (the first two are even self-adjoint).
\end{remark}

The set $A_+$ induces a partial ordering on $A_{\sa}$: for two elements $a, b \in A_{\sa}$
we define $$a \leq b \Leftrightarrow b - a \in A_+.$$
We notice that $x^* A_+ x \subseteq A_+$ for any $x \in A$.
For any $a, b \in A_{\sa}$ and for any $x \in a$ we have 
$$a \leq b \Rightarrow x^* a x \leq x^* b x.$$

\begin{proposition}
  Let $A$ be a $C^*$-algebra and $x \in A$. Then $x$ is a linear combination of four unitaries.
\end{proposition}

\begin{myproof}
  Since $x = \real x + i \imag x$, where $\real x, \imag x \in A_{\sa}$,
  it's enough to show that every self-adjoint is a linear combination of two unitaries.
  Without loss of generality, assume $\| x\| \leq 1$, so $\sigma(x) \subseteq [-1, 1]$.
  Consider the continuous function $$f: [-1, 1] \to \mathbb{T},\quad z \mapsto z + i(1 - z^2)^{\frac{1}{2}}$$
  and by continuous functional theorem, $f(x) \subseteq A$ and because $f \cdot \overline{f} \equiv 1$
  on $[-1, 1]$, we have $f(x) f(x)^* = f(x)^* f(x) = 1$.
  So $f(x) = u$ is unitary and $x = \frac{1}{2} (x + x^*)$ is a linear combination of two unitaries. 
\end{myproof}

\begin{definition}
  Let $x \in A_{\sa}$. Then $\sigma(x) \subseteq \R$ and we can define 
  $$x_+ = \max \{0, z\} (x) \in A,\quad x_- = - \min \{0, z\} (x) \in A.$$
  Then $\sigma(x_+), \sigma(x_- ) \subseteq [0, \infty)$, $x = x_+ - x_-$
  and $x_+ x_- = x_- x_+ = 0$.
\end{definition}

\begin{lemma}
  Suppose $x, y \in A_{\sa}$ satisfy $\sigma(x), \sigma(y) \subseteq [0, \infty)$.
  Then $\sigma(x + y) \subseteq [0, \infty)$.
\end{lemma}

\begin{myproof}
  Let $a := \| x\|$ and $b := \|y\|$.
  From $x = x^*$ and $\sigma(x) \subseteq [0, a]$ we deduce $\sigma(a - x) \subseteq [0, a]$,
  where $\| a - x\| = r(a - x) \leq a$. Likewise, $\|b - y\| \leq b$.
  Then 
  \begin{align*}
    \sup_{\lambda \in \sigma(x + y)} \{a + b - \lambda\} &= r(a + b - (x + y))\\
    &= \|(a + b) - (x + y)\|\\
    &\leq \|a - x\| + \|b - y\|\\
    &\leq a + b. \qedhere
  \end{align*}
\end{myproof}

\begin{theorem}
  Let $A$ be a $C^*$-algebra and $x \in A$ normal.
  \begin{enumerate}
    \item $x = x^* \Leftrightarrow \sigma(x) \subseteq \R$;
    \item $x \in A_+ \Leftrightarrow \sigma (x) \subseteq [0, \infty)$;
    \item $x \in U(A) \Leftrightarrow \sigma(x) \subseteq \mathbb{T}$;
    \item $x^2 = x^* = x \Leftrightarrow \sigma(x) \subseteq \{0, 1\}$.
  \end{enumerate}
\end{theorem}

\begin{myproof}
  We prove the item (2). For the implication $\Leftarrow$, apply the function $\sqrt{\cdot}: [0, \infty) \to \R$.
  Then $$x = (\sqrt{x})^2 = (\sqrt{x})^* \cdot \sqrt{x} \in A_+.$$ Now the converse $(\Rightarrow)$.
  Suppose $x = y^* y$ for some $y \in A$. Write $x = x_+ - x_-$ and let $z := y \cdot x_-$.
  Then $$z^* z = x_- y^* y x_- = x_- x x_- = -x_-^3.$$
  From there we get 
  $$\sigma (z z^*) \subseteq \sigma(z^* z) \cup \{0\} \subseteq (-\infty, 0].$$
  Let $z = a + ib$ for $a, b \in A_{\sa}$. Then 
  $$z z^* + z^* z = 2 a^2 + 2b^2 \Rightarrow \sigma(z z^* + z^* z) \subseteq [0, \infty).$$
  From there we get $$\sigma (z^* z) = \sigma((2 a^2 + 2b^2) - z z^*) \subseteq [0, \infty).$$
  This implies that $$\sigma(-x_-^3) = \sigma(z^* z) \subseteq \{0\},$$
  so $x_-^3 = 0$ and $x_- = 0$. This proves that $x = x_+$ has nonnegative spectrum.
\end{myproof}

\begin{corollary}
  Let $A$ be a $C^*$-algebra and $x \in A$. Then $x$ is a partial isometry iff $x^*$ is a partial isometry.
\end{corollary}

\begin{myproof}
  \begin{align*}
    \textrm{$x$ partial isometry} &\Leftrightarrow \textrm{$x^*x$ projection}\\
    &\Leftrightarrow {\sigma(x^* x) \subseteq \{0, 1\}}\\
    &\Leftrightarrow \sigma(x x^*) \subseteq \{0, 1\}\\
    &\Leftrightarrow \textrm{$xx^*$ projection}\\
    &\Leftrightarrow \textrm{$x^*$ partial isometry}. \qedhere
  \end{align*}
\end{myproof}

\begin{corollary}
  Let $A$ be a $C^*$-algebra.
  \begin{enumerate}
    \item $A_+$ is a closed convex cone ($\lambda A_+ \subseteq A_+$ for $\lambda \in \R_{\geq 0}$).
    \item If $a \in A_{\sa}$, then $a \leq \|a\|$.
  \end{enumerate}
\end{corollary}

\begin{proposition}
  Let $A$ be a $C^*$-algebra and $x, y \in A_+$.
  \begin{enumerate}
    \item If $x \leq y$, then $\sqrt{x} \leq \sqrt{y}$ (in fact, this is true for any exponent $r \in [0, 1]$).
    \item If $x, y \in GL(A)$ and $x \leq y$, then $y^{-1} \leq x^{-1}$.
  \end{enumerate}
\end{proposition}

\begin{myproof}
  \begin{enumerate}
    \item Let us prove the second point first. Suppose $x, y \in GL(A)$.
    Then we have $y^{-\frac{1}{2}} x y^{-\frac{1}{2}} \leq 1$ and 
    \begin{align*}
      x^{\frac{1}{2}} y^{-1} x^{\frac{1}{2}} &\leq \| x^{\frac{1}{2}} y^{-1} x^{\frac{1}{2}}\|\\
      &= r(x^{\frac{1}{2}} y^{-1} x^{\frac{1}{2}})\\
      &= r(y^{-\frac{1}{2}} x y^{-\frac{1}{2}})\\
      &\leq 1,
    \end{align*}
    so multiplying on both sides by $x^{-\frac{1}{2}}$ we get $y^{-1} \leq x^{-1}$.
    \item Now we prove the first point:  
    \begin{align*}
      \|y^{-\frac{1}{2}} x^{\frac{1}{2}}\|^2 &= \|(y^{-\frac{1}{2}} x^{\frac{1}{2}}) (y^{-\frac{1}{2}} x^{\frac{1}{2}})^*\|\\
      &= \|y^{-\frac{1}{2}} x y^{-\frac{1}{2}}\|\\
      &\leq 1,
    \end{align*}
    which implies
    \begin{align*}
      y^{-\frac{1}{4}} x^{\frac{1}{2}} y^{-\frac{1}{4}} &\leq \|y^{-\frac{1}{4}} x^{\frac{1}{2}} y^{-\frac{1}{4}}\|\\
      &= r(y^{-\frac{1}{4}} x^{\frac{1}{2}} y^{-\frac{1}{4}})\\
      &= r(y^{-\frac{1}{2}} x^{\frac{1}{2}})\\
      &= \| y^{-\frac{1}{2}} x^{\frac{1}{2}} \| \leq 1, 
    \end{align*}
    so multiplying on both sides by $y^{\frac{1}{4}}$ we get $y^{\frac{1}{2}} \leq x^{\frac{1}{2}}$ 
    For general non invertible $x, y$, pick $\varepsilon > 0$ and notice that 
    $$0 \leq x + \varepsilon \leq y + \varepsilon$$ and $x + \varepsilon, y + \varepsilon \in GL(A)$.
    By the above, $(x + \varepsilon)^{\frac{1}{2}} \leq (y + \varepsilon)^{\frac{1}{2}}$ and we send $\varepsilon \to 0$
    to get $x^{\frac{1}{2}} \leq y^{\frac{1}{2}}$.
    \qedhere.
  \end{enumerate}
\end{myproof}

\begin{remark}
  Let $I \subseteq \R$ and $f: I \to \R$ continuous. Then the function $f$ is operator monotone 
  iff for every $C^*$-algebra $A$ and $a, b \in A_{\sa},\ a \leq b,\ \sigma(a), \sigma(b) \subseteq I$ we have $f(a) \leq f(b)$.
  By the above proposition, $\sqrt{z}$ and $\frac{1}{z}$ are operator monotone on $[0, \infty)$,
  while $z^2$ for example isn't.
\end{remark}

\begin{definition}
  Absolute value of $x \in A$ is $$|x| = (x^* x)^{\frac{1}{2}} \in A_+.$$
\end{definition}

\begin{corollary}
  For $x, y \in A$ we have $|xy| \leq \|x\| |y|.$
\end{corollary}

\begin{myproof}
  Notice that 
  $$|xy|^2 = y^* x^* x y \leq y^* \|x^* x\| y = \|x\|^2 (y^* y)$$
  and now apply the operator-monotone $\sqrt{\cdot}$ and the previous proposition.
\end{myproof}

\begin{example}
  Let $A$ be a $C^*$-algebra. 
  \begin{enumerate}
    \item $\ext (A_+)_1 = \{\textrm{projections in $A$}\}$.
    \item $\ext (A)_1 \subseteq \{\textrm{partial isometries in $A$}\}$.
    \item $\ext (A_{\sa})_1 = U(A) \cap A_{\sa}$.
  \end{enumerate}
\end{example}

\begin{myproof}
  \begin{enumerate}
    \item Let $x \in (A_+)_1$. Then $x^2 \leq 2x$ since $z^2 - 2z \leq 0$ on $[0, 1] = \sigma(x)$.
    So $x = \frac{1}{2} x^2 + \frac{1}{2} (2x - x^2)$.
    If $x$ is an extreme point, then $x = x^2$ and $x \in A_+ \subseteq A_{\sa}$, so $x$ is an projection.
    For the converse we firstly assume $A$ is abelian, which means $A = C(K)$
    for a compact $K$ (by Gelfand). If $x \in A = C(K)$ is a projection, then $x = \chi_{E}$
    for some clopen $E \subseteq K$. Since $\ext [0, 1] = \{0, 1\}$, $\chi_E$ is an extreme point.
    Let $A$ now be a general $C^*$-algebra and $p \in A^*$ a projection. Suppose $p = \frac{1}{2} (a + b)$
    for some $a, b \in (A_+)_1$. Then $\frac{1}{2} a = p - \frac{1}{2} b \leq p$.
    Hence 
    $$0 \leq (1 - p)a(1 - p) \leq (1 - p) 2p (1 - p) = 0,$$
    so $$(\sqrt{a} (1 - p))^* (\sqrt{a} (1 - p)) = (1 - p)a(1 - p) = 0$$
    and $\sqrt{a} (1 - p) = 0$. This implies that $a (1 - p) = 0$, so 
    $$ap = a = a^* = (ap)^* = p^* a^* = pa.$$
    Similarly, we can show that $a, b, p$ all commute, so the $C^*$-subalgebra $C^*(a, b, p)$ is abelian and we just use the previous observation.
    \item Suppose $x \in (A)_1$ is not a partial isometry (alternatively, $x^* x$ is not a projection).
    First, we notice that $\| x^* x\| = \|x\|^2 \leq 1$. Since it is not a projection, $\sigma(x^* x) \subseteq (0, 1)$.
    Then we apply continuous functional calculus to obtain a function $f: \sigma(x^* x) \to [0, 1]$ such that 
    $|t (1 \pm f(t))^2| \leq 1$ for $t \in \sigma(x^* x)$ ($f$ can be a small bump function on an interval $[a, b] \subseteq (0, 1)$ where $[a, b] \cap \sigma(x^* x) \neq \emptyset$).
    Then $y := f(x^* x) \in A_+$ gives us $yx^* x \neq x^* x y \neq 0$
    and $\|x^* x (1 \pm y)^2\| \leq 1$. Then $\|x (1 \pm y)\|^2 \leq 1$ and 
    $$x = \frac{1}{2} ((x + xy) + (x - xy)) \notin \ext(A)_1.$$
    \item If $u \in U(A) \in (A_{\sa})$, then $x \mapsto ux$ is an isometry and as in the case $\mathcal{B}(\mathcal{H})$,
    $u$ is an extreme point, so $A_{\sa} \cap U(A) \subseteq \ext (A_{\sa})_1$. For the converse, assume 
    $x \in \ext (A_{\sa})_1$ and $x_+ = \frac{1}{2} (a + b)$ for $a, b \in (A_+)_{1}$. Then 
    $$0 = x_- x_+ x_- = \frac{1}{2} (x_- a x_- + x_- b x_-) \geq 0.$$
    So from $x_- a x_- = 0$, we get $(\sqrt{a} x_-)^* (\sqrt{a} x_-) = 0$, from there it follows that $\sqrt{a} x_- = 0$
    and $a x_- = 0$. Likewise, $x_- a = b x_- = x_- b = 0$. By Gelfand, the commutative $C^*$-algebra $C^*(a, b, x_-)$
    is isometrically $*$-isomorphic to $C(K)$ for some compact $K$, so $a$ and $x_-$ are functions such that for every point in $K$,
    at least one of them is zero. So $a - x_-$ is above bounded by $1$ and we have $a - x_- \in (A_{\sa})_1$.
    Similarly, $b - x_- \in (A_{\sa})_1$, so $$x = \frac{1}{2}((a - x_-) + (b - x_-)) \in (A_{\sa})_1.$$
    But since $x$ is an extreme point, we have $a - x_- = b - x_-$ and $a = b = x_+$.
    So $x_+ \in \ext (A_+)_1$ is a projection by (i) and by symmetry, so is $x_-$. Now we prove that $x$ is unitary:
    $$x^* x = x^2 = (x_+ - x_-)^2 = x_+ ^2 + x_- ^2 = x_+ + x_- = |x|.$$
    This implies that $|x|$ is a projection. Now set $q := 1 - |x|$.
    Then $x + q$ and $x - q$ are both in $(A_{\sa})_1$, so 
    $$x = \frac{1}{2} ((x + q) + (x - q))$$
    gives us $q = 0$, which further implies $|x| = 1$ and $x^* x = x x^* = 1$. \qedhere
  \end{enumerate}
\end{myproof}

\section{Representations of $C^*$-algebras and states}

\subsection{States}

Let $A$ be a $C^*$-algebra, then $A^*$ can be given an $A$-bimodule 
structure: if $\psi \in A^*$ and $a, b \in A$, then 
$$(a \cdot \psi \cdot b)(x) = \psi(bxa),\quad \forall x \in A.$$
We have 
\begin{align*}
  \| a \cdot \psi \cdot b\| = \sup_{x \in (A)_1} \| \psi (bxa)\| \leq \sup_{x \in (A)_1} \| \psi \| \|bxa\| \leq \| \psi\| \| a\| \|b\|.
\end{align*}

\begin{definition}
  Let $A$ be a $C^*$-algebra and $\varphi \in A^*$.
  \begin{itemize}
    \item We say that $\varphi$ is positive if $\varphi(x) \geq 0$, $\forall x \in A_+$.
    If $\varphi$ is positive and $a \in A$, then $a \varphi a^*$ is also positive.
    \item A positive element $\varphi \in A^*$ is faithful if $\varphi(x) \neq 0$, $\forall x \in A_+ \setminus \{0\}$.
    \item An element $\varphi \in A^*$ is a state if it is positive and $\| \varphi \| = 1$.
    The set of states is denoted $S(A) \subseteq (A^*)_1$.
  \end{itemize}
\end{definition}

\begin{remark}
  The set $S(A)$ is compact Hausdorff in the weak-* topology.
\end{remark}

We notice that if $\varphi \in A^*$ is positive and $x \in A_{\sa}$,
then $$\varphi(x) = \varphi(x_+ - x_-) = \varphi (x_+) - \varphi(x_-) \in \R.$$
If $y \in A$, then $y = y_1 + i y_2$, where $y_1, y_2$ are self-adjoint.
Then \begin{align*}
  \varphi(y^*) &= \varphi((y_1 + i y_2)^*) = \varphi (y_1 - i y_2)\\
  &= \varphi (y_1) - i \varphi(y_2) = \overline{\varphi(y_1) + i \varphi (y_2)}\\
  &= \overline{\varphi (y_1 + i y_2)} = \overline{\varphi(y)}
\end{align*}
Such a functional $\varphi \in A^*$ is called hermitian.
For any $\varphi \in A^*$, define $\varphi^* (y) = \overline{\varphi(y^*)}$.
Then $\varphi + \varphi^*$ and $i(\varphi - \varphi^*)$ are hermitian.
One can, of course, define these notions for unbounded linear functionals.
However, positivity implies continuity: for every $a \in A_{\sa}$ we have 
$-\| a\| \cdot 1 \leq a \leq \| a\| \cdot 1$, which implies
$$-\| a\| \varphi(1) \leq \varphi(a) \leq \| a\| \varphi(1)$$
and $\varphi$ is bounded.
For $a \in A$, we can of course write $a = b + ic$ for $b, c \in A_{\sa}$.
Here, $\|b\| \leq \|a\|$ and $\|c\| \leq \|a\|$. Let $\varphi(1) = C$.
Then 
$$|\varphi(a)|^2 = |\varphi(b) + i\varphi(c)|^2 = \varphi(b)^2 + \varphi(c)^2 \leq C^2 (\|b\|^2 + \|c\|^2) \leq 2 C^2 \|a\|^2.$$

\begin{lemma}
  Let $\varphi \in A^*$ be positive. Then $\forall x, y \in A$:
  $$|\varphi(y^* x)|^2 \leq \varphi (y^* y) \cdot \varphi(x^* x).$$
\end{lemma}

\begin{myproof}
  Consider the sesquilinear form
  $\langle x, y \rangle = \varphi (y^* x)$.
  Since $\varphi$ is positive, this is a positive sesquilinear form and we can apply Cauchy-Schwartz. 
\end{myproof}

\begin{theorem}
  An element $\varphi \in A^*$ is positive iff $\| \varphi \| = \varphi(1).$
\end{theorem}

\begin{remark}
  This implies that the set of states $S(A)$ is convex.
\end{remark}

\begin{myproof}
  First we prove the right implication $(\Rightarrow)$. We know that $x^* x \leq \|x^* x\|$, so 
  \begin{align*}
    |\varphi(x)|^2 &\leq \varphi(1) \varphi(x^* x)\\
    &\leq \varphi(1) \varphi(\| x^* x\|)\\
    &= \varphi(1)^2 \|x^* x\|\\
    &= \varphi(1)^2 \|x\|^2,
  \end{align*}
  so $|\varphi(x)| \leq \varphi(1) \|x\|$. From there we get $\| \varphi \| \leq \varphi(1) \leq \|\varphi\|$,
  so $\varphi(1) = \| \varphi \|$. Now the converse $(\Leftarrow)$. Suppose $x \in A_+$ and $\varphi (x) = \alpha + i \beta.$
  For each $t \in \R$, we have 
  \begin{align*}
    \alpha^2 + (\beta + t \|\varphi\|)^2 &= |\alpha + i (\beta + t \varphi(1))|^2\\
    &= |\varphi (x + it)|^2\\
    &= \| x + it\|^2 \cdot \|\varphi\|^2 \\
    &\leq \left( \|x\|^2 + t^2 \right) \|\varphi\|^2. 
  \end{align*}
  From this it directly follows $2 \beta t \|\varphi\| \leq \|x\|^2 \cdot \|\varphi\|^2$.
  Since $t \in \R$ was arbitrary, we have $\beta = 0$ and $\varphi(x) = \alpha \in \R$.
  Lastly, we derive 
  \begin{align*}
    \| x\| \cdot \|\varphi\| - \varphi(x) &= \varphi(\|x\| - x)\\
    &\leq \|\|x\| - x\| \cdot \|\varphi\|\\
    &\leq \| x\| \cdot \| \varphi \|,
  \end{align*}
  so $\varphi(x) \geq 0$.
\end{myproof}

\begin{proposition}
  Let $A$ be a $C^*$-algebra and $x \in A$. Then $\forall \lambda \in \sigma(x)$ there exists a $\varphi \in S(A)$
  such that $\varphi(x) = \lambda$.
\end{proposition}

\begin{myproof}
  We know that $\C x + \C \cdot 1 \subseteq A$.
  Define $$\varphi_0 : \C x+ \C 1 \to \C,\quad \alpha x + \beta \mapsto \alpha \cdot \lambda + \beta.$$
  Since $\varphi_0 (\alpha x + \beta) \in \sigma(\alpha x + \beta)$, we have
  $$\|\varphi_0 \| \leq 1 = \varphi_0 (1),$$
  therefore $\|\varphi_0\| = 1$. Now we apply Hahn-Banach to get an extension $\varphi \in A^*$
  such that $\varphi\big|_{\C x + \C 1} = \varphi_0$ and $\| \varphi \| = 1 = \varphi(1)$,
  so $\varphi \in S(A)$.
\end{myproof}

\begin{proposition}\label{prop:2}
  Let $A$ be a $C^*$-algebra and $x \in A$.
  \begin{enumerate}
    \item $x = 0$ iff $\varphi (x) = 0,\ \forall \varphi \in S(A)$.
    \item $x \in A_{\sa}$ iff $\varphi (x) \in \R,\ \forall \varphi \in S(A)$.
    \item $x \in A_+$ iff $\varphi (x) \geq 0,\ \forall \varphi \in S(A)$.
  \end{enumerate}
\end{proposition}

\begin{myproof}
  \begin{enumerate}
    \item If $\varphi x = 0$ for all $\varphi \in S(A)$, then writing $x = x_1 + i x_2$
    for self-adjoint $x_1, x_2$ gives us 
    $$0 = \varphi(x) = \varphi(x_1) + i \varphi(x_2),$$
    which implies $\varphi(x_1) = \varphi(x_2) = 0$. For the converse implication,
    use the previous proposition to get $\sigma(x) = \{0\}$, which can only imply $x = 0$.
    \item If $\varphi(x) \in \R$ for all $\varphi \in S(A)$, then 
    $$\varphi(x - x^*) = \varphi(x) - \varphi(x^*) = \varphi(x) - \overline{\varphi(x)} = 0$$
    and we use the previous item to show that $x - x^*$. The converse implication follows from positiveness.
    \item If $\varphi(x) \geq 0$ for all $\varphi \in S(A)$, then $x \in A_{\sa}$
    by previous item and $\sigma(x) \subseteq [0, \infty)$, so $x \in A_+$.
    The converse once again follows from positiveness. \qedhere
  \end{enumerate}
\end{myproof}

\subsection{Gelfand-Naimark-Segal (GNS) construction}

\begin{definition}
  \begin{itemize}
    \item A representation of a $C^*$-algebra is a *-homomorphism $\pi: A \to \mathcal{B}(\mathcal{H})$
  for some Hilbert space $\mathcal{H}$. 
    \item If $\mathcal{K}^{\mathrm{closed}} \leq \mathcal{H}$ and $\pi(x) \mathcal{K} \subseteq \mathcal{K},\ \forall x \in A$ ($\mathcal{K}$ is invariant for $\pi$),
  then the restriction of $\pi$ to $\mathcal{K}$ is a subrepresentation.
    \item   If a representation has no other representations besides $\mathcal{K} = (0)$ and $\mathcal{K} = \mathcal{H}$
  (equivalently, $\pi(A)$ only has $(0)$ and $\mathcal{H}$ as closed invariant subspaces),
  then $\pi$ is called irreducible.
    \item Representations $\pi: A \to \bh$ and $\rho: A \to \mathcal{B} (\mathcal{K})$
  are equivalent if there exists a unitary $U: \mathcal{H} \to \mathcal{K}$ such that $$U \pi(x) = \rho(x) U,\quad \forall x \in A.$$
    \item Vector $\mu \in \mathcal{H}$ is cyclic (for a representation $\pi: A \to \bh$) if 
    $$\pi (A) \mu := \{\pi(a) \mu\ |\ a \in A\}$$
    is dense in $\mathcal{H}$ (this means that $\overline{\pi (A) \mu} = \mathcal{H}$).
  \end{itemize}
   
\end{definition}

\begin{example}
  Each $w \in \mathcal{H}$ define a subrepresentation in $K := \overline{\pi (A) w}$.
\end{example}

\begin{example}
  Let $\pi: A \to \bh$ be a representation and $\mu \in \mathcal{H}$, $\| \mu \| = 1$.
  Then $$\varphi_\mu : A \to \C,\quad x \mapsto \langle \pi (x) \mu, \mu \rangle$$
  is a state. Indeed, 
  $$\varphi_\mu (1) = \langle 1 \cdot \mu, \mu \rangle = \| \mu \|^2 = 1$$
  and 
  \begin{align*}
    \varphi_\mu (x^* x) &= \langle \pi(x^* x) \mu, \mu \rangle\\
    &= \langle \pi (x^*) \pi (x) \mu, \mu \rangle\\
    &= \langle \pi (x)^* \pi (x) \mu, \mu\rangle \\
    &= \langle \pi (x) \mu, \pi(x) \mu \rangle\\
    &= \| \pi(x) \mu \|^2 \geq 0.
  \end{align*}
\end{example}

\begin{theorem}[GNS construction]
  Let $A$ be a $C^*$-algebra and $\rho \in S(A)$.
  Then there exists a Hilbert space $L^2 (A, \varphi)$ and a unique (up to equivalence)
  representation $\pi : A \to \mathcal{B} (L^2 (A, \varphi))$ and a unit cyclic vector $1_{\varphi}$
  such that $$\varphi(x) = \langle \pi(x) 1_{\varphi} , 1_{\varphi} \rangle,\quad \forall x \in A.$$
\end{theorem}

\begin{myproof}
  \begin{enumerate}
    \item We start by defining $$N_\varphi = \{x \in A\ |\ \varphi(x^* x) = 0\}$$
    whose elements we call nullvectors of $\varphi$. By Cauchy-Schwartz lemma, we have 
    $$N_\varphi = \{x \in A\ |\ \varphi(yx) = 0,\ \forall y \in A\}.$$
    Thus $N_\varphi$ is a closed subspace of $A$.
    \item We prove that $N_\varphi$ is a left ideal: for $x \in N_\varphi$ and $a \in A$, we have $ax \in N_\varphi$.
    Indeed, 
    $$\varphi ((ax)^* ax) = \varphi ((x^* a^* a) x) = 0.$$
    \item Now $\mathcal{H}_0 = \quot{A}{N_\varphi}$ is a vector space and we can endow it with the dot product 
    $\langle [x], [y] \rangle := \varphi(y^* x)$ for $x, y \in A$. It can easily be checked that this is a well-defined dot product in $\mathcal{H}_0$.
    We denote the completion of $\mathcal{H}_0$  by $L^2 (A, \varphi)$.
    \item To an arbitrary $a \in A$, we associate the map 
    $$\pi_0 (a) : \mathcal{H}_0 \to \mathcal{H}_0,\quad [x] \mapsto [ax].$$
    Since $N_\varphi$ is a left ideal of $A$, $\pi_0 (a)$ is a well-defined linear map.
    \begin{align*}
      \| \pi_0 (a) [x]\|^2 &= \| [ax]\|^2\\
      &= \langle [ax], [ax]\rangle\\
      &= \varphi ((ax)^* ax)\\
      &= \varphi(x^* a^* a x)\\
      &\leq \| a\|^2 \cdot \varphi(x^* x) \leq \| a\|^2 \|x\|^2.
    \end{align*}
    Since $\pi_0 (a)$ is continuous, it exdends uniquely to $\pi (a) \in \mathcal{B}(L^2 (A, \varphi))$
    with $\| \pi(a)\| \leq \| a\|$. Then we get $$\pi: A \to \mathcal{B} (L^2 (A, \varphi)),\quad a \mapsto \pi(a),$$
    which is a homomorphism and has the property 
    \begin{align*}
      \langle [x] , \pi(a^*) [y]\rangle &= \langle [x], [a^* y]\rangle\\
      &= \varphi((a^* y)^* x)\\
      &= \varphi(y^* ax)\\
      &= \langle [ax], [y] \rangle\\
      &= \langle \pi(a) [x], [y]\rangle.
    \end{align*}
    So $\pi(a) ^* = \pi(a^*)$ and $\pi$ is a representation.
    \item We define $1_\varphi := [1] \in \mathcal{H}_0 \subseteq L^2 (A, \varphi)$
    and notice that 
    $$\langle \pi(a) 1_\varphi, 1_\varphi \rangle = \langle \pi(a) [1], [1] \rangle = \langle[a], [1] \rangle = \varphi(a).$$
    Since $\{\pi (a) 1_\varphi\ |\ a \in A\} = \mathcal{H}_0$, the vector $1_\varphi$ is cyclic for $\pi$.
    \item Next we prove uniqueness: let $\rho: A \to \mathcal{B} (\mathcal{K})$ be a representation, $\mu \in \mathcal{K}$ a unit cyclic vector and 
    assume $\varphi(a) = \langle \rho(a)\mu, \mu\rangle,\ \forall a \in A$.
    We will prove that $\rho$ is equivalent to $\pi$. Define 
    $$U_0 : \mathcal{H}_0 \to \mathcal{K},\quad [x] \mapsto \rho(x) \mu.$$
    Then we have 
    \begin{align*}
      \langle U_0 [x], U_0 [y] \rangle_{\mathcal{K}} &= \langle \rho (x) \mu, \rho(y) \mu \rangle\\
      &= \langle \rho(y) ^* \rho(x)\mu, \mu \rangle\\
      &= \langle \rho (y^* x) \mu, \mu\rangle = \varphi(y^* x) = \langle [x], [y] \rangle_{L^2 (A, \varphi)},
    \end{align*}
    so $U_0$ really is a well-defined isometry. For all $a, x \in A$:
    $$U_0 (\pi (a) [x]) = U_0 ([ax]) = \rho (ax) \mu = \rho(a) \rho(x) \mu = \rho(a) U_0 [x].$$
    Therefore, $U_0$ induces an isometry $U: L^2 (A, \varphi) \to \mathcal{K}$
    such that $U\pi(a) = \rho (a) U$ for all $a \in A$. Since $\mu$ is cyclic and $\rho(a) \mu \subseteq \im U$, it is dense in $\mathcal{K}$.
    It is also closed since $U$ is isometric. We just proved that $U$ is isometric and onto, so it is unitary. \qedhere
  \end{enumerate}
\end{myproof}

\begin{corollary}
  Every $C^*$-algebra has a faithful (i.e. injective) representation. In particular, every $C^*$-algebra is isometrically *-isomorphic to a closed subalgebra of $\mathcal{B} (H)$
  for some Hilbert space $\mathcal{H}$.
\end{corollary}

\begin{myproof}
  Let $\pi$ be a direct sum of all representations from GNS construction over all states. Then the proposition \ref{prop:2} tells us that $\pi$ is injective. 
  An injective *-monomorphism is isometric and we are done.
\end{myproof}

\begin{definition}
  If $S \subseteq A$, then $$S' := \{x \in A\ |\ \forall s \in S:\ xs = sx\}$$
  is a commutant.
\end{definition}

\begin{proposition}[Radon-Nikodym for linear functionals]
  Let $\varphi, \psi$ be positive linear functionals on a $C^*$-algebra $A$ and $\varphi \in S(A)$.
  Then $\varphi \leq \psi$ iff there exists a unique $y \in \pi_{\psi} (A)'$ such that $0 \leq y \leq 1$
  and $$\varphi(a) = \langle \pi_{\psi} (a) y 1_{\psi}, 1_{\psi} \rangle,\quad \forall a \in A.$$
\end{proposition}

\begin{myproof}
  Start with $(\Leftarrow)$. For $a \in A_+$ we have 
  $$\pi_{\psi} (a) y = \pi_{\psi} (a)^{\frac{1}{2}} y \pi_{\psi} (a) ^{\frac{1}{2}} \leq \pi_{\psi} (a).$$
  Then 
  $$\varphi(a) = \langle \pi_{\psi} (a) y 1_{\psi}, 1_{\psi} \rangle \leq \langle \pi_{\psi} (a) 1_{\psi}, 1_{\psi}\rangle = \psi(a).$$
  Now the opposite $(\Rightarrow)$. By Cauchy-Schwartz,
  \begin{align*}
    \varphi (b^* a)|^2 &\leq \varphi(a^* a) \varphi(b^* b)\\
    &\leq \psi (a^* a) \psi (b^* b)\\
    &= \| \pi_{\psi} (a) 1_{\psi} \|^2 \cdot \| \pi_{\psi} (b) 1_{\psi} \|^2.
  \end{align*}
  This means that $\langle \pi_{\psi} (a) 1_{\psi}, \pi_{\psi} (b) 1_{\psi}\rangle_{\varphi} := \varphi (b^* a)$ is a nonnegative sesquilinear form on 
  $\pi_{\varphi} (A) 1_{\psi}^{\mathrm{dense}} \subseteq L^2 (A, \psi)$, which is bounded by $1$.
  This further implies that it is continuous and we can extend it to $L^2 (A, \psi)$.
  By Riesz, there exists $y \in \mathcal{B} (L^2 (A, \psi))$ such that 
  $$\varphi(b^* a) = \langle y \pi_{\psi} (a) 1_{\psi} , \pi_{\psi} (b) 1_{\psi} \rangle,\quad \forall a, b \in A$$
  and $0 \leq y \leq 1$. For $a, b, c \in A$ we have 
  \begin{align*}
    \langle y \pi_{\psi} (a) \pi_{\psi} (b) 1_{\psi}, \pi_{\psi} (c) 1_{\psi}\rangle &= \langle y \pi_{\psi} (ab) 1_{\psi}, \pi_{\psi} (c) 1_{\psi} \rangle\\
    &= \varphi(c^* \cdot ab) = \varphi ((a^* c)^* b)\\
    &= \langle y \pi_{\psi} (b) 1_{\psi}, \pi_{\psi} (a^*) \pi_{\psi} (c) 1_{\psi}\rangle\\
    &= \langle \pi_{\psi} (a) y \pi_{\psi} (b) 1_{\psi}, \pi_{\psi} (c) 1_{\psi}\rangle,
  \end{align*}
  so $y \pi_{\psi} (a) = \pi_{\psi} (a) y$ for all $a \in A$ and $y \in \pi_{\psi} (A) '$.
  Finally, the uniqueness. Say that there exists a $z \in \pi_{\psi} (A)'$ such that $0 \leq z \leq 1$ and 
  $$\langle \pi_{\psi} (a) y 1_{\psi}, 1_{\psi} \rangle = \langle \pi_{\psi} (a) z 1_{\psi}, 1_{\psi} \rangle,\quad \forall a \in A.$$
  Then 
  \begin{align*}
    \langle \pi_{\psi} (b^* a) z 1_{\psi}, 1_{\psi} \rangle &= \langle \pi_{\psi} (b^* a) y 1_{\psi}, 1_{\psi} \rangle \\
    &= \langle y \pi_{\psi} (a) 1_{\psi}, \pi_{\psi} (b) 1_{\psi} \rangle\\
    &= \langle z \pi_{\psi} (a) 1_{\psi}, \pi_{\psi} (b) 1_{\psi} \rangle,  
  \end{align*}
  which implies $y = z$.
\end{myproof}

\begin{proposition}
  Suppose that $A$ is a separable $C^*$-algebra. Then $A$ has a faithful
  cyclic representation on a separable Hilbert space.
\end{proposition}

\begin{myproof}
  If $A$ is separable, then it has a dense subset $\{a_i\}_{i = 1} ^\infty$.
  We can embed $S(A)$ into a space $\prod_{i = 1} ^\infty \overline{B_1 (0)}$, where $\overline{B_1 (0)}$
  is a closed unit ball in $\C$. The latter topological space is metrizable by metric $\rho (x, y) = \sum_{i = 1} ^\infty \frac{\rho_i (x_i, y_i)}{2^i (\rho_i (x_i, y_i) + 1)}$,
  and so is $S(A)$. Therefore, $S(A)$ with the weak-* topology is a metrizable compact, therefore separable.
  Let $\{f_i\}_i ^{\infty}$
  countable weak-* dense subset of $S(A)$. Then 
  $$f(a) := \sum_{i = 1} ^{\infty} 2^{-i} f_i (a)$$
  defines a faithful ($f(a^* a) = 0$ iff $a = 0$) state on $A$.
  Then the GNS construction $\pi_f$ is faithful: if $\pi_f (a) = 0$, then 
  $$f(b^* a^* a b) = \langle \pi_f (a) [b], \pi_f (a) [b] \rangle = 0$$
  for every $b \in A$. In particular for $b = 1$, we get $f(a^* a) = 0$ and so $a = 0$.
  Since $a \mapsto [a]$ is 
a continuous map of $A$ onto a dense subspace of some Hilbert space $\mathcal{H}_f$ (induced by $\pi_f : A \to \mathcal{B}(\mathcal{H}_f)$), the latter space is
separable.
\end{myproof}

\begin{proposition}
  Every representation of a $C^*$-algebra is equivalent to a direct sum of cyclic representations.
\end{proposition}

\begin{myproof}
  Let $\pi: A \to \bh$ be some representation of $A$.
  Let $\mathcal{E}$ be the collection of all subsets $E$ of nonzero vectors in $\mathcal{H}$
  such that $\pi(A) e \perp \pi(A)f$ for any $e, f \in E$. If we order $\mathcal{E}$ by inclusion, 
  then Zorn's lemma tells us that $\mathcal{E}$ has a maximal element $E_0$.
  Let $\mathcal{H}_0 = \bigoplus_{e \in E_0} \overline{\pi(A) e}$. Take $h \in \mathcal{H}_0 ^{\perp}$ in $\mathcal{H}$.
  Then for any $a, b \in A$ and $e \in E_0$ we have 
  $$\langle \pi(a) e, \pi(b) h \rangle = \langle \pi(b) ^* \pi (a) e, h \rangle = \langle \pi(b^* a) e, h\rangle = 0,$$
  so $\pi(A)e \perp \pi(A)h$ for each $e \in E_0$. By maximality, $h = 0$ and $\mathcal{H} = \mathcal{H}_0$.
  For $e \in E_0$, define $\mathcal{H}_e := \overline{\pi(A) e}$.
  Obviously, $\mathcal{H}_e$ is invariant for $\pi$, so $\pi_e := \pi\big|_{\mathcal{H}_e}$ is a cyclic representation of $A$.
  Clearly, $\pi = \bigoplus_{e\in E_0} \pi_e$.
\end{myproof}

\subsection{Pure states and irregular representations}

\begin{definition}
  A state $\varphi \in S(A)$ is called pure if it's an extreme point of $S(A)$.
\end{definition}

\begin{proposition}
  A state $\varphi \in S(A)$ is pure iff GNS $\pi_{\varphi}: A \to \mathcal{B} (L^2 (A, \varphi))$
  with a cyclic vector $1_{\varphi}$ is irreducible.
\end{proposition}

\begin{myproof}
  \begin{itemize}
    \item[$(\Rightarrow)$] Let $\mathcal{K} \leq L^2 (A, \varphi)$ be a closed invariant subspace.
    Then $\mathcal{K}^{\perp}$ is also a closed invariant subspace: for $a \in A$, $x \in \mathcal{K}^{\perp}$ and $k \in \mathcal{K}$ we have 
    $$\langle \pi_\varphi (a) x, k\rangle = \langle x, \pi_\varphi (a^*) k \rangle = 0.$$
    Since $L^2 (A, \varphi) = \mathcal{K} \oplus \mathcal{K}^\perp$ we write $1_\varphi = \underbrace{\mu_1}_{\in \mathcal{K}} + \underbrace{\mu_2}_{\in \mathcal{K}^\perp}$
    and form 
    $$\varphi_j := \frac{\langle \pi_\varphi (x) \mu_j, \mu_j \rangle}{\| \mu_j\|^2},\quad j = 1, 2.$$
    These are states and so is 
    $$\varphi(x) = \| \mu_1 \|^2 \varphi_1 (x) + \| \mu_2 \|^2 \varphi_2 (x)$$
    because $1 = \|1_\varphi\|^2 = \| \mu_1\|^2 + \|\mu_2\|^2$. Since $\varphi \in \ext S(A)$, we either have 
    $\mu_1 = 0$ or $\mu_2 = 0$, which implies that $\mathcal{K}$ is either $(0)$ or $\mathcal{H}$.
    \item[$(\Leftarrow)$] Suppose $\varphi = \frac{1}{2} (\varphi_1 + \varphi_2)$ for $\varphi_1, \varphi_2 \in S(A)$.
    Define a linear map 
    $$U: L^2 (A, \varphi) \to L^2 (A, \varphi_1) \oplus L^2 (A, \varphi_2),\quad \pi_\varphi(x) 1_\varphi \mapsto \frac{1}{\sqrt{2}} \pi_{\varphi_1}(x) 1_{\varphi_1} \oplus \frac{1}{\sqrt{2}} \pi_{\varphi_2} (x) 1_{\varphi_2}.$$
    First we notice that $U$ preserves scalar product:
    \begin{align*}
      \langle \pi_\varphi (x) 1_\varphi, \pi_\varphi (y) 1_\varphi \rangle &= \varphi (x^* y)\\
      &= \frac{1}{2} \varphi_1(x^* y) + \frac{1}{2} \varphi_2 (x^* y)\\
      &= \langle \frac{1}{\sqrt{2}} \pi_{\varphi_1} (x) 1_{\varphi_1} \oplus \frac{1}{\sqrt{2}} \pi_{\varphi_2} (x) 1_{\varphi_2}, \frac{1}{\sqrt{2}} \pi_{\varphi_1} (y) 1_{\varphi_1} \oplus \frac{1}{\sqrt{2}} \pi_{\varphi_2} (y) 1_{\varphi_2} \rangle\\
      &= \langle U \pi_\varphi (x) 1_\varphi, U \pi_\varphi (y) 1_\varphi \rangle
    \end{align*}
    Additionally, $U$ intertwines: for all $x \in A$, we have
    \begin{align*}
      U \pi_{\varphi}(x) (\pi_{\varphi} (y) 1_{\varphi}) &= U \pi_{\varphi} (xy) 1_{\varphi}\\
      &= \frac{1}{\sqrt{2}} \pi_{\varphi_1} (xy) 1_{\varphi_1} \oplus \frac{1}{\sqrt{2}} \pi_{\varphi_2} (xy) 1_{\varphi_2}\\
      &= \left(\pi_{\varphi_1} (x) \oplus \pi_{\varphi_2} (x)\right) (\pi_{\varphi_1} (y) 1_{\varphi_1} \oplus \pi_{\varphi_2} (y) 1_{\varphi_2})\\
      &= \left(\pi_{\varphi_1} (x) \oplus \pi_{\varphi_2} (x)\right) U (\pi_{\varphi} (y) 1_{\varphi}).
    \end{align*}
    If we star the intertwining identity, we get 
    \begin{equation*}
      \pi_{\varphi}(x^*) U^* = U^* \left(\pi_{\varphi_1} (x^*) \oplus \pi_{\varphi_2} (x^*)\right),\quad \forall x^* \in A.
    \end{equation*}
    If we plug in $x$ instead of $x^*$, we get 
    \begin{equation*}
      \pi_{\varphi}(x) U^* = U^* \left(\pi_{\varphi_1} (x) \oplus \pi_{\varphi_2} (x)\right),\quad \forall x \in A.
    \end{equation*}
    Now let $$p_1 \in \mathcal{B} (L^2 (A, \varphi_1) \oplus L^2 (A, \varphi_2))$$
    be orthogonal projection onto the first factor.
    Clearly, we have
    \begin{equation*}
      p_1 \left(\pi_{\varphi_1} (x) \oplus \pi_{\varphi_2} (x)\right) = \left(\pi_{\varphi_1} (x) \oplus \pi_{\varphi_2} (x)\right) p_1 
    \end{equation*}
    Putting it all together, we get 
    \begin{align*}
      \pi_{\varphi} (x) U^* p_1 U &= U^* (\pi_{\varphi_1} (x) \oplus \pi_{\varphi_2} (x)) p_1 U\\
      &= U^* p_1 (\pi_{\varphi_1} (x) \oplus \pi_{\varphi_2} (x)) U\\
      &= U^* p_1 U (\pi_{\varphi_1} (x) \oplus \pi_{\varphi_2} (x))
    \end{align*}
    so $U^* p_1 U$ commutes with $\pi_{\varphi} (x)$ for all $x \in A$.
    If $\sigma(U^* p_1 U)$ has more than one element, then $\exists t \in (0, 1]$
    such that $\sigma(U^* p_1 U - t)$ has both positive and negative elements.
    By CFC, we can write $U^* p_1 U = a - b$ for positive $0 \neq a, b$ such that $ab = ba = 0$.
    Then $a, b$ commute with $\pi_{\varphi} (A)$, so $\ker a \neq 0$ is an closed subspace of $L^2 (A, \varphi)$ that is invariant under $\pi_{\varphi} (x)$, which is a contradiction.
    So $U^* p_1 U$ has a single element spectrum $\{\alpha\}$ and since $U^* p_1 U$ is normal (because it is positive), so is $U^* p_1 U - \alpha I.$
    But now we can write 
    $$\| U^* p_1 U - \alpha I\| = r(U^* p_1 U) = 0,$$
    which proves that $U^* p_1 U = \alpha I$.
    Then
    \begin{align*}
      \alpha &= \alpha \varphi(1) = \varphi(\alpha)\\
      &= \langle \alpha 1_{\varphi}, 1_{\varphi} \rangle\\
      &= \langle U^* p_1 U 1_\varphi, 1_\varphi\rangle \\
      &= \left\langle \frac{1}{\sqrt{2}} 1_{\varphi_1} \oplus 0, \frac{1}{\sqrt{2}} 1_{\varphi_1} \oplus \frac{1}{\sqrt{2}} 1_{\varphi_2}\right\rangle \\
      &= \left\langle \frac{1}{\sqrt{2}} 1_{\varphi_1}, \frac{1}{\sqrt{2}} 1_{\varphi_1} \right\rangle _{\varphi_1} = \frac{1}{2}.
    \end{align*}
    This means that we can write 
    $$\left({\sqrt{2}} p_1 U \right)^* \left({\sqrt{2}} p_1 U \right) = 1,$$
    so $$u_1 = \frac{1}{\sqrt{2}} p_1 U : L^2 (A, \varphi) \to L^2 (A, \varphi_1)$$
    is an isometry. We also have the identities
    $$u_1 1_{\varphi} = 1_{\varphi_1},\quad u_1 \pi_{\varphi} (x) = \pi_{\varphi_1} (x) u_1.$$
    It follows that 
    \begin{align*}
      \varphi(x) &= \langle \pi_{\varphi} (x) 1_{\varphi}, 1_\varphi \rangle\\
      &= \langle u_1 ^* u_1 \pi_\varphi (x) 1_\varphi, 1_\varphi\rangle\\
      &= \langle u_1 ^* \pi_{\varphi_1} (x) u_1 1_\varphi, 1_\varphi\rangle\\
      &= \langle \pi_{\varphi_1} (x) u_1 1_\varphi, u_1 1_\varphi\rangle\\
      &= \langle \pi_{\varphi_1} (x) 1_{\varphi_1}, 1_{\varphi_1} \rangle = \varphi_1(x)
    \end{align*}
    and we are done. \qedhere
  \end{itemize}
\end{myproof}

\begin{theorem}
  A representation $\pi: A \to \bh$ if irreducible iff $\pi(A)' = \C \cdot \id$.
\end{theorem}

\begin{myproof}
  Start with $(\Leftarrow)$. Suppose there exists a closed invariant subspace $(0) \neq \mathcal{K} \lneqq \mathcal{H}$.
  Let $p \in \bh$ be the orthogonal projection onto $\mathcal{K}$.
  Then $p \notin \C \cdot \id$. Now we prove that $p \in \pi(A)'$.
  let $a \in A$. For $\mu \in \mathcal{K}$, we have 
  $$(p \pi(a)) \mu = p(\pi(a) \mu) = \pi(a) \mu = \pi(a) (p \mu) = (\pi (a) p) \mu.$$
  Now for $\mu \in \mathcal{K}^\perp$, we get 
  $$(p \pi(a)) \mu = p(\pi(a) \mu) = 0 = \pi(a) (0) = \pi(a) (p \mu) = (\pi(a) p) \mu.$$
  For the converse $(\Rightarrow)$, suppose there exists a non-scalar self-adjoint $h \in \pi(A)'$.
  Then $\sigma(h)$ has at least two elements. By CFC, there exist nonzero $f, g \in C(\sigma(h))$
  such that $fg = 0$. Then $f(h) \neq 0$ since $f \neq 0$.
  Then also $\mathcal{K} := \overline{\im f(h)} \leq \mathcal{H}$ is nonzero.
  Also, $g(h) \neq 0$ and $g(h)\big|_{\mathcal{K}} = 0$ since $g(h) \cdot f(h) = 0$.
  in particular, $\mathcal{K} \subsetneqq \mathcal{H}$. From $h \in \pi(A)'$, we deduce $f(h) \in \pi(A)'$.
  We claim that $\mathcal{K}$ is invariant; it's enough to show that $\im f(h)$ is invariant.
  For $a \in A, \mu \in \mathcal{H}$ we have  
  $$\pi (a) (f(h) \mu) = \pi(a) f(h) \mu = f(h) \pi(a) \mu \in \im f(h).$$
  In general, if $q \in \pi(A)'$, then $q^* \in \pi(A)'$ and we can reduce the problem to self-adjoint case above.
\end{myproof}

\begin{corollary}
  Irreps of abelian $C^*$-algebras are $1$-dimensional.
\end{corollary}

\begin{myproof}
  Let $A$ be an abelian $C^*$-algebra and $\pi: A \to \bh$ an irrep.
  Then by theorem, $\pi(A)' = \C$. Moreover,
  \begin{equation*}
    \pi(A) = Z(\pi(A)) = \pi(A)' \cap \pi(A) = \C \cdot \id.\qedhere
  \end{equation*}
\end{myproof}

\begin{corollary}
  If $A$ is an abelian $C^*$-algebra, then $\ext S(A) = \sigma(A)$.
\end{corollary}

\begin{myproof}
  Let $\sigma \in \sigma(A)$. Then $\sigma$ is $1$-dimensional (therefore irreducible) representation and so $\sigma \in \ext S(A)$.
  For the converse, take $\varphi \in \ext S(A)$. Then the GNS construction $\pi_{\varphi}$ is irreducible, therefore $1$-dimensional. So 
  $L^2 (A, \varphi) = \C$ with the standard scalar product and $\varphi (x) = \langle \pi_{\varphi}(x) 1_\varphi, 1_{\varphi}\rangle = \pi_{\varphi}(x)$.
\end{myproof}

\begin{proposition}
  Let $A$ be a $C^*$-algebra. Then $\co \ext S(A)$ is weak-* dense in $S(A)$.
\end{proposition}

\begin{myproof}
  We know that $S(A)$ is compact Hausdorff wrt the weak-* topology. The conclusion follows from Krein-Milman.
\end{myproof}

\begin{corollary}
  Let $A$ be a $C^*$-algebra and $x \in A\setminus (0)$. Then there exist an irrep $\pi: A \to \bh$
  such that $\pi(x) \neq 0$.
\end{corollary}

\begin{myproof}
  By proposition, there exists $\varphi \in S(A)$ such that $\varphi(x) \neq 0$.
  by previous proposition (Krein-Milman), there exists a $\tau \in \ext S(A)$ such that $\tau (x) \neq 0$.
  Then apply GNS: $\pi_{\tau}$ is irreducible and $\pi_{\tau} (x) \neq 0$.
\end{myproof}

\begin{theorem}[Jordan decomposition for linear functionals]
  Let $A$ be a $C^*$-algebra and $\varphi \in A^*$ hermitian. Then there exist (unique - without proof)
  positive linear functionals $\varphi_+, \varphi_- \in A^*$ such that $\varphi = \varphi_+ - \varphi_-$
  and $\| \varphi\| = \|\varphi_+\| = \| \varphi_-\|$.
\end{theorem}

\begin{myproof}
  WLOG $\| \varphi\| = 1$. Let $\Sigma$ denote the set of positive linear functionals with norm $ \leq 1$.
  By Banach-Alaoglu, $\Sigma$ is weak-* compact and Hausdorff.
  Consider $$\gamma: A \to C(\Sigma),\quad a \mapsto (\psi \mapsto \psi(a)).$$
  This is an isometry and $\gamma(A_+) \subseteq C(\Sigma)_+$.
  By Hahn-Banach, there exists a $\widetilde{\varphi}: C(\Sigma) \to \C$ such that $\| \widetilde{\varphi} \| = \| \varphi\|$
  and $\varphi = \widetilde{\varphi} \circ \gamma$.
  Assume $\widetilde{\varphi}$ is hermitian (otherwise, we can it by  $\frac{\widetilde{\varphi} + \widetilde{\varphi}^*}{2}$).
  By Riesz-Markoff, there exists a regular Radon Measure $\mu$ on $\Sigma$ such that $\widetilde{\varphi} (f) = \int f\, d\mu$ for all $f \in C(\Sigma)$.
  Then we use Jordan decomposition for measures to obtain $\mu_+, \mu_-$
  such that $\mu = \mu_+ - \mu_-$ and $\| \mu \| = \| \mu_+ \| = \| \mu_- \|$.
  Now we just define $\varphi_{\pm} (a) := \int a \, d\mu_{\pm}$.
\end{myproof}

\begin{corollary}
  For a $C^*$-algebra $A$, $A^*$ is the span of positive linear functionals on $A$.
\end{corollary}

\begin{corollary}
  Let $A$ be a $C^*$-algebra and $\varphi \in A^*$. Then there exists a representation $\pi: A \to \bh$
  and $\mu, \theta \in \mathcal{H}$ such that $\varphi(a) = \langle \pi(a) \theta, \mu \rangle$.
\end{corollary}

\begin{myproof}
  Unite $\varphi = \sum_{i = 1} ^n \alpha_i \psi_i$ for some $\psi_j \in S(A)$.
  Let $\pi_i$ be the GNS representation of $\psi_i$. Define $\pi := \bigoplus_i \pi_i$,
  $\theta := \bigoplus_i \alpha_i 1_{\psi_i}$ and $\mu = \bigoplus_i 1_{\psi_i}$.
  The result then follows immediately.
\end{myproof}

\subsection{Examples of $C^*$-algebras}

\begin{example}
  The most canonical example of a $C^*$-algebra is $\bh$.
  Similarly, the algebra of compact operators $\mathcal{K}(\mathcal{H})$ is a $C^*$-algebra 
  (if $\dim \mathcal{H} = \infty$, it is non-unital).
\end{example}

\begin{example}
  If $\dim \mathcal{H} = \infty$, then $\quot{\bh}{\mathcal{K}(\mathcal{H})}$ is a so-called Calkin algebra.
  It is simple and it does not have a separable representation.
\end{example}

\begin{example}
  The algebra of matrices $M_n (\C) = \mathcal{B}(\C^n)$ is a $C^*$-algebra.
\end{example}

\begin{proposition}[Artin-Wedderburn for $C^*$-algebras]
  Every finite-dimensional $C^*$-algebra $A$ is 
  $$ A \cong M_{n_1} (\C) \oplus \dots \oplus M_{n_r} (\C)$$
  for uniquely determined $n_1, \dots, n_r$.
\end{proposition}

\begin{myproof}
  Since $A$ is a finite-dimensional algebra over $\C$, it is artinian. It is enough to prove that it is $J$-semisimple.
  Denote $J = \rad A$, which is finitely-generated.
  By artinian property, the sequence 
  $$J \supseteq J^2 \supseteq J^3 \supseteq \dots$$
  has to stabilize somewhere, so assume $J^n = J^{n + 1}$.
  By Nakayama's lemma, we have $J \cdot J^{n} = J^n$, which implies $J^n = (0)$, so $J$ is nilpotent.
  Take any $a \in J$. Then $a^* a \in J$ and so $(a^* a)^n = 0$. Then we have 
  \begin{align*}
    0 = \| (a^* a)^{2^n} \| = \| a^* a\|^{2^n} = \| a\|^{2^{n + 1}}
  \end{align*}
  and $a = 0$. So $A$ is artinian and $J$-semisimple, therefore semisimple. Now we use Artin-Wedderburn for algebras,
  together with the fact that $\C$ is an algebraically-closed field, so any finite-dimensional division algebra over $\C$ is $\C$ itself.
\end{myproof}

Let $G$ be a group. Then the (complex) group algebra $\C [G]$ is the algebra with basis 
$\{u_g\ |\ g \in G\}$ and multiplication given by $u_g \cdot u_h = u_{gh}$.
Then $\C [G]$ has the involution 
$$\left(\sum_{g \in G} ^{\mathrm{finite}} a_g u_g\right)^* = \sum_g \overline{a_g} u_{g^{-1}}.$$
Multiplication is convolutive:
\begin{align*}
  \left(\sum_g a_g u_g\right) \left(\sum_h b_h u_h \right) &= \sum_{g, h} a_g b_h u_g u_h\\
  &= \sum_{g, h} a_g b_h u_{gh}\\
  &= \sum_k \left(\sum_g a_g b_{g^{-1} k}\right) u_k.
\end{align*}
To introduce norms on $\C[G]$ we use representations $\pi: \C [G] \to \bh$.
In such a case, we define the $C^*$-algebra 
$$C_{\pi} ^* (G) := \overline{\pi(\C [G])} \subseteq \bh.$$
For $g \in G$, we get 
\begin{align*}
  \pi(u_g) \pi(u_g) ^* &= \pi(u_g) \cdot \pi(u_g ^*)\\
  &= \pi(u_g) \cdot \pi(u_{g^{-1}})\\
  &= \pi(u_g \cdot u_{g^{-1}}) = \pi(u_e) = 1.
\end{align*}
Similarly, $\pi(u_g) ^* \pi(u_g) = 1$. Under any representation of $\C[G]$,
each $u_g$ is mapped to a unitary.

\begin{example}
  Take $\mathcal{H} = \ell^2 (G)$ (this is a Hilbert space with ONB $\{\delta_g\ |\ g \in G\}$).
  Then $$\lambda : \C [G] \to \mathcal{B} (\ell^2 (G)),\quad u_g \mapsto (\delta_h \mapsto \delta_{gh})$$
  is a faithful representation. We call it the left regular representation of $G$.
  The induced group $C^*$-algebra $C_r ^* (G) := \overline{\lambda(\C[G])} \subseteq \mathcal{B}(\ell^2 (G))$.
\end{example}

\begin{definition}
  Universal (or full) group $C^*$-algebra is $\C[G]$ where the norm of an element $a \in \C[G]$
  is $\| a\|_u = \sup \{\| \pi(a)\|\ |\ \textrm{$\pi$ rep of $\C[G]$}\}$.
\end{definition}

\begin{lemma}
  If $\pi$ is a representation of $\C[G]$ and $a = \sum_{g \in G} ^{\mathrm{finite}} a_g u_g \in \C [G]$,
  then $\| \pi (a)\| \leq \sum |a_g|$.
\end{lemma}

\begin{myproof}
  Then $\pi(a) = \sum a_g \cdot \pi(u_g)$. Then 
  $$\| \pi (a) \| = \left\| \sum a_g \pi (u_g) \right\| \leq \sum |a_g| \cdot \| \pi (u_g)\| = \sum |a_g|.$$
\end{myproof}

This implies that $\| \cdot \|_u$ is a norm on $\C [G]$.
The universal $C^*$-algebra of $G$ is $C^* (G)$ the completion of $\C[G]$
wrt $\| \cdot \|_u$.

\begin{remark}
  Then $\C [G]$ is dense in both $C_{\lambda} ^* (G)$ and $C^* (G)$.
\end{remark}

\begin{theorem}[Universal property]
  For each representation $\pi$ of $\C [G]$ there exists a surjective *-homomorphism 
  $\widehat{\pi}: C^* (G) \to C_{\pi} ^* (G)$ such that 
  \[\begin{tikzcd}
    {\mathbb{C} [G]} & {C_{\pi} ^* (G)} \\
    {C^* (G)}
    \arrow["\pi", from=1-1, to=1-2]
    \arrow[hook', from=1-1, to=2-1]
    \arrow["{\exists !\widehat{\pi}}"', dashed, two heads, from=2-1, to=1-2]
  \end{tikzcd}\]
\end{theorem}

\begin{myproof}
  Define first $\widehat{\pi}$ on $\C [G] \subseteq C^* G$ by $\widehat{\pi} (a) := \pi(a) \in C_{\pi} ^* (G)$.
  Then $\widehat{\pi}$ on $\C [G]$. Firstly, $\widehat{\pi}$ on $\C [G]$ is contractive:
  $$\|\widehat{\pi} (a)\| = \| \pi(a) \| \leq \| a\|_u.$$
  By density, $\widehat{\pi}$ uniquely extends to a continuous *-homomorphism $\widehat{\pi} : C^* (G) \to C_{\pi} ^* (G)$.
  This $\widehat{\pi}$ is contractive and $\im \pi$ is dense, so $\widehat{\pi}$ is onto.
\end{myproof}

\begin{example}
  Let $G$ be abelian and $|G| = n$. Then $\C [G] = \C^{|G|}$ as vector space.
  Hence $C^* G = \C[G] = C_r ^* (G)$. Further, $\C[G]$ is commutative, so by structure theorem 
  $$\C [G] \cong \underbrace{\C \oplus \dots \oplus \C}_{\textrm{$n$ times}}.$$
  For instance, $\C \left[\quot{\Z}{2\Z} \times \quot{\Z}{4\Z}\right] = \C \left[\quot{\Z}{4 \Z}\right].$
\end{example}

\begin{example}
  Let $G = S_3$. Then $|G| = 6$ and once again $C^* (G) = \C [G] = C_r ^* (G)$.
  By structure theorem, $\C [G] \cong M_2 (\C) \oplus \C \oplus \C$ (otherwise it would be commutative).
\end{example}

\begin{example}
  Let $G = S_4$. Again, $C^* (G) = \C [G] = C_r ^* (G)$. By Maschke's theorem, $\C [G]$ is semisimple, therefore it is a direct sum of matrix algebras over $\C$.
  Since $S_4$ has five conjugacy classes, there are five factors\footnote{Pierre Antoine Grillet, \emph{Abstract algebra}, theorem IX.7.9.}.
  Adding up all the dimensions, the only combination that works is $9 + 9 + 4 + 1 + 1 = 24$, therefore 
  $$\C [G] = M_3 (\C) \oplus M_3 (\C) \oplus M_2 (\C) \oplus \C \oplus \C.$$
\end{example}

\begin{example}
  What is $C^* (\Z)$? Representations $\pi(\C [Z]) \to \bh$ are determined by choice of unitary $U \in \bh$ such that $\pi (u_1) = U$.
  By universal property, for every $\mathcal{H}$ and $U \in \bh$ there exists a unique *-homomorphism 
  $$\widehat{\pi}: C^* (\Z) \to C^* (\{U\}),$$ where the latter is a $C^*$-subalgebra of $\bh$, generated by $U$. 
  We call $C^* (\Z)$ the universal $C^*$-algebra, generated by a unitary.
\end{example}

\subsection{Abelian group $C^*$-algebras}

If $G$ is abelian, then $\C [G]$ is commutative and $C_r ^* (G)$ is abelian.
By Gelfand, there exists a compact hausdorff space $\widehat{G}$ such that $C_r ^* (G) \cong C(\widehat{G})$
and $\widehat{G} = \sigma(C_r ^* (G))$.

\begin{definition}
  To each abelian group $G$ we associate its Pontryagin dual 
  $$\widehat{G} = \{\textrm{$w: G \to \mathbb{T}$ group homomorphism}\}.$$
\end{definition}

Then $\widehat{G}$ is a group under pointwise multiplication. We endow $\widehat{G}$
with the topology induced from $\widehat{G} \subseteq \mathbb{T} ^G$.
The basis sets for this topology are 
$$B_{\varepsilon, F} (w) = \{\eta \in \widehat{G}\ |\ |\eta (h) - w(h)| < \varepsilon,\ \forall h \in F\}$$
for $\varepsilon > 0$, $w \in \widehat{G}$ and $F \subseteq G$ finite.
Notice that a net $(w_i)_{i \in I} \subseteq \widehat{G}$ is Cauchy iff 
$(w_i (g))_{i \in I} \subseteq \mathbb{T}$ is Cauchy for all $g \in G$.

\begin{theorem}
  The map 
  $$h: \widehat{G} \to \sigma(C_r ^* (G)),\quad w \mapsto \left(\sum a_g u_g \mapsto \sum a_g w(g)\right)$$
  is a homeomorphism.
\end{theorem}

\begin{myproof}
  First, we prove that $h(w) \in \sigma (C_r ^* (G))$ for all $w \in \widehat{G}$.
  We begin by showing $h(w): \C [G] \to \C$ is a homomorphism. Take $b = \sum b_k u_k \in \C [G]$.
  Then $$h(w) (a \cdot b) = \sum_g \left(\sum_h a_h b_{h^{-1} g}\right) \cdot w(g)$$
  and $$h(w) (a) \cdot h(w) (b) = \left(\sum_g a_g w(g)\right) \cdot \left(\sum_h b_h w(h)\right) = \sum_k \left(\sum_h a_{k h^{-1}} b_h\right) w(k),$$
  so $h(w)$ is multiplicative. To extend it to $C_r ^*$, we must prove that $| h(w) a| \leq \| a\|_r$ for all $a \in \C [G]$.
  To $\chi \in \sigma(C_r ^* (G))$ and $a \in \C[G]$ we associate 
  $$\widetilde{a} = \sum a_g w(g) \cdot \overline{\chi(u_g)} u_g,$$
  so $h(w) a = \chi(\widetilde{a})$. By Gelfand, 
  $$\| \widetilde{a} \|_r = \sup \{| \mu (\widetilde{a}) |\ |\ \mu \in \sigma (C_r ^* (G))\} \geq |\chi(\widetilde{a})| = |h(w) a|.$$
  Next, we show that $\| \widetilde{a} \|_r = \| a \|_r$: to $\theta \in \ell^2 (G)$ assign $\widetilde{\theta}$ by 
  $\widetilde{\theta_h} := \chi(u_{h^{-1}}) \overline{w(h)} \theta_h.$
  Then $\| \theta\|_2 = \| \widetilde{\theta} \|_2$. Further,
  $\| \lambda (\widetilde{a}) \widetilde{\theta} \|_2 = \| \lambda (a) \theta\|_2$ (short calculation), so 
  $$\| \widetilde{a} \|_r = \sup \{ \|\lambda(\widetilde{a}) \widetilde{\theta} \|\ |\ \| \widetilde{\theta} \|_2 = 1\} = \sup \{ \|\lambda(\widetilde{a}) {\theta} \|\ |\ \| {\theta} \|_2 = 1\} = \| a\|_r.$$
  Next, we prove that $h$ is continuous. Suppose the net $(w_i)_{i \in I} \subseteq \widehat{G}$ is Cauchy.
  We prove that for every $a \in C_r ^* (G)$ the net $(h(w_i) (a))_{i \in I}$ is Cauchy.
  Pick $\varepsilon > 0$. There exists $J$ such that for every $i, j \geq J$, we have 
  $$|w_i (g) - w_j (g)| < \frac{\varepsilon}{|\{g\ |\ a_g \neq 0\}|},\quad \forall g \in G.$$
  Then for all $i, j \geq J$ we get $|h(w_i) (g) - h(w_j) (g)| < \varepsilon$.
  For the general case $a \in C_r ^* (G)$, we can take $a$ as a limit of a sequence $(a_n)_n \subseteq \C G$,
  approximate $a$ with $a_n$ and use the triangle inequality to establish that $(h(w_i) (a))_i$ is Cauchy.
  Now on to bijectivity of $h$. It's enough to check that it is surjective: take $\phi \in \sigma(C_r ^* (G))$. Define 
  $$w_{\phi} : G \to \C,\quad g \mapsto \phi(u_g).$$
  Since $\phi$ is a *-homomorphism, $\im w_{\phi} \subseteq \mathbb{T}$.
  We have to prove that $w_{\phi} \in \widehat{G}$. We just check the multiplicativity:
  $$w_{\phi} (g) \cdot w_{\phi} (h) = \phi(u_g) \phi(u_h) = \phi(u_g u_h) = \phi(u_{gh}) = w_{\phi} (gh).$$
  For every $w \in \widehat{G}$, we get $w_{h(w)} = w$. So $w_{\phi} = w_{h(w_\phi)}$,
  which gives us $h(w_{\phi}) = \phi$. Now since $h$ is a bijective continuous map between compact and Hausdorff spaces, it is a homeomorphism.
\end{myproof}

\begin{example}
  $\widehat{\quot{\Z}{n\Z}} = \quot{\Z}{n\Z}$, $\widehat{\R} = \R$, $\widehat{\Z} = \mathbb{T}$, $\widehat{\mathbb{T}} = \widehat{\Z}$.
\end{example}

\begin{theorem}[Pontryagin]
  If $G$ is a locally compact abelian group (it's underlying topological space is locally compact Hausdorff),
  then $G \cong \widehat{\widehat{G}}$.
\end{theorem}

\section{Bounded operators on Hilbert spaces}

Let $\mathcal{H}$ be a complex Hilbert space. Then $\bh$
is a $\C$-algebra with norm $\|A\| = \sup_{\mu \in \mathcal{H}, \|\mu\| = 1} \|A\mu\|$.

\begin{remark}
  Recall that $A \in \bh$ is:
  \begin{enumerate}
    \item normal $\Leftrightarrow A^* A = A A^* \Leftrightarrow \|A\mu\| = \|A^* \mu\|,\ \forall \mu \in \mathcal{H}$
    \item self-adjoint $\Leftrightarrow A^* = A \Leftrightarrow \langle A\mu, \mu\rangle \in \R,\ \forall \mu \in \mathcal{H}$
    \item positive $\Leftrightarrow \textrm{$A = B^* B$ for some $B \in \mathcal{B}(\mathcal{H})$} \Leftrightarrow \langle A\mu, \mu\rangle \geq 0,\ \forall \mu \in \mathcal{H}$
    \item isometry $\Leftrightarrow A^* A = I \Leftrightarrow \| A\mu \| = \| \mu\|,\ \forall \| \in \mathcal{H}$
    \item projection $\Leftrightarrow A^2 = A = A^* \Leftrightarrow \textrm{$A$ is an orthogonal projection onto some closed subspace of $\mathcal{H}$}$
  \end{enumerate}
\end{remark}

\begin{lemma}
  An operator $A \in \bh$ is a partial isometry iff there exists a closed subspace $\mathcal{K} \leq \mathcal{H}$
  such that $A\big|_{\mathcal{K}}$ is an isometry and $A\big|_{\mathcal{K}^\perp} = 0$.
\end{lemma}

\begin{myproof}
  We first prove $(\Leftarrow)$. Obviously, $\mathcal{K}^\perp \subseteq \ker A$.
  From $Ax = 0$, where $x = y + z$ and $y \in \mathcal{K}, z \in \mathcal{K}^\perp$, we have 
  $$0 = Ax = A(y + z) = Ay + Az = Ay.$$
  But since $A\big|_{\mathcal{K}}$ is an isometry, $\| Ay\| = \|y\| = 0$, so $y = 0$ and $x \in \mathcal{K}^\perp$.
  Now we prove that $P = A^* A$ is a standard projection onto $\mathcal{K}$.
  For $x \in \mathcal{K}$, we have
  $$\langle Px, x \rangle = \langle A^* A x, x\rangle = \langle Ax, Ax\rangle = \|Ax\|^2 = \|x\|^2,$$
  so $$\|P\|  = \|A^* A\| \leq \|A\| \|A^*\| = \|A\|^2 = 1.$$
  From Cauchy-Schwartz:
  $$\langle Px, x\rangle \leq \|Px\| \|x\| \leq \|P\| \|x\|^2 \leq \|x\|^2.$$
  Since we have equality in Cauchy-Schwartz, there exists a $\lambda \in \C$ such that $Px = \lambda x$.
  But from $\langle Px, x\rangle = \|x\|^2$, it follows that $\lambda = 1$. So $P\big|_{\mathcal{K}} = \id$
  and for $x \in \mathcal{K}^\perp$, $Px = A^* Ax = 0$. Therefore, $P = A^* A$ is indeed a projection.
  Now onto the opposite direction $(\Rightarrow)$. Suppose $P = A^* A$ is a projection
  and denote $\mathcal{K} = \im P$. Since $\mathcal{K} = \ker (I - P)$, it is a closed subspace of $\mathcal{H}$.
  For $x \in \mathcal{K}$, we have 
  $$\| Ax\|^2 = \langle Ax , Ax\rangle = \langle Px, x\rangle = \langle x, x\rangle = \|x\|^2.$$
  But for $x \in \mathcal{K}^\perp$, we use the identity 
  $$(\im P)^\perp = \ker P^* = \ker P$$
  to get $Px = 0$, so $\| A x\|^2 = \langle Px, x\rangle = 0$ and $\| Ax\| = 0$.
\end{myproof}

\begin{theorem}
  Let $\mathcal{H}$ be a Hilbert space and $x \in \bh$.
  Then there exists a partial isometry $v$ such that $x = v \cdot |x|$ and 
  $\ker v = \ker |x| = \ker x$. This decomposition is unique if $x = wy$
  for $y \geq 0$ and partial isometry $w$ such that $\ker y = \ker w$. Then $w = v$ and $y = |x|$. 
\end{theorem}

\begin{myproof}
  First we prove the existence. Define $$v_x : \im |x| \to \im x,\quad |x|y \mapsto xy.$$
  Since \begin{align*}
    \| |x| y\|^2 &= \langle |x|y, |x|y \rangle \\
    &= \langle |x|^2 y, y\rangle\\
    &= \langle x^* x y, y\rangle\\
    &= \langle xy, xy\rangle\\
    &= \| xy\|^2.
  \end{align*}
  The above $v_x$ is well defined. It is also linear and isometric.
  By continuity, extend $v_x$ to a map $\overline{\im |x|} \to \overline{\im x}$.
  Now $v_0$ can be extended to $v: \mathcal{H} \to \mathcal{H}$ by setting 
  $v\big|_{(\im |x|)^\perp} = 0.$ By previous lemma, $v$ is a partial isometry.
  By definition, $x = v \cdot |x|$ and $\ker v = (\im |x|)^\perp = \ker |x| = \ker x$.
  Next, we prove uniqueness. If $x = wy$ as in the statement, then $\ker w = \ker y = (\im y)^\perp$,
  so $w$ is a partial isometry on $\overline{\im y}$. From there, we get 
  $$|x|^2 = (wy)^* (wy) = y^* w^* w y = y^* y = y^2,$$
  which implies 
  $$|x| = (|x|^2)^{\frac{1}{2}} = (y^2)^{\frac{1}{2}} = y.$$
  Now $$w|x| \mu = wy \mu = x\mu$$
  together with 
  $$\ker w = (\im y)^\perp = (\im |x|)^\perp$$ implies $w = v$.
\end{myproof}

\subsection{Trace class operators}

Recall that $A \in \bh$ has finite rank if $\rank A = \dim \overline{\im A} < \infty$.
We know that 
$$\im A^* = \im (A^* |_{(\ker A^*)^\perp}) = \im (A^* \big|_{\overline{\im A}}).$$
So $\rank A < \infty$ iff $\rank A^* < \infty$. Define a set
$$\mathcal{F} (\mathcal{H}) = \{A \in \bh\ |\ \rank A < \infty\}$$
of finite rank operators. Now if $\alpha, \beta \in \mathcal{H}$, then we can define 
$$\alpha \otimes \overline{\beta} : \mathcal{H} \to \mathcal{H},\quad y \mapsto \langle y, \beta \rangle \cdot \alpha.$$
It is trivial to see that $\rank (\alpha \otimes \overline{\beta}) \leq 1$ and $(\alpha \otimes \overline{\beta})^* = \beta \otimes \overline{\alpha}$.
If $\| \alpha\| = \| \beta \| = 1$, then $\alpha \otimes \overline{\beta}$
is a partial isometry with initial space $\C \beta$ and image $\C \alpha$.
Then $$\mathcal{F} (\mathcal{H}) = \mathrm{span}\ \{\alpha \otimes \overline{\beta}\ |\ \alpha, \beta \in \mathcal{H}\}.$$
For $x, y \in \bh$ we have $$x (\alpha \otimes \overline{\beta}) y = (x \alpha) \otimes \overline{(y^* \beta)}.$$  

\begin{lemma}
  Let $x \in \bh$ have the polar decomposition $x = v \cdot |x|$.
  Then for all $y \in \mathcal{H}$, we have 
  $$2 \left| \langle xy , y \rangle \right| \leq \langle |x| y, y\rangle + \langle |x|v^* y, v^* y \rangle.$$
\end{lemma}

\begin{myproof}
  Let $\lambda \in \mathbb{T}$. Then 
  \begin{align*}
    0 &\leq \|(|x|^{\frac{1}{2}} - \lambda |x|^{\frac{1}{2}} v^*) y\|^2\\
    &= \| |x|^{\frac{1}{2}} y\|^2 - 2 \real \overline{\lambda} \langle |x|^{\frac{1}{2}} y, |x|^{\frac{1}{2}} v^* y\rangle + \||x|^{\frac{1}{2}} v^* y\|^2.
  \end{align*}
  Now pick $\lambda$ such that $\overline{\lambda} \langle |x|^{\frac{1}{2}} y, |x|^{\frac{1}{2}} v^* y \rangle \geq 0$ and we are done.
\end{myproof}

\begin{definition}
  Let $(e_i)_{i \in I}$ be an orthonormal system for $\mathcal{H}$. For $x \in \mathcal{B}(\mathcal{H})_+$,
  define the trace 
  $$\trace (x) = \sum_{i \in I} \langle x e_i, e_i \rangle \in [0, \infty].$$
  We call $x \in \mathcal{B}(\mathcal{H})$ trace class if 
  $$\| x\| = \trace (|x|) < \infty.$$
  The set of trace class operators on $\mathcal{H}$ will be denoted by $L^1 (\bh, \trace)$.
\end{definition}

\begin{remark}
  By $\sum_{i \in I} \langle x e_i, e_i \rangle$, we mean the limit of the net $a_F = \sum_{i \in F} \langle x e_i, e_i\rangle$, where $F \subseteq I$ is a finite subset.
  Indeed, one can check that finite subsets $F \subseteq I$ together with the inclusion relation form a directed set. Furthermore, the above net is monotone,
  therefore it either converges (if it is above bounded) or it goes to infinity. Therefore, it has a generalized limit. If the sum converges, then $\langle x e_i, e_i\rangle$ is non-zero for at most countable many $e_i$
  and our definition of the sum coincides with the usual sum of the series.
\end{remark}

\begin{lemma}
  For all $x \in \mathcal{B}(\mathcal{H})$ we have $\trace (x^* x) = \trace(x x^*)$.
\end{lemma}

\begin{myproof}
  \begin{align*}
    \trace (x^* x) &= \sum_i \langle x^* x e_i , e_i\rangle = \sum_i \langle x e_i, x e_i \rangle\\
    &= \sum_i \| x e_i\|^2 = \sum_i \sum_j \langle x e_i, e_j \rangle \overline{\langle x e_i, e_j \rangle}\\
    &= \sum_j \sum_i \langle e_i, x^* e_j \rangle \overline{\langle e_i, x^* e_j \rangle} = \sum_j \sum_i \langle x^* e_j, e_i\rangle \overline{\langle x^* e_j , e_i\rangle}\\
    &= \sum_j \| x^* e_j \|^2 = \sum_j \langle x^* e_j, x^* e_j\rangle\\
    &= \sum_j \langle x x^* e_j, e_j \rangle = \trace(x x^*) \qedhere
  \end{align*}
\end{myproof}

\begin{corollary}
  If $x \in \bh_+$ and $u \in \mathcal{U} (\mathcal{H})$, then 
  $$\trace (u^* x u) = \trace (x).$$
  In particular, the trace of a positive operator is independent of the choice of the 
  orthonormal basis for $\mathcal{H}$.
\end{corollary}

\begin{myproof}
  Since $x \in \bh_+$, there exists a $y \in \bh$
  such that $x = y^* y$. By lemma, we have 
  \begin{align*}
    \trace (x) &= \trace (y^* y) = \trace (y y^*)\\
    &= \trace (u^* y^* y u) = \trace (u^* x u).
  \end{align*}
  If $(f_i)$ is another ONB for $\mathcal{H}$, then there exists $u \in \mathcal{U}(\mathcal{H})$ such that $u e_i = f_i$ for all indices $i$:
  \begin{align*}
    \sum_i \langle x f_i, f_i \rangle &= \sum_i \langle x u e_i, u e_i\rangle\\
    &= \sum_i \langle u^* x u e_i, e_i \rangle\\
    &= \trace (u^* x u) = \trace (x). \qedhere
  \end{align*}
\end{myproof}

\begin{definition}
  If $(e_i)$ is ONB for $\mathcal{H}$ and $x \in L^1 (\bh)$, then its trace is 
  $$\trace(x) := \sum_{i \in I} \langle x e_i, e_i \rangle.$$
\end{definition}

By one of the lemmas above, this series is absolutely convergent:
\begin{align*}
  2 | \trace(x) | \leq \trace (|x|) + \trace (v |x| v^*) \leq \|x\|_1 + \|x\|_1 = 2\| x\|_1.
\end{align*}
This is the result of the following proof.

\begin{theorem}
  \begin{enumerate}
    \item $L^1 (\bh)$ is a two-sided ideal in $\mathcal{B}(\mathcal{H})$
    that is closed under involution. 
    \item $L^1 (\bh)$ is a linear span of all positive operators of finite trace.
    \item Trace is independent of the ONB and $\| \cdot \|_1$ is a norm on $L^1 (\bh)$.
  \end{enumerate}
\end{theorem}

\begin{myproof}
  Let $A, B \in L^1 (\bh)$ and satisfy the polar decompositions:
  $$A + B = U |A + B|,\quad A = V |A|,\quad B = W |B|.$$
  Let $(e_i)$ be an ONB. Then 
  \begin{align*}
    \sum_{i = 1} ^N \langle |A + B| e_i, e_i \rangle &= \sum_{n = 1} ^N |\langle U^* (A + B) e_n, e_n\rangle|\\
    &\leq \sum_{n = 1} ^N |\langle U^* A e_n, e_n \rangle| + \sum_{n = 1} ^N |\langle U^* B e_n, e_n \rangle| \\
    &= \sum_{n = 1} ^N |\langle U^* V |A| e_n, e_n \rangle| + \sum_{n = 1} ^N |\langle U^*W |B| e_n, e_n \rangle|.
  \end{align*}
  We can bound the first term:
  \begin{align*}
    \sum_{n = 1} ^N |\langle U^* V |A| e_n, e_n \rangle| &= \sum_{n = 1} ^N |\langle |A|^{\frac{1}{2}} e_n, |A|^{\frac{1}{2}} V^* U e_n \rangle|\\
    &\leq \sum_{n = 1} ^N \||A|^{\frac{1}{2}} e_n\| \||A|^{\frac{1}{2}} V^* U e_n\|\\
    &\leq \left(\sum_{n = 1} ^N \||A|^{\frac{1}{2}} e_n\|^2 \right)^{\frac{1}{2}} \left(\sum_{n = 1} ^N \||A|^{\frac{1}{2}} V^* U e_n\|^2\right)^{\frac{1}{2}}.
  \end{align*}
  Since $\| |A|^{\frac{1}{2}} e_n \|^2 = \langle |A|^{\frac{1}{2}} e_n, |A|^{\frac{1}{2}} e_n \rangle = \langle |A| e_n, e_n\rangle$, the expression in the first bracket goes to $\trace |A|$.
  Next, we prove that the expression in the second bracket is less or equal to $\trace |A|$:
  $$\sum_{n = 1} ^N \langle |A|^{\frac{1}{2}} V^* U e_n, |A|^{\frac{1}{2}} V^* U e_n \rangle = \sum_{n = 1} ^N \langle U^* V |A| V^* U e_n, e_n \rangle \xrightarrow{N \to \infty} \trace |A|.$$
  Pick an ONB for $\mathcal{H}$ as follows: each $f_j$ should be in $\ker U$ or $(\ker U)^\perp$.
  Then $$\trace (U^* V |A| V^* U) \leq \trace (V |A| V^*).$$
  By similar argument, 
  $$\trace (V |A| V^*) \leq \trace(|A|)$$
  and we are done:
  $$\sum_{n = 1} ^N |\langle U^* V |A| e_n, e_n \rangle| \leq \trace |A|.$$
  Similarly, 
  $$\sum_{n = 1} ^N |\langle U^* W |B| e_n, e_n \rangle| \leq \trace |B|,$$
  which implies 
  $\trace |A + B| \leq \trace |A| + \trace |B|$.
  We have proved that $L^1 (\bh)$ is a vector space and $\| \cdot \|_1$ is a norm.
  Clearly, $L^1 (\bh)$ contains all positive operators with finite trace,
  so also their linear span. Next we prove that it is a two-sided ideal of $\bh$.
  Let $A \in L^1 (\bh)$ and $B \in \bh$.
  Since every operator is a linear combination of four unitaries, we can assume WLOG that $B = U$ is a unitary.
  Then 
  $$|UA| = (A^* U^* U A)^{\frac{1}{2}} = (A^* A)^{\frac{1}{2}} = |A|,$$
  so $BA = UA \in L^1 (\bh)$. Furthermore,
  $$|AU| = (U^* A^* A U)^{\frac{1}{2}} = U^* |A| U,$$
  which implies 
  $$\trace |AU| = \trace (U^* |A| U) = \trace |A|$$
  and $AB = AU \in L^1 (\bh)$.
  Now we prove that $L^1 (\bh)$ is closed under involution.
  Let $A = U |A|$ and $A^* = V |A^*|$ be polar decompositions. Then 
  $$|A^*| = V^* A^* = V^* (U |A|)^* = V^* |A| U^*.$$
  If $A \in L^1 (\bh)$, then $|A| \in L^1 (\bh)$, so 
  $$|A^*| = V^* |A| U^* \in L^1 (\bh).$$ This gives us $A^* \in L^1 (\bh)$.
  Finally, we prove that $L^1 (\bh)$ is a linear span of all positive operators of finite trace.
  Let $x \in L^1 (\bh)$ and $a \in \bh$. The following glorization identity holds:
  $$4 a |x| = \sum_{k = 0} ^3 i^k \underbrace{(a + i^k) |x| (a + i^k)^*}_{\textrm{positive and finite trace}}.$$
  If $a = v$ partial isometry from the polar decomposition theorem, then 
  $$x = v |x| = \sum_{k = 0} ^3 \frac{i^k}{4} {(v + i^k) |x| (v + i^k)^*}.$$
  is a linear combination of four positive operators with finite trace.
\end{myproof}

As an obvious corollary, the definition of trace is independent of the choice of an ONB of $\mathcal{H}$.


\begin{proposition}
  Let $x \in L^1 (\bh)$ and $a, b \in \bh$. Then 
  \begin{itemize}
    \item $\| x\| \leq \|x\|_1$;
    \item $\| axb\|_1 \leq \| a\| \|b\| \|x\|_1$;
    \item $\trace (ax) = \trace (xa)$.
  \end{itemize}
\end{proposition}

\begin{myproof}
  \begin{enumerate}
    \item
    \begin{align*}
      \| x\| &= \| |x|\| = \| |x|^{\frac{1}{2}} \|^2\\
      &= \sup _{\| \alpha\| = 1} \langle |x|^{\frac{1}{2}} \alpha, |x|^{\frac{1}{2}} \alpha \rangle = \sup_{\| \alpha \| = 1} \langle |x| \alpha, \alpha \rangle \\
      &\leq \trace |x| = \| x\|_1.
    \end{align*}
    \item We begin with 
    \begin{equation*}
      | a x |^2 = x^* a ^* a  x \leq \| a ^* a \| x^* x = \| a^* a\|\cdot |x|^2 = \|a\|^2\cdot |x|^2
    \end{equation*}
    and since $|ax| \leq \| a\| \cdot |x|$ we get $\| ax\|_1 \leq \|a\| \cdot \|x\|_1$.
    But $\|x\|_1 = \|x^*\|_1$, we also get $\| xb\|_1 \leq \|b\| \cdot \|x\|_1$.
    \item WLOG $a = u \in \mathcal{U} (\mathcal{H})$. Then 
    \begin{align*}
      \trace (xu) &= \sum_i \langle x u e_i, e_i \rangle = \sum_i \langle x u e_i, u^* u e_i\rangle\\
      &= \sum_i \langle ux ue_i, u e_i \rangle = \trace (ux). \qedhere
    \end{align*}
  \end{enumerate}
\end{myproof}

\begin{remark}
  We have the following identities:
  \begin{enumerate}
    \item $\trace (\alpha \otimes \overline{\beta}) = \langle \alpha, \beta \rangle$;
    \item $\mathcal{F} (\mathcal{H})$ is dense in $(L^1 (\bh), \| \cdot \|_1)$.
    Of course, we know that $\mathcal{F} (\mathcal{H})$ is dense in $(\mathcal{K} (\mathcal{H}), \| \cdot \|)$.
  \end{enumerate}
\end{remark}

\begin{theorem}
  $(L^1 (\bh), \| \cdot \|_1)$ is a Banach space.
\end{theorem}

\begin{myproof}
  We only have to prove completeness. Let $(x_n)_n$ be a Cauchy sequence in $(L^1 (\bh), \| \|_1)$.
  Since $\| \cdot\| \leq \| \cdot \|_1$, $(x_n)$ is a Cauchy sequence in $(\mathcal{B}(\mathcal{H}), \| \|)$.
  But $(\mathcal{B}(\mathcal{H}), \| \|)$ is a Banach space, so there exists $x \in \bh$ such that $x_n \to x$ in $\| \|$-topology.
  Notice that 
  $$x^* x - x_n^* x_n = x^* (x - x_n) + (x - x_n)^* x_n.$$
  By continuity of continuous functional calculus, this implies $|x_n| \to |x|$, meaning $\| |x_n| - |x| \| \to 0$.
  Next we prove that $x \in L^1 (\bh)$. For any ONB $(e_i)_i$, we have 
  $$\sum_{i = 1} ^k \langle |x| e_i, e_i \rangle = \lim_{n \to \infty} \sum_{i = 1} ^k \langle |x_n| e_i, e_i \rangle \leq \lim_{n \to \infty} \trace |x_n| = \lim_{n \to \infty} \|x_n\|_1 < \infty.$$
  Here, we used the fact that $\| x_n - x_k \|_1 \geq \| x_n \|_1 - \|x_k\|_1$, so the sequence $(\| x_n\|_1)_n$ is Cauchy and therefore has a limit.
  This proves that $x \in L^1 (\bh)$ and $\| x\|_1 \leq \lim_{n \to \infty} \| x_n\|_1$.
  Finally, we have to show that $\| x_n - x\|_1 \to 0$. Let $\varepsilon > 0$. Pick $N \in \N$ such that for every $n > N$, we get $\| x_n - x_N \|_1 < \frac{\varepsilon}{3}$.
  Let $\mathcal{H}_0 \subseteq \mathcal{H}$ be a finite dimensional subspace such that 
  $$\| x_N P_{\mathcal{H}_0 ^\perp} \|_1,\ \| x P_{\mathcal{H}_0 ^\perp} \|_1 < \frac{\varepsilon}{3}.$$
  Then for every $n > N$, we have 
  \begin{align*}
    \| x - x_n \|_1 &\leq \| (x - x_n) P_{\mathcal{H}_0} \|_1 + \| (x - x_n) P_{\mathcal{H}_0 ^\perp} \|_1\\
    &\leq \| (x - x_n) P_{\mathcal{H}_0} \|_1 + \| x P_{\mathcal{H}_0 ^\perp} - x_N P_{\mathcal{H}_0 ^\perp}\|_1 + \| x_N P_{\mathcal{H}_0 ^\perp} - x_n P_{\mathcal{H}_0 ^\perp}\|_1\\
    &\leq \| (x - x_n) P_{\mathcal{H}_0 }\|_1 + \frac{\varepsilon}{3} + \frac{\varepsilon}{3} + \|x_N - x_n\|_1 \| P_{\mathcal{H}_0 ^\perp}\|\\
    &= \| (x - x_n) P_{\mathcal{H}_0 }\|_1 + \varepsilon\\
    &\leq \| (x - x_n) \|  \| P_{\mathcal{H}_0 }\|_1 + \varepsilon \xrightarrow[n \to \infty]{} \varepsilon.
  \end{align*}
  Since $\varepsilon > 0$ was arbitrary, this shows $x_n \xrightarrow[\| \cdot \|_1]{} x$.
\end{myproof}

\begin{theorem}
  The map 
  $$\Psi: \bh  \to L^1 (\bh)^*,\quad a \mapsto (\psi_a: x \mapsto \trace (ax))$$
  is an isometric isomorphism of Banach spaces.
\end{theorem}

\begin{corollary}
  The map $$\Phi: L^1 (\bh) \to \mathcal{K} (\mathcal{H})^*, \quad x \mapsto (\varphi_x: a \mapsto \trace (ax))$$
  is an isometric isomorphism of Banach spaces.
\end{corollary}

\begin{myproof}[Proof of the theorem]
  We notice that $\Psi$ is linear and a contraction because the norms $\|\cdot \|$
  and $\| \cdot \|_1$ are comparable. We will first show that $\Psi$ is surjective.
  Let $\varphi \in L^1 (\bh)^*$. Notice that 
  $$(\alpha, \beta) \mapsto \varphi(\alpha \otimes \overline{\beta})$$
  is a bounded sesquilinear form in $\mathcal{H}$. By the introductory course, there exists 
  an $a \in \bh$ such that 
  $$\varphi(\alpha \otimes \overline{\beta}) = \langle a \alpha, \beta \rangle = \trace (a\alpha \otimes \overline{\beta}) = \trace (a(\alpha \otimes \overline{\beta})) = \psi_a (\alpha \otimes \overline{\beta}).$$
  So $\varphi$ and $\psi_a$ agree on $\mathcal{F} (\mathcal{H})$, so by bounded density $\varphi = \psi_a$.
  Finally, 
  $$\| a\| = \sup_{\alpha, \beta \in (\mathcal{H})_1} |\langle a \alpha, \beta \rangle| = \sup_{\alpha, \beta \in (\mathcal{H})_1} |\trace (a (\alpha \otimes \overline{\beta})) | \leq \| \psi_a \|_1.$$
  But since 
  $$\| \psi_a \|_1 = \sup_{x \in (L^1(\bh))_1} |\trace (ax)| = \sup_{x \in (L^1(\bh))_1} \| ax \|_1 \leq \sup_{x \in (L^1(\bh))_1} \| a \| \|x \|_1 = \| a\|,$$
  we have $\| a\| = \| \psi_a\|_1$ and $\psi$ is isometric.
\end{myproof}

Recall that $T \in \bh$ is compact if $T((\mathcal{H})_1)$ is relatively compact.
Equivalently, image under $T$ of a bounded sequence in $\mathcal{H}$ has a convergent subsequence.
For Hilbert spaces, this is also equivalent to $T \in \overline{\mathcal{F} (\mathcal{H})}$ in the norm $\| \cdot \|$.
For compact operators in Hilbert space, we have the singular value decomposition.
For $K \in \mathcal{K} (\mathcal{H})$, then there exists an orthonormal basis $(e_i)_i$ and $(f_j)_j$ for $\mathcal{H}$
and $\sigma_1 \geq \sigma_2 \geq \dots \geq 0$ such that 
$$K x = \sum_{n = 1} ^\infty \sigma_n \langle x, e_n \rangle f_n.$$
This implies $$|K| x = \sum \sigma_n \langle x, e_n \rangle e_n.$$

\begin{theorem}
  \begin{enumerate}
    \item $L^1 (\bh) \subseteq K(\mathcal{H})$.
    \item $K \in \mathcal{H}$ is a $L^1 (\bh)$ iff $\sum_{k = 1} ^\infty \sigma_n < \infty$.
  \end{enumerate}
\end{theorem}

\begin{myproof}
  \begin{enumerate}
    \item If $x \in L^1 (\bh) = \mathcal{F}$ then there exists $(x_n)_n$ in $\mathcal{F} (\mathcal{H})$ such that $\|x_n - x\|_1 \to 0$.
    Since $\| \cdot \| \leq \| \cdot \|_1$, we get $\|x_n - x \| \to 0$ and $x \in \overline{\mathcal{F}}^{\| \cdot \|} = \mathcal{K} (\mathcal{H})$.
    \item This follows from $\trace |K| = \sum \sigma_n$.
  \end{enumerate}
\end{myproof}

\subsection{Hilbert-Schmidt operators}

\begin{definition}
  An element $x \in \bh$ is a Hilbert-Schmidt operator 
  if $$|x|^2 = x^* x \in L^1 (\bh).$$
  The set of all such elements is denoted by $L^2 (\bh, \trace)$. 
\end{definition}

\begin{proposition}
  \begin{enumerate}
    \item $L^2 (\bh) \lhd \bh$ and is closed under $*$.
    \item If $x, y \in L^2 (\bh)$, then $xy, yx \in L^1 (\bh)$ and $\trace(xy) = \trace (yx)$.
  \end{enumerate}
\end{proposition}

\begin{remark}
  Beware: $\exists a, b \in \bh$ such that $ab \in L^1 (\bh)$
  and $ba \notin L^1 (\bh)$. However, if $ab, ba \in L^1 (\bh)$,
  then $\trace (ab) = \trace (ba)$.
\end{remark}

\begin{myproof}
  For $\alpha \in \C$ and $x \in \mathcal{B}(\mathcal{H})$, we have $|\alpha x|^2 = |\alpha|^2 |x|^2$.
  Similarly, $|x + y|^2 \leq |x + y|^2 + |x - y|^2 = 2 (|x|^2 + |y|^2)$, so $L^2 (\bh)$ is a complex vector space.
  Since $|ax|^2 \leq \| a\|^2 \cdot |x|^2$, we have $L^2 (\bh)$ is a left ideal of $\bh$.
  From 
  $$\trace |x|^2 = \trace (x^* x) = \trace (x x^*) = \trace |x^* |^2,$$
  we deduce that $L^2 (\bh)$ is closed under involution.
  If $x \in L^2 (\bh)$ and $b \in \bh$,
  then $x^* \in L^2$, which implies $b^* x^* \in L^2$ and finally $xb = (b^* x^*)^* \in L^2 (\bh)$,
  so $L^2 (\bh) \lhd \bh$.
  Next, we use the polarization identity 
  $$4 y^* x = \sum_{k = 0} ^3 i^k |x + i^k y|^2.$$
  If $x, y \in L^2 (\bh)$, then this shows $y^* x \in L^1 (\bh)$
  and 
  \begin{align*}
    4 \trace (y^* x) &= \sum_{k = 0} ^3 i^k \trace ((x + i^k y)^*(x + i^k y))\\
    &= \sum_{k = 0} ^3 i^k \trace ((x + i^k y)(x + i^k y)^*)\\
    &= 4 \trace (x y^*).
  \end{align*}
  On $L^2 (\bh)$ we have the sesquilinear form $\langle x, y\rangle_2 := \trace (y^* x)$.
  It is well-defined and positive definite, so it is a scalar product. The induced norm is denoted as $\| \cdot \|_2$.
  For every $y \in L^2 (\bh)$, we have 
  $$\| y\| = \| y^* y\|^{\frac{1}{2}} \leq \| y^* y\|_1 ^{\frac{1}{2}} = \|y\|_2.$$
  Similarly, we have $$\| axb\|_2 = \| a\| \cdot \|x\|_2 \cdot \| b\|$$ for all $x \in L^2 (\bh)$
  and $a, b \in \bh$. As before, $\mathcal{F} (\mathcal{H})$ are dense in $L^2 (\bh)$ with regards to $\| \cdot \|_2$ and $L^2 (\mathcal{B}(\mathcal{H}))$.
  Using singular values $(\sigma_n)_n$ of compact $K \in \mathcal{K} (\mathcal{H})$, we have $K \in L^2 (\bh)$
  iff $\sum_{k = 0} ^\infty \sigma_j ^2 < \infty$.
  For every $x \in L^1 (\bh)$, we have 
  $$\| x\|_2 = \sup_{y \in L^2 (\mathcal{B}(\mathcal{H})),\ \| y\|_2 = 1} | \trace (y^* x) | \leq \sup_{y \in L^2 (\bh),\ \| y\|_2 = 1} \|y\| \cdot \| x\|_1 \leq \|x\|_1.$$
  As a result $(L^2 (\bh), \langle \cdot \rangle_2)$ is a Hilbert space.
\end{myproof}

\begin{theorem}[H√∂lder inequality]
  For all $x, y \in L^2 (\bh)$ we have 
  $$\| xy\|_1 \leq \| x\|_2 \| y\|_2.$$
\end{theorem}

\begin{myproof}
  \begin{align*}
    \| xy\|_1 &= \trace |xy| = |\trace (v^* xy)|\\
    &= |\langle y, x^* v \rangle_2| \leq \| x^* v\|_2 \| y\|_2\\
    &\leq \| x^*\|_2 \| v\| \|y\|_2 \leq \| x\|_2 \cdot \|y\|_2. \qedhere
  \end{align*}
\end{myproof}

\subsection{Hilbert-Schmidt integral operators}

Let $(X, \mu)$ be a $\sigma$-finite measure space.
This means that $X$ is a countable union of finite-measure sets:
$$X = \bigcup_{j = 1} ^\infty A_j,\quad \mu(A_j) < \infty.$$
For $K \in L^2 (X \times X, \mu \times \mu)$, then we can define a Hilbert-Schmidt integral operator 
with kernel $K$:
$$T_K : L^2 (X, \mu) \to L^2 (X, \mu),\quad f \mapsto \left(y \mapsto \int_X K(x, y) f(y)\, d\mu (x)\right).$$
Suppose $(\varphi_\alpha)_{\alpha}$ is an ONB for $L^2 (K, \mu)$.
By Fubini, $\left(\overline{\varphi_a (x)} \varphi_\beta (y)\right)_{\alpha, \beta}$
is an orthonormal basis for $L^2 (X \times X, \mu \times \mu)$.
Since $K \in L^2 (X \times X, \mu \times \mu)$, there exist $c_{ij} \in \C$ such that 
$$K(x, y) = \sum_{i,j} c_{ij} \overline{\varphi_i (x)} \varphi_j (y),\quad \| K\|^2 _{L^2 (X \times X)} = \sum |c_{ij}|^2 < \infty.$$
We show that $T_K$ is well-defined: for $f \in L^2 (X, \mu)$, we have $T_K f \in L^2 (X,\mu)$.
Indeed,
$$T_k f (y) = \sum_{i, j} c_{ij} \langle f, \varphi_i \rangle \varphi_j (y),$$
which implies 
\begin{align*}
  \| T_K f\|_{L^2 (X)} ^2 &\leq \sum_{i, j} |c_{ij}|^2 |\langle f, \varphi_j\rangle|^2 \| \varphi_j\|^2 _{L^2 (X)}\\
  &\leq \| f\|_{L^2} ^2 \sum_{i, j} |c_{ij}|^2 \| \varphi\|^2 _{L^2} \| \varphi_j\|^2 _{L^2}\\
  &= \| f\|^2 _{L^2} \sum|c_{ij}|^2\\
  &= \| f\|^2 _{L^2} \|K\|^2 _{L^2 (X \times X)}
\end{align*}
and finally $\| T_K\| \leq \|K\|_{L^2}$.
Suppose that $T_K ^* : L^2 (X, \mu) \to L^2 (X, \mu)$ is the integral operator with kernel 
$$K^* (y, x) := \overline{K(x, y)}.$$
Now 
\begin{align*}
  \langle T_K f, g \rangle &= \int_Y \left(\int_X K(x, y) f(x) \, d\mu (x)\right) \cdot \overline{g(y)}\, d\mu (y)\\
  &= \int_X f(x) \cdot \left(\overline{\int_Y \overline{K(x, y)} g(y)\, d\mu(y)}\right)\, d\mu (x)\\ 
  &= \langle f, T_{K^*} g \rangle.
\end{align*}

\begin{remark}[Fubini's theorem]
  If $X, Y$ are measure spaces and $\int_{X \times Y} |f| d(x, y) < \infty$, then 
  $$\int_{X \times Y} f = \int_Y \left(\int_X f\, dx\right)\, dy = \int_X \left(\int_Y f\, dy\right)\, dx.$$
\end{remark}

\begin{theorem}
  \begin{enumerate}
    \item For $K \in L^2 (X \times X, \mu \times \mu)$ we have $T_K \in L^2 (\mathcal{B} (L^2 (X, \mu)))$.
    \item The mapping $\Phi: K \mapsto T_K$ is a unitary 
    $$L^2 (X \times X, \mu \times \mu) \mapsto L^2 (\mathcal{B} (L^2 (X, \mu))).$$
  \end{enumerate}
\end{theorem}

\begin{myproof}
  \begin{enumerate}
    \item We will prove that $\| T_K\|_2 = \| K\|_{L^2}$.
    We want to approximate $T_K$ with finite rank operators, so we first approximate $K$:
    $$K (x, y) = \sum_{i, j = 1} ^\infty c_{ij} \overline{\varphi_{i} (x)} \varphi_j (x)$$
    for orthonormal basis $(\varphi_\alpha)_{\alpha}$ for $L^2 (X, \mu)$.
    For $N \in \N$ let $K_{N} (x, y) = \sum_{i, j} ^N c_{ij} \overline{\varphi_i (x)} \varphi_j (x)$.
    Then 
    $$T_{K_N} f = \sum_{i, j = 1} ^N c_{ij} \langle f, \varphi_i\rangle \varphi_j \in \mathcal{F} (L^2 (X, \mu)).$$
    By the above inequality, 
    $$\| T_K - T_{K_N}\| \leq \| K - K_N\|_{L^2} \to 0,$$
    so $T_K \in \overline{\mathcal{F}}^{\| \cdot\|} = \mathcal{K} (\mathcal{H})$.
    Then $$\| T_K \|^2 _2 = \sum_i \| T_K \varphi_i \|_{L^2} ^2 = \sum_{i, j, k} \| c_{jk} \varphi_j (x) \delta_{ik} \|^2 = \sum |c_{ij}|^2 = \|K \|_{L^2} ^2.$$
    \item It remains to prove surjectivity. Since $\Phi$ is isometric, $\im \Phi$ is closed.
    So it suffices to show that $\im \Phi$ is dense. In particular, we will show that $\im \Phi \supseteq \mathcal{F} (L^2 (X, \mu))$.
    Let $A \in \mathcal{F} (L^2 (X, \mu))$, so $\rank A < \infty$. Let $(\psi_1, \dots, \psi_m)$ be an orthonormal basis for $\im A$.
    Then $A \varphi = c_1 (\varphi) \psi_1 + \dots + c_m (\varphi) \psi_m$ for some bounded linear functionals $c_j$ on $L^2 (X, \mu)$.
    By Riesz, there exist $\mu_j \in L^2 (X, \mu)$ such that $c_j (\varphi) = \langle \varphi, \mu_j \rangle$.
    Hence \begin{equation*}
      A \varphi(x) = \int_X \left(\sum_{j = 1} ^m \psi_j (x) \cdot \overline{\mu_j (y)} \cdot \varphi (y)\right)\, d\mu (y) = T_{\sum_{i = 1} ^m \psi_j (x) \overline{\mu_j (y)}} \in \im \Phi. \qedhere 
    \end{equation*}
  \end{enumerate}
\end{myproof}

Now let $\mathcal{H}, \mathcal{K}$ be Hilbert spaces and $A \in \mathcal{B} (\mathcal{H}, \mathcal{K})$.
We associate to $A$ the map 
$$\widetilde{A} \in \mathcal{B} (\mathcal{H} \oplus \mathcal{K}, \mathcal{H} \oplus \mathcal{K}),\quad \alpha \oplus \beta \mapsto 0 \oplus A \alpha$$
or in matrix form 
$$\widetilde{A} = \begin{bmatrix}
  0 & 0\\
  A & 0
\end{bmatrix}.$$
We denote the set of Hilbert-Schmidt operators $\mathcal{H} \mapsto \mathcal{K}$ as 
$$HS (\mathcal{H}, \C) = \{A \in \mathcal{B} (\mathcal{H}, \mathcal{K})\ |\ \widetilde{A} \in L^2 (\mathcal{B}(\mathcal{H} \oplus \mathcal{K}))\}.$$
Using this notation, $HS (\mathcal{H}, \C)$ is just the dual of $\mathcal{H}$, so $\mathcal{H}^*$.
By Riesz, we have a natural anti-isomorphism 
$$\mathcal{H} \to \mathcal{H}^*,\quad \alpha \mapsto \langle \cdot , \alpha\rangle =: \overline{\alpha}$$
and a natural anti-linear bijection 
$$\bh \to \mathcal{B} (\mathcal{H}^*),\quad A \mapsto (\overline{A}: \overline{\alpha} \mapsto \overline{A \alpha}).$$
We denote the Hilbert space $\mathcal{H} \overline{\otimes} \mathcal{K} := HS (\mathcal{K}^*, \mathcal{H})$.
This is called the tensor product of Hilbert spaces. If $(e_\alpha)_\alpha$ is an ONB for $\mathcal{H}$ and $(f_\beta)_\beta$ for $\mathcal{K}$, then 
$(e_\alpha \otimes\overline{f_\beta})_{\alpha, \beta}$ is an ONB for $\mathcal{H} \overline{\otimes} \mathcal{K}$.
The algebraictensor product $\mathcal{H} \otimes \mathcal{K}$ are exactly the operators in $HS (\mathcal{K}^*, \mathcal{H})$ that are of finite rank, which are 
$\linspan \{\varphi \otimes \overline{\psi}\ |\ \varphi \in \mathcal{H},\ \psi \in \mathcal{K}\}$.

\subsection{Locally convex topologies on $\bh$}

If $\mathcal{H}$ is a Hilbert space, then $(\bh, \| \cdot\|)$
is a Banach algebra with its norm topology.

\begin{definition}
  \begin{enumerate}
    \item The weak operator topology (WOT) is given by the seminorms 
    $$T \mapsto |\langle T\alpha, \beta\rangle|,\quad \forall \alpha, \beta \in \mathcal{H}.$$
    \item The strong operator topology (SOT) is given by the seminorms 
    $$T \mapsto \|T\alpha\|,\quad \forall \alpha \in \mathcal{H}.$$
  \end{enumerate}
\end{definition}

These topologies are comparable: $\mathrm{WOT} \subseteq \mathrm{SOT} \subseteq \mathrm{uniform}$.
\begin{itemize}
  \item Uniform topology has the subbasis $$\{S \in \mathcal{B}(\mathcal{H})\ |\ \| S - T\| < \varepsilon \}$$
for $T \in \mathcal{B}(\mathcal{H})$ and $\varepsilon > 0$. The net $T_i$ converges to $T$ iff $\| T_i - T\|$ converges to $0$.
  \item WOT topology has the subbasis $$\{S \in \mathcal{B}(\mathcal{H})\ |\ \langle (S - T) \alpha, \beta \rangle < \varepsilon \}$$
  for $\alpha, \beta \in \mathcal{H}$, $T \in \mathcal{B}(\mathcal{H})$ and $\varepsilon > 0$. The net $T_i$ converges to $T$ iff $\langle T_i \alpha, \beta \rangle$ converges to $\langle T \alpha, \beta \rangle$ for all $\alpha, \beta$.
  \item SOT topology has the subbasis $$\{S \in \mathcal{B}(\mathcal{H})\ |\ \| (S - T) \alpha\| < \varepsilon \}$$
  for $\alpha \in \mathcal{H}$, $T \in \mathcal{B}(\mathcal{H})$ and $\varepsilon > 0$. The net $T_i$ converges to $T$ iff $\| (T_i - T)\alpha \|$ converges to $0$ for all $\alpha$.
\end{itemize}

\begin{example}
  Let $\mathcal{H} = \ell^2 (\N)$ and denote $T_n = \frac{1}{n} \circ \id$.
  Then $T_n \to 0$ in the norm topology. Now if we introduce the operator
  $$S (x_1, x_2, \dots) = (0, 0, \dots, 0, x_{n + 1}, x_{n + 2}, \dots),$$
  then $S_n \to 0$ in SOT, but not in norm topology, since $\|S_n\| = 1$.
  Lastly, we define 
  $$W_n (x_1, x_2, \dots) = (0, 0, \dots, x_1, x_2, \dots).$$
  We get that $W_n \to 0$ in WOT, but not in SOT and norm topology.
\end{example}

\begin{example}
  Let $(y_n)_n$ be a countable dense subset of $\mathcal{H} = \ell^2$.
  Consider the following metrics on $(\bh)_1$:
  $$d_S (A, B) = \sum_{n = 1} ^\infty \frac{1}{2^n} \|(A - B) {y_n}\|,\quad d_W (A, B) = \sum_{n = 1} ^\infty \frac{1}{2^n} \left|\langle(A - B) {y_n} , y_n\rangle\right|.$$
  Then $d_S$ induces SOT and $d_W$ induces WOT on $(\bh)_1$.
\end{example}

\begin{example}
  The multiplication 
  $$\bh \times \bh \to \bh,\quad (A, B) \mapsto A \cdot B$$
  is not jointly continuous with regards to SOT or WOT. Indeed, if $S: \ell^2 \to \ell^2$ is right shift (and $S^*$ left shift),
  then $S^n \to 0$ and $(S^*)^n \to 0$ in WOT, but $(S^*)^n S^n = I$. However,
  multiplication is WOT- and SOT- continuous in each factor separately.
  Suppose that $(x_\alpha)_\alpha \to x$ in WOT and $y \in \bh$.
  Then for each $v, w \in \bh$, we have 
  $$|\langle x_\alpha yv - xyv, w \rangle | \to 0,$$
  since $x_\alpha \to x$ in WOT. Similarly,
  $$|\langle y x_\alpha v - yxv, w \rangle | = |\langle  x_\alpha v - xv, y^*w \rangle | \to 0,$$
  which implies $x_\alpha y \to xy$ and $y x_\alpha \to yx$ in WOT.
\end{example}

\begin{example}
  The adjoint is isometric in uniform topology. It is also continuous in WOT:
  $$|\langle x^* v - y^* v, w \rangle| < \varepsilon \Leftrightarrow |\langle xw - yw, v\rangle| < \varepsilon.$$
  However, it is not continuous with regards to SOT. If $(e_n)_n$ is an ONB for $\mathcal{H}$, consider $e_1 \otimes \overline{e_n}$.
  Then for every $x \in \mathcal{H}$, we have 
  $$\|(e_1 \otimes \overline{e_n}) x \| = |\langle x, e_n \rangle | \xrightarrow[n \to \infty]{} 0,$$
  so $e_1 \otimes \overline{e_n} \to 0$ in SOT. However,
  $$\| (e_1 \otimes \overline{e_n})^* x\| = \| (e_n \otimes \overline{e_1}) x\| = |\langle x, e_1 \rangle |$$
  does not go to $0$ for all $x \in \mathcal{H}$, which proves our statement.
\end{example}

\begin{remark}
  If $T:X\to Y$ is continuous, then $T$ remains continuous if $X$ is given a finer topology or $Y$ is given a coarser topology. 
  But if both topologies are made coarser or both finer, nothing can be said in general. In particular, if $T:X\to X$ is 
  continuous with respect to a given topology on $X$ in both domain and codomain, you cannot generally conclude anything 
  about continuity of $T$ when $X$ is given a finer or coarser topology on both domain and codomain. The previous example illustrates this.
\end{remark}

\begin{lemma}
  Let $\varphi: \mathcal{B} \to \C$ be linear. The following is equivalent.
  \begin{enumerate}
    \item There exist $v_1, \dots, v_n \in \mathcal{H}$ and $w_1, \dots, w_n \in \mathcal{H}$ such that 
    $$\varphi (T) = \sum_{i = 1} ^n \langle T v_i, w_i \rangle.$$
    \item $\varphi$ is WOT-continuous.
    \item $\varphi$ is SOT-continuous.
  \end{enumerate}
\end{lemma}

\begin{myproof}
  The implications $(1) \Rightarrow (2) \Rightarrow (3)$ is obvious. Let us prove $(3) \Rightarrow (1)$.
  By a proposition in chapter 1 (the application of Hahn-Banach), there exists a $K > 0$ and $v_1, \dots, v_n \in \mathcal{H}$
  such that 
  $$|\varphi(T)|^2 \leq K \cdot \sum_{i = 1} ^n \| Tv_i\|^2.$$
  Define $$\mathcal{H}_0 := \overline{\left\lbrace \bigoplus_{i = 1} ^n Tv_i\ |\ T \in \bh \right\rbrace} \leq \mathcal{H} ^{\bigoplus n}.$$
  The map 
  $$\mathcal{H}_0 \ni \bigoplus_{i = 1} ^n T v_i \mapsto \varphi(T) \in \C$$
  is a well-defined and bounded linear functional, which by continuity extends to $\mathcal{H}_0 \to \C$.
  By Riesz, there exist $w_1, \dots, w_n \in \mathcal{H}$ such that 
  $$\varphi(T) = \sum_{i = 1} ^n \langle T v_i, w_i \rangle.$$
  Recall that $v \otimes \overline{w} \in \mathcal{F} \mathcal{H}$ and $\trace (v \otimes \overline{w}) = \langle v, w \rangle$, so 
  $$\trace (T (v \otimes \overline{w})) = \langle Tv, w \rangle.$$
  The previous identity is really 
  $$\varphi(T) = \sum_{i = 1} ^n \trace (T (v \otimes \overline{w})) = \trace (T \cdot \sum_{i = 1} ^n v_i \otimes \overline{w}_i).$$
  This means that $\varphi(T) = \trace (T \cdot A)$ for $A \in \mathcal{F} (\mathcal{H})$.
\end{myproof}

\begin{corollary}
  If $K \subseteq \bh$ is convex, then 
  $$\overline{K}^{\mathrm{WOT}} = \overline{K}^{\mathrm{SOT}}.$$
\end{corollary}

\begin{myproof}
  \begin{align*}
    \overline{K}^{\mathrm{WOT}} = \overline{K}^{\mathrm{weak}, WOT} = \overline{K}^{\mathrm{weak}, SOT}  = \overline{K}^{\mathrm{SOT}}. \qedhere
  \end{align*}
\end{myproof}

\begin{definition}
  The $\sigma$-weak operator topology ($\sigma$-WOT or ultra-weak) is the topology in $\bh$
  given by the seminorms $$x \mapsto \left| \sum_{i = 1} ^\infty \langle x \alpha_i, \alpha_i \rangle\right| $$
  for $\alpha_j \in \mathcal{H}$ with $\sum_{j = 1} ^\infty \| \alpha_j \|^2 < \infty$.
  A subbasis of open sets is thus 
  $$\left\lbrace x \in \bh\ |\ \left| \sum \langle (x - x_0), \alpha_i, \alpha_i \rangle \right| < \varepsilon \right\rbrace$$
  for $\alpha_j \in \mathcal{H}$ with $\varepsilon > 0$, $x_0 \in \bh$ and $\sum \| \alpha_j\|^2 < \infty$.
\end{definition}

\begin{definition}
  The $\sigma$-strong operator topology ($\sigma$-SOT or ultra-strong) is the topology in $\bh$
  given by the seminorms $$x \mapsto \left( \sum_{i = 1} ^\infty \| x \alpha_i \|^2\right)^{\frac{1}{2}}$$
  for $\alpha_j \in \mathcal{H}$ with $\sum_{j = 1} ^\infty \| \alpha_j \|^2 < \infty$.
  A subbasis of open sets is thus 
  $$\left\lbrace x \in \bh\ |\ \left( \sum \| (x - x_0) \alpha_i\|^2 \right)^{\frac{1}{2}} < \varepsilon \right\rbrace$$
  for $\alpha_j \in \mathcal{H}$ with $\varepsilon > 0$, $x_0 \in \bh$ and $\sum \| \alpha_j\|^2 < \infty$.
\end{definition}

\begin{remark}
  $\sigma$-WOT can also be given by seminorms 
  $$x \mapsto |\trace (xa) |$$
  for $a \in L^1 (\bh)$ positive.
  Let $(f_i)_i$ be an ONB for $\mathcal{H}$ and define 
  $$b: \mathcal{H} \to \mathcal{H},\quad f_i \mapsto \alpha_i.$$
  Since $\sum \| \alpha_j \|^2 < \infty$, we can conclude $b \in L^2 (\bh)$.
  Then:
  \begin{align*}
    \sum_i \langle x \alpha_i, \alpha_i \rangle &= \sum_i \langle xb f_i, b f_i\rangle\\
    &= \sum_i \langle b^* x bf_i, f_i\rangle\\
    &= \trace (b^* xb)\\
    &= \trace (xbb^*),
  \end{align*}
  where $a := b b^* \in L^1 (\bh)$. Since $\bh = L^1 (\mathcal{B} (\mathcal{H}))^*$,
  the $\sigma$-WOT is just the weak-* topology (with regards to this pairing).
\end{remark}

\begin{remark}
  The map 
  $$\id \otimes 1: \bh \to \mathcal{B} (\mathcal{H} \overline{\otimes} \ell^2),\quad x \mapsto x \otimes 1$$
  is an isometric *-isomorphism of $C^*$-algebras. It is neither SOT- nor WOT-continuous.
  Despite that, $\sigma$-WOT on $\bh$ is induced by WOT on $\mathcal{B} (\mathcal{H} \overline{\otimes} \ell^2)$ 
  and the $\sigma$-SOT on $\bh$ is induced by SOT on $\mathcal{B} (\mathcal{H} \overline{\otimes} \ell^2)$. 
  Indeed, if $(e_i)_{i \in \N}$ is an ONB for $\ell^2$, define $\alpha := \sum_{i = 1} ^\infty \alpha_i \otimes e_i \in \mathcal{H} \overline{\otimes} \ell^2$.
  Then 
  $$\sum_{i \in \N} \langle x \alpha_i, \alpha_i \rangle_{\mathcal{H}} = \langle (\id \otimes 1)(x) \alpha, \alpha \rangle_{\mathcal{H} \overline{\otimes} \ell^2}$$ 
  and similarly $$\left(\sum_{i \in \N}  \| x \alpha_i \|^2 _{\mathcal{H}}\right)^{\frac{1}{2}} = \| (\id \otimes 1)(x) \alpha \|_{\mathcal{H} \overline{\otimes} \ell^2}$$ 
\end{remark}

\begin{lemma}
  Let $\varphi: \bh \to \C$ be a linear functional operator. Then the following is equivalent.
  \begin{enumerate}
    \item $\exists a \in L^1 (\bh)$ such that $\varphi(x) = \trace (a x),\ \forall x \in \bh$;
    \item $\varphi$ is $\sigma$-WOT continuous;
    \item $\varphi$ is $\sigma$-SOT continuous.
  \end{enumerate}
\end{lemma}

\begin{myproof}
  As previously, the implication $(1) \Rightarrow (2) \Rightarrow (3)$ is obvious.
  Let us prove $(3) \Rightarrow (1)$. Assume $\varphi$ is $\sigma$-SOT continuous.
  By identifying $\bh$ via $\id \otimes 1$ with a subspace in $\mathcal{B} (\mathcal{H} \otimes \ell^2)$,
  $\varphi$ is SOT-continuous on this subspace. By Hahn-Banach, $\varphi$ extends to a SOT-continuous 
  linear functional on $\mathcal{B} (\mathcal{H} \otimes \ell^2)$.
  By the previous lemma, $\exists \alpha_1, \dots, \alpha_n, \beta_1, \dots, \beta_n \in \mathcal{H} \overline{\otimes} \ell^2$.
  $$\varphi(x) = \sum_{i = 1} ^n \langle (\id \otimes 1) (x) \alpha_i, \beta_i \rangle.$$
  With 
  $$\alpha_i \sum_{j = 1} ^\infty \alpha_{ij} \otimes e_j, \quad \sum_j \| \alpha_{ij} \|^2 < \infty$$
  and 
  $$\beta_i \sum_{j = 1} ^\infty \beta_{ij} \otimes e_j, \quad \sum_j \| \beta_{ij} \|^2 < \infty.$$
  Then 
  \begin{align*}
    \varphi(x) &= \sum_{i = 1} ^n \langle (x \otimes 1) \sum_{j = 1} ^\infty \alpha_{ij} \otimes e_j, \sum_{k = 1} ^\infty \beta_{ik} \otimes e_k\rangle\\
    &= \sum_{i = 1} ^n \sum_{j = 1} ^\infty \sum_{k = 1} ^\infty \langle x \alpha_{ij}, \beta_{ik}\rangle \langle e_j, e_k\rangle\\
    &= \sum_{i = 1} ^n \sum_{j = 1} ^\infty \langle x \alpha_{ij}, \beta_{ij}\rangle.
  \end{align*}
  Define $$A_i : \mathcal{H} \to \mathcal{H},\quad A_i f_k = \alpha_{ik}$$
  and $$B_i : \mathcal{H} \to \mathcal{H},\quad B_i f_k = \beta_{ik}$$
  for an orthonormal basis $(f_k)_{k \in \N}$. By assumption, $A_i, B_i \in L^2 (\bh)$.
  As before, this gives $\varphi (x) = \sum_i \trace (B_i ^* x A_i) = \trace (x A_i B_i^*)$.
\end{myproof}

\begin{corollary}
  The unit disk $(\bh)_1$ is compact with respect to $\sigma$-WOT topology.
\end{corollary}

\begin{myproof}
  $\sigma$-WOT on $\bh$ is the weak-* topology from $L^1 (\bh)^* = \bh$.
  The statement now follows from Banach-Alaoglu.
\end{myproof}

\begin{corollary}
  WOT and $\sigma$-WOT agree on bounded subsets $B \subseteq \bh$.
\end{corollary}

\begin{myproof}
  WLOG $B$ is closed. Then the identity $(B, \textrm{$\sigma$-WOT}) \to (B, \textrm{WOT})$
  is a continuous map from a $T_2$ compact (previous corollary) to a $T_2$ space.
  Therefore an identity map is a closed continuous bijection, so a homeomorphism.
\end{myproof}

We use the following notation: if $A$ is vector space and $B \subseteq \mathcal{L} (A, \C)$
is a set of linear functionals, then $\sigma(A, B)$ is the weakest topology in $A$ such that linear functionals in $B$ are continuous.

\begin{definition}
  Let $A$ be a vector space and $B \subseteq \mathcal{L} (A, \C)$ a set of some of its linear functionals.
  Then we define $\sigma(A, B)$ as the weakest topology such that functionals in $B$ are continuous. 
\end{definition}

\begin{remark}
  $\sigma$-WOT is $\sigma(\bh, L^1 (\bh))$.
\end{remark}

\begin{definition}
  Let us define the following topologies on $\bh$.
  \begin{enumerate}
    \item Weak Banach topology is $\sigma(\bh, \bh^*)$.
    \item Ultrastrong-* topology is the weakest topology stronger than $\sigma$-SOT such that * is continuous.
    \item Strong-* topology is generated by seminorms $x \mapsto \|x\alpha\|$ and $x \mapsto \|x^* \alpha\|$ for $\alpha \in \mathcal{H}$.
  \end{enumerate}
\end{definition}

In the end, we get the following diagram which demonstrates which topologies are comparable.

\[\begin{tikzcd}
	& {\textrm{norm}} \\
	{\textrm{weak Banach}} && {\textrm{ultrastrong-*}} \\
	& {\textrm{$\sigma$-SOT}} & {\textrm{strong-*}} \\
	{\textrm{$\sigma$-WOT}} && {\textrm{SOT}} \\
	& {\textrm{WOT}}
	\arrow[from=1-2, to=2-3]
	\arrow[from=1-2, to=2-1]
	\arrow[from=2-3, to=3-2]
	\arrow[from=2-3, to=3-3]
	\arrow[from=2-1, to=4-1]
	\arrow[from=3-2, to=4-1]
	\arrow[from=3-2, to=4-3]
	\arrow[from=3-3, to=4-3]
	\arrow[from=4-1, to=5-2]
	\arrow[from=4-3, to=5-2]
\end{tikzcd}\]

\section{von Neumann algebras}

\subsection{Bicommutant theorem}

\begin{definition}
  A von Neumann algebra (on Hilbert space $\mathcal{H}$) is a *-subalgebra of $\mathcal{B}(\mathcal{H})$
  that is WOT-closed. Equivalently, a *-subalgebras that is SOT-closed.
\end{definition}

\begin{definition}
  If $A \subseteq \bh$, then $W^* (A)$ denotes the vNa generated by $A$.
  This is equivalent to the smallest vNa in $\bh$ that contains $A$, which is equivalent to 
  $$\bigcap \{W \ |\ A \subseteq W,\ \textrm{$W \subseteq \bh$ is vNa} \}.$$
\end{definition}

\begin{lemma}
  Let $A \subseteq \bh$ be a vNa. Then $(A)_1$ is WOT-compact.
\end{lemma}

\begin{myproof}
  Follows from Banach-Alaoglu and $\sigma$-WOT and WOT topologies being equivalent on bounded sets.
\end{myproof}

\begin{corollary}
  Let $A \subseteq \bh$ vNa. Then $(A)_1$ and $A_{\sa}$ are SOT-closed and WOT-closed.
\end{corollary}

\begin{myproof}
  By the lemma above, * is continuous in WOT, so $A_{\sa}$ is closed in WOT.
  Since $A_{\sa}$ is convex, we use Hahn-Banach to see that it is also SOT-closed.
  The same exact argument applies for $(A)_1$.
\end{myproof}

\begin{definition}
  Commutant of $B \subseteq \bh$ is 
  $$B' = \{T \in \bh\ |\ \forall S \in B:\ ST = TS\}.$$
  Bicommutant is $B'' := (B')'$. By definition, $B'' \supseteq B$.
\end{definition}

\begin{theorem}
  Suppose $A \subseteq \bh$ is closed under *. Then $A'$ is vNa.
\end{theorem}

\begin{myproof}
  Obviously, $A'$ is a subalgebra of $\bh$ closed under *. We prove that it is WOT-closed.
  Let $(x_\alpha)_{\alpha}$ be a net in $A'$ that WOT-converges to $x \in \bh$.
  Pick $a \in A$ and $\varphi, \mu \in \mathcal{H}$. Then 
  \begin{align*}
    \langle [x, a]\varphi, \mu\rangle &= \langle (xa - ax) \varphi, \mu\rangle\\ 
    &= \langle x a \varphi, \mu\rangle - \langle a x\varphi, \mu\rangle\\
    &= \langle x a \varphi, \mu\rangle - \langle x\varphi, a^*\mu\rangle\\
    &= \lim_{\alpha} \langle x_\alpha a \varphi, \mu\rangle - \langle x_\alpha \varphi, a^*\mu\rangle\\
    &= \lim_{\alpha} \langle (x_\alpha a - a x_\alpha) \varphi, \mu\rangle\\
    &= \lim_{\alpha} \langle [x_\alpha, a]\varphi, \mu\rangle = 0,
  \end{align*}
  so $x \in A'$ and we're done.
\end{myproof}

\begin{corollary}
  Every vNa is unital.
\end{corollary}

\begin{example}
  For an infinitely-dimensional Hilbert space $\mathcal{H}$, the set of all compact operators $\mathcal{K}(\mathcal{H})$
  is not a vNa, since it doesn't include the identity (the latter is a consequence of Riesz lemma).
  Another way: as we'll see later, the finite-rank projections converge strongly to identity, $\mathcal{K} (\mathcal{H})$
  is not SOT-closed, so it is also not WOT-closed.
\end{example}

\begin{corollary}
  Suppose $A \subseteq \bh$ is a maximal commutative subalgebra and is closed under *.
  Then $A$ is vNa. 
\end{corollary}

\begin{myproof}
  Since $A$ is commutative, $A' \supseteq A$. Take $b \in A' \subseteq A$ and consider the subalgebra, generated by $A$ and $b$. This is an abelian algebra, so by maximality we have 
  we have $b \in A$ and $A = A'$. Then by theorem, $A$ is a vNa.
\end{myproof}

\begin{lemma}
  Let $A \subseteq \bh$ be a *-subalgebra. Then $\forall \mu \in \mathcal{H}$ and $\forall x \in A''$
  there exists a net $(x_\alpha)_\alpha$ in $A$ such that $\lim_\alpha \| (x_\alpha - x)\mu \| = 0$.
\end{lemma}

\begin{myproof}
  Define $\mathcal{K} := \overline{A \mu} \leq \mathcal{H}$. Let $p: \mathcal{H} \to \mathcal{K}$ be the orthogonal projection onto $\mathcal{K}$.
  By definition, $a \mathcal{K} \subseteq \mathcal{K},\ \forall a \in A$.
  Equivalently, $pap = ap$. Then 
  $$pa = (a^* p) ^* = (p a^* p)^* = pap = ap,$$
  so $p \in A'$. But $x \in A''$, so  
  $$xp = xp^2 = pxp$$
  and $x \mathcal{K} \subseteq \mathcal{K}$. In particular, since $\mu \in \mathcal{K}$, we have $x \mu \in \mathcal{K} = \overline{A\mu}$.
  So there must exist some net in $A \mu$ that converges to $x \mu$.
\end{myproof}

\begin{theorem}[von Neumann's bicommutant theorem]
  Let $A \subseteq \bh$ be a *-subalgebra. Then $\overline{A}^{\mathrm{WOT}} = A''$.
\end{theorem}

\begin{myproof}
  By the previous theorem, $A''$ is a vNa. In particular, it is WOT-closed.
  Since $A \subseteq A''$, it suffices to show that $A$ is WOT-dense in $A''$.
  Because $A$ is convex, it is enough  to show that $A$ is SOT-dense in $A''$.
  Let $x \in A''$ and $\mu_1,\dots, \mu_n \in \mathcal{H}$. Form the following subalgebra of $\mathcal{B} (\mathcal{H}^n) \cong M_n (\mathcal{B}(\mathcal{H})).$
  Define 
  $$\widetilde{A} = \left\lbrace \begin{bmatrix}
    a & &\\
    & \ddots &\\
    & & a
  \end{bmatrix} \in M_n (\bh)\ |\ a \in A\right\rbrace.$$
  Then $\widetilde{A}' = M_n (A')$.
  Hence we get 
  $$\widetilde{A''} \subseteq M_n (A') ' = \widetilde{A}''.$$
  This implies that $$\begin{bmatrix}
    x & &\\
    & \ddots &\\
    & & x
  \end{bmatrix} \in \widetilde{A''} \subseteq \widetilde{A}''.$$
  Now we apply lemma to $\widetilde{A}$ to get a net $(a_i)_i$ in $A$
  such that 
  \begin{equation*}
    \lim_{i} \| (x - a_i) \mu_j \| = 0,\quad \forall j = 1, \dots, n. \qedhere
  \end{equation*}
\end{myproof}

\begin{corollary}
  Let $A \subseteq \bh$ be a *-subalgebra. Then $A$ is a vNa iff $A = A''$.
\end{corollary}

\begin{remark}
  WOT-closed implies norm-closed. In particular, every vNa is a $C^*$-algebra.
  However, the converse is not always true: $\mathcal{C} ([0, 1])$ is a $C^*$-algebra that is not vNa.
\end{remark}


\begin{corollary}[Polar decomposition in vNa]
  Let $A \subseteq \bh$ be a vNa and $x \in A$.
  Then for its polar decomposition $x = v|x|$ we have $v \in A$.
\end{corollary}

\begin{myproof}
  We know that 
  $$\ker v = (\im |x|)^\perp = \ker |x| = \ker x.$$
  For $a \in A'$ and $\mu \in \ker x$ we have $a\mu \in \ker x$:
  $$x (a\mu) = a x\mu = 0,$$
  which implies $a \ker |x| \subseteq \ker |x|$.
  We know that $\mathcal{H} = \ker |x| \oplus \overline{\im |x|}$.
  Suppose that $|x| \mu \in \im |x|$. Then 
  \begin{align*}
    [a, v] |x| \mu &= (av - va) |x| \mu = av |x| \mu - va |x| \mu\\
    &= ax\mu - v|x| a \mu = ax\mu - xa\mu \\
    &= [a, x]\mu = 0.
  \end{align*}
  But for $\beta \in \ker |x| = \ker v$, we have
  $$[a, v] \beta = (av - va)\beta = av\beta - va \beta = 0.$$
  Since $av$ and $va$ agree on $\ker |x| \oplus \overline{\im |x|}= \mathcal{H}$, we have $v \in A'' = A$.
\end{myproof}

\begin{example}[Commutative vNa - IMPORTANT] \label{ex:1}
  Let $(X, \mu)$  be a $\sigma$-finite measure space and 
  $$M: L^\infty (X, \mu) \to B (L^p (X,\mu)),\quad g \mapsto M_g,$$
  where we define 
  $$(M_g f) (x) = g (x) f(x).$$
  Then $M$ is an isometric *-isomorphism $L^\infty (X, \mu) \to M(L^\infty (X, \mu))$
  and $M(L^\infty (X, \mu))$ is a maximal commutative vNa in $\mathcal{B} (L^2 (X, \mu))$.
\end{example}

\begin{remark}
  A measurable function $f: X \to \C$ is essentially bounded if there exists a real number $M$ (called an essential bound) such that 
  $$\mu \left(\left\lbrace x \in X\ |\ |f(x)| > M \right\rbrace\right) = 0.$$
  We define $\| f\|_{\infty}$ to be an essential supremum of $f$, which is the infimum of its essential bounds.
  If $\mathcal{L}^\infty (X, \mu)$ are essentially-bounded functions and $\mathcal{N} = \{f\ |\ \| f\|_\infty  = 0\}$.
  Then $\| \cdot \|_{\infty}$ is a norm on the space $L^\infty (X, \mu) = \quot{\mathcal{L}^\infty (X, \mu)}{\mathcal{N}}$.
\end{remark}

\begin{myproof}[Proof of the example]
  Clearly, $M$ is injective, additive and multiplicative.
  First, we prove that $M$ is a *-homomorphism. This follows from the next calculation:
  \begin{align*}
    \langle M_{\overline{g}} \mu, \varphi \rangle &= \int_X M_{\overline{g}} \mu \cdot \overline{\varphi}\, d\mu\\
    &= \int_X \overline{g}\mu \overline{\varphi}\\
    &= \int_X \mu \overline{g \varphi}\, d\mu\\
    &= \langle \mu, M_g\varphi\rangle = \langle M_g ^* \mu, \varphi \rangle,
  \end{align*}
  so $M_{\overline{g}} = M_g ^*$. Next, we prove that $M$ is isometric.
  For $g \in L^\infty (X, \mu)$, there exists a sequence $E_n \subseteq X$ such that $0 < \mu(E_n) < \infty$
  and $|g|\big|_{E_n} \geq \|g\|_{\infty} -\frac{1}{n}$ for all $n \in \N$.
  Then 
  $$\| M_g \| \geq \frac{\| M_g 1_{E_n}\|_2}{\| 1_{E_n}\|_2} \geq \|g\|_{\infty} - \frac{1}{n},\quad \forall n \in \N,$$
  which implies $\|M_g\| \geq \|g\|_{\infty}$.
  For the reverse, notice that 
  \begin{align*}
    \| M_g 1_{E_n} \|^2 &= \int_X |g \cdot 1_{E_n}|^2\, d\mu\\
    &= \int_{E_n} |g|^2\, d\mu\\
    &\geq \int_{E_n} (\|g\|_{\infty} - \frac{1}{n})^2\, d\mu \\
    &= (\|g\|_\infty -\frac{1}{n})^2 \cdot \mu(E_n)
  \end{align*}
  and 
  \begin{align*}
    \|M_g\|^2 &= \sup_{\| \mu\|_2 = 1} \| M_g \mu\|^2 _2 = \sup_{\| \mu\|_2 = 1} \int_X |g\mu|^2\, d\mu\\
    &\leq \|g\|_{\infty} ^2 \cdot \sup_{\| \mu\|_2 = 1} \int_X |\mu|^2\, d\mu = \|g\|_{\infty} ^2.
  \end{align*}
  We've just shown that $\|Mg\| = \|g\|_{\infty}$.
  Lastly, we prove that $M(L^\infty (X, \mu))$ is a maximal commutative subalgebra of $\mathcal{B}(L^2 (X, \mu))$.
  Take $T \in \mathcal{B}(L^2 (X, \mu))$ and assume it commutes with all $M_g$'s.
  Now pick a measurable sequence $E_n \subseteq X$ such that $0 < \mu(E_n) < \infty$, $E_n \subseteq E_{n + 1}$ and $X = \bigcup_{n \in \N} E_n$.
  Define $f_n := T(1_{E_n}) \in (X, \mu)$. First we prove that $f_n \in L^\infty (X, \mu)$. If $A$ is measurable and $0 < \mu(A) < \infty$, then 
  \begin{align*}
    \frac{1}{\mu(A)} \int_X |f_n \cdot 1_A|^2\, d\mu &= \frac{1}{\mu(A)} \cdot \|M_{1_A} T(1_{E_n})\|^2\\
    &= \frac{1}{\mu(A)} \cdot \| T(1_{A \cap E_n}) \|^2\\
    &\leq \frac{1}{\mu(A)} \cdot \|T\|^2 \cdot \|1_A \|^2 = \| T\|^2.
  \end{align*}
  If $f \notin L^\infty$, then for all $M \in \R$ we have 
  $$0 < \mu (\underbrace{\{x \in X\ |\ |f_n (x)| > M\}}_{A_{n, M}}) < \infty,$$
  since $f_n \in L^2$. By above calculation,
  $$M^2 \leq \frac{1}{\mu(A_{n, M})} \cdot \int_X |f \cdot 1_{A_{n, M}} |^2\, d\mu \leq \|T\|^2,$$
  which is of course a contradiction. This proves that $f_n \in L^\infty (X, \mu)$ and $\| f_n\|_{\infty} \leq \|T \|.$
  For $n \leq m$ we have 
  \begin{align*}
    1_{E_n} \cdot f_m &= 1_{E_n} \cdot T(1_{E_m})\\
    &= M_{1_{E_n}} (T (1_{E_m}))\\
    &= T(M_{1_{E_n}} 1_{E_m})\\
    &= T(1_{E_n} 1_{E_m}) = f_n.
  \end{align*}
  Therefore, $f_m \big|_{E_n} = f_n$. Sequence $(f_n)_n$ converges to a measurable $f: X \to \C$.
  From $\| f_n\|_{\infty} \leq \|T\|$ for all $n \in \N$ we also deduce $\|f\|_{\infty} \leq T$,
  so $f \in L^\infty (X, \mu)$. Lastly, we prove $T = M_f$.
  Note that simple functions $\sum_{j = i} ^r \alpha_j 1_{A_j}$ are $L^2$-dense.
  Let $A \subseteq X$ be measurable with $\mu(A) < \infty$.
  Then $\| 1_{A \cap E_n} - 1_A\|_2 \xrightarrow{n \to \infty} 0$.
  Hence $$\| (T - M_f) 1_A \|_2 = \lim_{n \to \infty} \| (T - M_f) 1_{A \cap E_n} \|_2 = 0,$$ as we shall prove.
  \begin{align*}
    T(1_{A \cap E_n}) &= T(1_A \cdot 1_{E_n}) = T(M_{1_A} 1_{E_n})\\
    &= M_{1_{A}} (T(1_{E_n})) = M_{1_A} (f_n)\\
    &= 1_A \cdot f_n.
  \end{align*}
  On the other hand,
  $$M_f (1_{A \cap E_n}) = f \cdot 1_{A \cap E_n} = f \cdot 1_{E_n} \cdot 1_A = 1_A \cdot f_n$$
  and we are done.
\end{myproof}


Another possible characterization of vNa's is given by the following.

\begin{theorem}[Sakai]
  Let $A$ be a $C^*$-algebra such that for a Banach space there exists an isometric *-isomorphism 
  $A \to E^*$. Then there exists a vNa $B \subseteq \bh$ such that $A \cong B$ as a $C^*$-algebra.
\end{theorem}

For the proof, see R.V.Kadison's \emph{The von Neumann algebra characterization theorems} (1985).

\subsection{Kaplansky's density theorem}

\begin{lemma}
  Multiplication $(A, B) \mapsto A \cdot B$ is SOT-continuous on bounded sets.
\end{lemma}

\begin{myproof}
  Let $(A_i)_i$ and $(B_i)_i$ be nets with 
  $\sup \| A_i\|, \sup \|B_i\| < M$ for some $M \in \R$.
  Suppose $A_i \to A$ and $B_i \to B$ in SOT. For any $x$, we get 
  \begin{align*}
    \|ABx - A_i B_i x\| &= \| ABx - A_i Bx + A_i Bx - A_i B_i x\|\\
    &\leq \|AB x - A_i Bx\| + \|A_i Bx - A_i B_ix\|\\
    &\leq \|A(Bx) - A_i (Bx)\| + \|A_i\| \cdot \|Bx - B_i x\|\\
    &\leq \|A(Bx) - A_i (Bx)\| + M \cdot \|Bx - B_i x\|\to 0,
  \end{align*}
  so $A_i B_i \xrightarrow{\textrm{SOT}} AB$.
\end{myproof}

\begin{proposition}
  Let $f \in C (\C)$. Then $x \mapsto f(x)$ is SOT-continuous on each bounded set of normal operators in $\mathcal{B}(\mathcal{H})$.
\end{proposition}

\begin{myproof}
  By Stone-Weierstrass, we can uniformly approximate $f$ by polynomials on a bounded subset $B_R (0) \subseteq \C$.
  By the previous lemma, multiplication is SOT-continuous on this bounded set of normal operators.
  But for normal operator $A$, we have $\|Ax\| = \|A^*x\|$ for every $x\in \mathcal{H}$, so * is also SOT-continuous on normal operators and we're done.  
\end{myproof}

\begin{theorem}[Cayley transform]
  Mapping $x \mapsto (x - i)(x + i)^{-1}$ is SOT-continuous $\bh_{\sa} \to \mathcal{U} (\mathcal{H})$.
\end{theorem}

\begin{myproof}
  If $x \in \mathcal{B}(\mathcal{H})_{\sa}$, then $\sigma(x) \subseteq \R$ and $(x + i) \in \bh$ is invertible.
  We notice that $z \mapsto \frac{z - i}{z + i}: \R \to \C$ has its range in $\mathbb{T}$,
  so the Cayley transform does in fact map into the unitaries. Now onto the SOT-continuity:
  let $(x_k)_k$ be a net in $\mathcal{B}(\mathcal{H})_{\sa}$ with $x_k \to x$ in SOT.
  By spectral mapping theorem, $\| (x_k + i)^{-1} \| \leq 1.$ For each $\alpha \in \mathcal{H}$,
  we have
  \begin{align*}
    \|(x - i) (x + i)^{-1} \alpha - (x_k - i)(x_k + i)^{-1} \alpha\| &= \| (x_k + i)^{-1} \left((x_k + i) (x - i) (x + i^{-1}) - (x_k - i)\right) \alpha \|\\
    &= \| (x_k + i)^{-1} \left((x_k + i) (x - i) - (x_k - i)(x + i)\right) (x + i)^{-1} \alpha \|\\
    &= \| (x_k + i)^{-1} 2i (x - x_k) (x + i)^{-1} \alpha\|\\
    &\leq 2 \|(x_k + i)^{-1}\| \|(x - x_k)\underbrace{(x + i)^{-1} \alpha}_{\beta}\|\\
    &\leq 2\| (x - x_k) \beta\| \to 0. \qedhere
  \end{align*}
\end{myproof}

\begin{corollary}
  If $f \in C_0(\R)$, then $x \mapsto f(x)$ is SOT-continuous on $\mathcal{B}(\mathcal{H})_{\sa}$.
\end{corollary}

\begin{myproof}
  Suppose 
  $$g(t) = \begin{cases}
    f\left(i \frac{1 + t}{1 - t}\right);& t \neq 1\\
    0;& t = 1
  \end{cases}$$
  which maps $\mathbb{T} \to \C$.
  By previous proposition, $x \mapsto g(x)$ is SOT-continuous on unitaries.
  Letting $U(z) = \frac{z - i}{z + i}$, denote the Cayley transform, we have that 
  $f = g \circ U$ is a composite of two SOT-continuous maps, which is a SOT-continuous map of itself.
\end{myproof}

\begin{theorem}[Kaplansky's density theorem]
  Let $A \subseteq \bh$ be a *-subalgebra and $B = \overline{A}^{\mathrm{SOT}}$,
  then \begin{enumerate}
    \item $\overline{A_{\sa}}^{\mathrm{SOT}} = B_{\sa}$;
    \item $\overline{(A)_1}^{\mathrm{SOT}} = (B)_1$.
  \end{enumerate}
\end{theorem}

\begin{myproof}
  WLOG $A$ is a $C^*$-algebra, so norm-closed.
  \begin{enumerate}
    \item First we prove that $\overline{A_{\sa}}^{\mathrm{SOT}} \subseteq B_{\sa}$.
    Since $\overline{A_{\sa}}^{\mathrm{SOT}} = \overline{A_{\sa}}^{\mathrm{WOT}}$, take $x \in \overline{A_{\sa}}^{\mathrm{SOT}}$
    and the net $(x_k)_k \subseteq A_{\sa}$ converges to $x$. Since * is WOT continuous, 
    $(x_k ^*)_k = (x_k)_k$ converge to $x^*$, so $x = x^*$.
    Now the converse inclusion: suppose the net $(x_k)_k$ SOT-converges to $x \in B_{\sa}$.
    Then $\frac{x_k + x_k^*}{2} \to x$ in WOT-topology, which implies 
    $$B_{\sa} \subseteq \overline{A_{\sa}}^{\mathrm{WOT}} = \overline{A_{\sa}}^{\mathrm{SOT}}.$$
    \item Suppose the net $(y_i)_i$ in $A_{\sa}$ SOT-converges to $x \in B_{\sa}$.
    Take $f \in C_0 (\R)$ such that for all we have $f(t) = t,\ \forall |t| \leq \|x\|$ and $|f(t)| \leq \|x\|,\ \forall t \in \R$. 
    By functional calculus, $\| f(y_k)\| \leq \|x\|$. By the previous corollary, $(f(y_i))_i \xrightarrow{\mathrm{SOT}} f(x) = x$.
    This proves that $(A)_1 \cap A_{\sa}$ is SOT-dense in $(B)_1 \cap B_{\sa}$.
    Pass over to $M_2 (\bh) = \mathcal{B} (\mathcal{H} \oplus \mathcal{H})$.
    Then $M_2 (A)$ is SOT-dense in $M_2 (B)$ by assumption. For $x \in (B)_1$, we have 
    $$\widetilde{x} = \begin{pmatrix}
      0 & x\\
      x^* & 0
    \end{pmatrix} \in (M_2 (B))_1 \cap (M_2 (B))_{\sa}.$$ 
    That means there exists a net $$\widetilde{x_i} = \begin{pmatrix}
      a_i & b_i\\
      c_i & d_i
    \end{pmatrix} \in (M_2 (A))_1$$ such that $\widetilde{x_i} \to \widetilde{x}$
    and therefore $b_i \in (A)_1$ converge to $x$. \qedhere
  \end{enumerate}
\end{myproof}

\begin{corollary}
  Let $A \subseteq \bh$ be a *-algebra. Then $A$ is a vNa iff $(A)_1$ is SOT-closed.
\end{corollary}

\subsection{Examples of vNa's}

\begin{definition}
  A vNa $M$ is called a factor if $Z(M) = M \cap M' = \C \cdot 1$.
\end{definition}

\begin{example}
  Clearly, $\bh$ is a factor. If $n = \dim \mathcal{H} < \infty$, then $M_n (\C)$ is a factor.
\end{example}

Let $\Gamma$ be a group and $\mathcal{H} = \ell^2 (\Gamma)$. Consider the left regular representation
$$\lambda: \Gamma \to \mathcal{B} (\ell^2 (\Gamma)),\quad g \mapsto (\delta_h \mapsto \delta_{gh})$$
and extend linearly to $\lambda: \C [\Gamma] \to \mathcal{B} (\ell^2 (\Gamma)).$
The group vNa of $\Gamma$ is $VN (\Gamma) := \lambda (\C [\Gamma]) ''$
in $\mathcal{B} (\ell^2 (\Gamma))$. It has a trace, which is the linear functional 
$$\tau: VN(\Gamma) \to \C,\quad x \mapsto \langle x \delta_e, \delta_e\rangle.$$
For $g \in \Gamma$, $\tau (\lambda (g)) = 1$ if $g = e$, otherwise zero.
For $g_1, \dots, g_r \in \Gamma$, we have 
$$g_1 \dots g_r = e \Leftrightarrow \tau (\lambda (g_1) \dots \lambda (g_r)) = 1.$$
Since $\tau$ is a positive linear functional and $\tau(1) = 1$, $\tau$ is a state.
For any two elements $g, h \in \Gamma$ we have $gh = e \Leftrightarrow hg = e$, which together with the above line implies 
$$\tau(\lambda(g) \lambda(h)) = \tau (\lambda(h) \lambda (g)).$$
By linearity, $\tau$ has a cyclic property on $\lambda (\C [\Gamma])$.
But since $\tau$ is, by definition, WOT-continuous and $VN(\Gamma) = (\lambda(\C [\Gamma]))'' = \overline{\lambda(\C [\Gamma])}^{\mathrm{WOT}}$,
$\tau$ is cyclic on the entire $VN(\Gamma)$. Now if $|\Gamma| = \infty$,
then $VN(\Gamma) \neq \bh$, since the latter does not have a trace if $\dim \mathcal{H} = \infty$.
If $\Gamma$ is Abelian, then $VN(\Gamma)$ is commutative. 

\begin{definition}
  Group $\Gamma$ has icc (infinite conjugacy classes) if for all $g \in \Gamma \setminus \{e\}$
  the set $\{f^{-1} g f\ |\ f \in \Gamma\}$ is infinite.
\end{definition}

\begin{example}
  The group 
  $$S_{\infty} = \{\textrm{bijections $\N \to \N$ that only permute finitely many elements}\}$$ has icc.
\end{example}

\begin{example}
  Free groups $\F_n$ for $n > 1$ have icc.
\end{example}

\begin{theorem}
  If $\Gamma$ has icc, then $VN(\Gamma)$ is a factor.
\end{theorem}

\begin{definition}
  $VN(S_\infty) =: R$ is the hyperfinite $II_1$-factor.
\end{definition}

Open problem: does $VN (\F_2) \cong VN (\F_3)$ hold?

\subsection{Operations with vNa's}

\subsubsection*{Direct sums}

Let $M_i \subseteq \mathcal{B}(\mathcal{H}_i)$ be vNa's.
Define the isometric embedding 
$$\iota_j : \mathcal{B}(\mathcal{H}_j) \to \mathcal{B}(\mathcal{H}_1 \oplus \dots \oplus \mathcal{H}_n),\quad x \mapsto ((\alpha_1, \dots, \alpha_n) \mapsto (0, \dots, 0, x\alpha_j, 0, \dots, 0)).$$
This map is the $n \times n$ bounded matrix where the $(j, j)$-th element is $x$ and the rest are zero.
Then 
$$M_1 \oplus \dots \oplus M_n := \linspan \{\iota_j (x)\ |\ j = 1, \dots, n,\ x \in M_j\}$$
is the direct sum of vNa's. If $n \geq 2$, then from 
$$Z(M_1 \oplus \dots \oplus M_n) = Z(M_1) \oplus \dots \oplus Z(M_n),$$
we deduce that $M_1 \oplus \dots \oplus M_n$ is not a factor.

\subsubsection*{Tensor products}

The algebraic tensor product $\mathcal{B}(\mathcal{H}_1) \otimes \dots \otimes \mathcal{M} (\mathcal{H}_n)$
acts on $\mathcal{H}_1 \overline{\otimes} \dots \overline{\otimes} \mathcal{H}_n$ by
$$(x_1 \otimes \dots \otimes x_n) (\alpha_1 \otimes \dots \otimes \alpha_n) = (x_1 \alpha_1) \otimes \dots \otimes (x_n \alpha_n)$$
for $x_j \in \mathcal{B} (\mathcal{H}_j)$ and $\alpha_j \in \mathcal{H}_j$, which implies 
$$\mathcal{B}(\mathcal{H}_1) {\otimes} \dots {\otimes} \mathcal{B}(\mathcal{H}_n) \subseteq \mathcal{B}(\mathcal{H}_1 \overline{\otimes} \dots \overline{\otimes} \mathcal{H}_n).$$
Finally, we define the tensor product of vNa's as 
$$M_1 \overline{\otimes} \dots \overline{\otimes} M_n = (M_1 {\otimes} \dots {\otimes} M_n)'' \cap \mathcal{B}(\mathcal{H}_1 \overline{\otimes} \dots \overline{\otimes} \mathcal{H}_n).$$
 
\subsubsection*{Compressions}

\begin{definition}
  Let $M \subseteq \mathcal{B}(\mathcal{H})$ be a vNa and $p \in \mathcal{B}(\mathcal{H})$ a projection.
  A compression of $M$ is $p M p = \{pxp\ |\ x \in M\}$.
  When $p \in M$, it is also called a corner.
\end{definition}

If $\mathcal{H} = \im p \oplus (\im p)^{\perp} = \im p \oplus (1 - p)$.
In this basis, elements of $p M p$ has the matrix form 
$$\begin{bmatrix}
  pxp & 0\\
  0 & 0
\end{bmatrix}.$$
If $M \ni p \neq 1$, then $pMp$ is a $*$-algebra and $pMp \subseteq M$
but it is not a subalgebra since $1_{M} = 1 _{\mathcal{B}(\mathcal{H})} \notin pMp$.
However, $pM p$ is a subalgebra of $\mathcal{B}(p\mathcal{H})$ with identity element $p$. 

\begin{definition}
  Let $\mathcal{K} \subseteq \mathcal{H}$ and $x \in \mathcal{B}(\mathcal{H})$.
  \begin{enumerate}
    \item $\mathcal{K}$ is invariant for $x$ if $x \mathcal{K} \subseteq \mathcal{K}$;
    \item $\mathcal{K}$ is reducing for $x$ if $\mathcal{K}$ is invariant for both $x$ and $x^*$.
  \end{enumerate}
  Now if $S \subseteq \mathcal{B}(\mathcal{H})$, then 
  \begin{enumerate}
    \item $\mathcal{K}$ is invariant for $S$ if $x \mathcal{K} \subseteq \mathcal{K}$ for all $x \in S$;
    \item $\mathcal{K}$ is reducing for $S$ if $\mathcal{K}$ is reducing for all $x \in S$.
  \end{enumerate}
\end{definition}

If $S \subseteq \bh$ is closed under *, then $\mathcal{K}$ is invariant for $S$ iff it is reducing for $S$. 

\begin{lemma}\label{lem:1}
  Let $\mathcal{K}^{\mathrm{closed}} \leq \mathcal{H}$ and $M \subseteq \bh$ an *-algebra.
  Let $p: \mathcal{H} \to \mathcal{K}$ be an orthogonal projection. Then $\mathcal{K}$ is reducing for $M$ iff $p \in M'$.
\end{lemma}

\begin{theorem}
  Let $M \subseteq \bh$ be a vNa and $p \in M$ a projection.
  Then $p M p$ and $M' p$ are vNa's in $\mathcal{B}(p \mathcal{H})$.
\end{theorem}

\begin{myproof}
  We will show that 
  $$(M' p)' \cap \mathcal{B} (p\mathcal{H}) = pM p,\quad (p M p)' \cap \mathcal{B} (p\mathcal{H}) = M' p.$$
  Then the bicommutant theorem will take care of the rest. 
  It is obvious that $(M' p)' \cap \mathcal{B} (p\mathcal{H}) \supseteq pM p$.
  For the converse, pick $x \in (M' p)' \cap \mathcal{B} (p\mathcal{H})$.
  Define $\widetilde{x} = xp = px  \in \mathcal{B}(\mathcal{H})$.
  For $y \in M'$, we have 
  $$y \widetilde{x} = ypx = xyp = xpy = \widetilde{x} y,$$
  which implies $\widetilde{x} \in M'' = M$.
  Then $x = pxp = p\widetilde{x}p \in pMp$.
  As before $(p M p)' \cap \mathcal{B} (p\mathcal{H}) \supseteq M' p$
  is trivial and we just prove the converse. Take $y \in (pMp)' \cap \mathcal{B}(p\mathcal{H})$. Using CFC, we can write $y$ as 
  a linear combinations of $4$ unitaries. Since $pMp$ is closed under $*$,
  $(pM p)'$ is a vNa (and therefore a $C^*$-algebra). So we can assume WLOG that $y = u$ a unitary.
  Set $\mathcal{K} := \overline{M p \mathcal{H}}$ and $q: \mathcal{H} \to \mathcal{K}$ an orthogonal projection.
  Since $\mathcal{K}$ is reducing for $M$ and $M'$, which implies 
  $$q \in M' \cap M'' = M' \cap M = Z(M).$$
  Next, we extend $u$ to $\mathcal{K}$:
  $$\widetilde{u} (\sum_i \underbrace{x_i}_{\in M} p \underbrace{\alpha_i}_{\in \mathcal{H}}) = \sum_i x_i u p \alpha_i.$$
  We shall show that this is a well-defined isometry in $Mp\mathcal{H}$:
  \begin{align*}
    \| \widetilde{u} \sum_i x_i p \alpha_i \|^2 &= \sum_{i, j} \langle x_i u p \alpha_i, x_j u p \alpha_j \rangle\\
     &= \sum_{i, j} \langle(p x_j^* x_i p) u \alpha_i, u\alpha_j \rangle\\
     &= \sum_{i, j} \langle u p x_j^* x_i p \alpha_i, u\alpha_j \rangle\\ 
     &= \sum_{i, j} \langle p x_j^* x_i p \alpha_i, \alpha_j \rangle = \| \sum_i x_i p \alpha_i\|^2. 
  \end{align*}
  So $\widetilde{u}$ extends to an isometry on $\mathcal{K} = \overline{M p \mathcal{H}}$.
  By definition, $\widetilde{u}$ commutes with $M$ on $M p \mathcal{H}$, so also on $\mathcal{K}$.
  Thus for every $x \in M$ and $\alpha \in \mathcal{H}$, we have 
  $$x (\widetilde{u} q) \alpha = \widetilde{u} x q \alpha = (\widetilde{u} q)x \alpha,$$
  which implies $\widetilde{u} q \in M' \cap \bh$.
  Then $$\widetilde{u} qp \alpha = \widetilde{u} 1 p \alpha = 1 u p \alpha,$$
  which implies 
  $u = \widetilde{u} q p \in \bh$
  and $u \in M'p$. 
\end{myproof}

\begin{corollary}
  Suppose the vNa $M \subseteq \bh$ is a factor and let $p \in M$
  be a projection. Then $pMp$ and $M' p$ are factor (in $\mathcal{B}(p \mathcal{H})$).
\end{corollary}

\begin{myproof}
  Let $\mathcal{K} = \overline{Mp \mathcal{H}}$ and $q: \mathcal{H} \to \mathcal{K}$ a projection.
  From the previous proof, $q \in Z(M) = \C$. Then $q \in \{0, 1\}$. WLOG $p \neq 0$, so $q = 1$.
  Thus $\mathcal{K} = \mathcal{H}$, so $Mp\mathcal{H}$ is dense in $\mathcal{H}$.
  Consider $$\psi: M' \to M' p,\quad y \mapsto yp.$$
  We will prove that $\psi$ is an isomorphism of algebras. Obviously, it is additive.
  Since 
  $$\psi(xy) = xyp = xyp^2 = xpyp = \psi(x)\psi(y),$$
  it is also multiplicative. Same calculation shows $\psi(y^*) = \psi(y)^*$.
  Obviously, $\psi$ is surjective. Finally, we prove injectivity. Suppose $y \in M'$ satisfies $yp = 0$.
  Then for every $x \in M$ and $\alpha \in \mathcal{H}$, we get $yxp\alpha = x(yp)\alpha = 0.$
  Hence $y\big|_{Mp\mathcal{H}} = 0$, so by continuity, $y\big|_{\overline{Mp\mathcal{H}}} = y\big|_{\mathcal{K}} = 0$.
  But because $\mathcal{K} = \mathcal{H}$, this yields $y\big|_{\mathcal{H}} = 0$.
  As a result, we get 
  $$Z(M' p) = Z(M') p = \C \cdot p,$$ so $M' p$ is a factor.
  Similarly,
  $$Z(pMp) = (pMp) \cap (pMp)' = (M'p)' \cap M'p = Z(M'p) = \C p,$$
  so $pMp$ is a factor. 
\end{myproof}

\section{Spectral theorem and Borel functional calculus}

\subsection{Spectral theorem}

Recall the spectral theorem for $\mathcal{K(\mathcal{H})}$.
Let $T \in \mathcal{K} (\mathcal{H})$ be self-adjoint and for $\lambda \in \sigma_p (T)$, define $E(\lambda)$
as an orthogonal projection onto the eigenspace $\ker (T - \lambda I)$.
For $\mu \neq \lambda$, we get $E(\lambda) E(\mu) = 0$ and 
$$T = \sum_{\lambda \in \sigma_p (T) \setminus \{0\}} \lambda E(\lambda).$$
Our first goal will be to generalize this to non-compact self-adjoint operator.

\begin{theorem}[Vigier]
  Let $(u_\lambda)$ be a net of increasing (decreasing) and above (below) bounded self-adjoint operators on $\mathcal{H}$.
  Then $(u_\lambda)$ converges.
\end{theorem}

\begin{myproof}
  We prove the statement for above-bounded increasing net. We can assume $(u_\lambda)$ has a lower bound $m$ by considering a truncated net. 
  WLOG we can assume $u_\lambda$ are positive (otherwise we can consider $u_\lambda - m$).
  There exists $M \geq 0$ such that $\|u_\lambda\| \leq M$ for indices $\lambda$. So the net $\langle u_\lambda x, x\rangle$
  is real and increasing and bounded above by $M \|x\|^2$. Using the polarization identity 
  $$\langle u_\lambda x, x\rangle = \frac{1}{4} \sum_{k = 0} ^3 i^k \langle u_\lambda (x + i^k y), x + i^k y\rangle,$$
  we see that $\langle u_\lambda x, y\rangle$ is an convergent net for all $x, y \in \mathcal{H}$.
  Letting $\sigma(x, y)$ denote its limit, we can eaasily check that $\sigma$ is a bounded sesquilinear form ($|\sigma(x, y)| \leq M\|x\| \|y\|$).
  By Riesz, there exists an operator $u \in \mathcal{B} (\mathcal{H})$ such that $\langle ux, y\rangle = \sigma(x, y)$.
  Then $u$ is self-adjoint, $\|u\| \leq M$ and $u_\lambda \leq u$. Note that 
  \begin{align*}
    \| (u - u_\lambda)x\|^2 &\leq \| (u - u_\lambda)^{\frac{1}{2}} (u - u_\lambda)^{\frac{1}{2}} x \|^2\\
    &\leq \| (u - u_\lambda) \| \| (u - u_\lambda)^{\frac{1}{2}} x\|^2\\
    &\leq 2M \langle (u - u_\lambda)x, x\rangle \to 0,
  \end{align*}
  so $u_\lambda$ converge strongly to $u$.
\end{myproof}

\begin{remark}
  If $(p_\lambda)$ is a net of projections converging strongly to some operator $u$, then $u$ is also a projection.
  Clearly, $u$ is self-adjoint and 
  \begin{align*}
    \langle ux, y \rangle &= \lim_{\lambda} \langle p_\lambda x, y\rangle = \lim_{\lambda} \langle p_\lambda x, p_\lambda y \rangle\\
    &= \langle ux, uy\rangle = \langle u^2 x, y\rangle,
  \end{align*}
  therefore $u^2 = u$.
\end{remark}

\begin{corollary}
  If $(p_n)_{n \in \N}$ is a sequence of pairwise orthogonal orthogonal projections in $\bh$,
  then $\left(\sum_{n = 1} ^N p_n\right)$ SOT-converges for $N \to \infty$ (we denote the limit by $\sum_{n = 1} ^\infty p_n$). 
\end{corollary}

\begin{definition}
  Let $X$ be a set, $\Omega$ a $\sigma$-algebra in $X$ and $\mathcal{H}$ a Hilbert space.
  Then we define a projection-valued measure (PVM) for $(X, \Omega, \mathcal{H})$ is a map 
  $E: \Omega \to \bh$ such that 
  \begin{enumerate}
    \item $E(S)$ is a projection for all $S \in \Omega$;
    \item $E(\emptyset) = 0$ and $E(X) = 1$;
    \item $E(S \cap T) = E(S) E(T)$ for all $S, T \in \Omega$;
    \item If $(S_n)_{n \in \N} \subseteq \Omega$ is a sequence of pairwise disjoint sets, then 
    $$E (\bigcup_{n = 1} ^\infty S_n) = \sum_{n = 1} ^\infty E(S_n).$$
  \end{enumerate}
\end{definition}

\begin{remark}
  Projections $E (S)$ commute with each other (follows directly from the third point of the definition).
\end{remark}

\begin{example}
  Let $(X, \Omega, \mu)$ be a $\sigma$-finite measure space.
  Let $\mathcal{H} = L^2 (X, \mu)$ and $S \in \Omega$, then 
  $\chi_S \in L^\infty (X, \mu) \subseteq \mathcal{B} (L^2 (X, \mu))$ is a projection (with pointwise multiplication in $\bh$).
  Letting $E(S) := \chi_S \in \mathcal{B} (L^2 (X, \mu))$, we get a PVM $E: \Omega \to \mathcal{B}(L^2 (X, \mu))$.
\end{example}

\begin{lemma}
  Let $E$ be a PVM for $(X, \Omega, \mathcal{H})$. Then for all $\alpha, \beta \in \mathcal{H}$ the mapping 
  $$E_{\alpha, \beta} : \Omega \to \C,\quad S \mapsto \langle E(S) \alpha, \beta\rangle$$
  is a complex measure in $\Omega$ with total variation $\leq \|\alpha\| \|\beta\|.$
\end{lemma}

\begin{myproof}
  Let $\alpha, \beta \in \mathcal{H}$. Then $E_{\alpha, \beta}$ is $\sigma$-additive
  (countably-additive for disjoint sets) since $E$ is $\sigma$-additive by (4).
  Total variation of a complex measure is 
  $$\| E_{\alpha, \beta} \| := \sup \{\sum_{S \in \pi} |E_{\alpha, \beta} (S)|\},$$
  where the sum is over all partitions of $X$ into finitely many pieces of measurable sets.
  Let $\pi = \{S_1, \dots, S_n\}$ be a partition of $X$ with $S_j \in \Omega$.
  For each $j$ pick $\alpha_j \in \C$ such that $|\alpha_j| = 1$ and 
  $$\alpha_j \cdot E_{\alpha, \beta} (S_j) = \alpha_j \langle E(S_j)\alpha, \beta\rangle = |\langle E(S_j) \alpha, \beta\rangle| = |E_{\alpha, \beta} (S_j)|.$$
  Then $$\sum_{j = 1} ^n |E_{\alpha, \beta} (S_j)| = \langle \sum \alpha_j E(S_j) \alpha, \beta\rangle| \leq \| \sum \alpha_j E(S_j) \alpha\| \cdot \|\beta\|.$$
  For $i \neq j$ we have $$E(S_i) E(S_j) = E(S_i \cap S_j) = E(\emptyset) = 0,$$
  so $E(S_i)$ are pairwise orthogonal. Finally, we can use Pythagoras to get 
  \begin{align*}
    \| \sum_{j = 1} ^n \alpha_j E(S_j) \alpha\|^2 &= \sum_{j = 1} ^n \| E(S_j) \alpha\|^2\\
    &= \| \sum_{j = 1} ^n E(S_j) \alpha\|^2\\
    &= \| E\left(\bigcup_{j = 1} ^n S_j\right) \alpha\|^2\\
    &= \| E(X) \alpha\|^2 = \|\alpha \|^2. \qedhere
  \end{align*}
\end{myproof}

\begin{remark}
  Let $E$ be a PVM for $(X, \Omega, \mathcal{H})$, $\alpha \in \mathcal{H}$ and $S \in \Omega$.
  Then \begin{align*}
    E_{\alpha, \alpha} (S) &= \langle E(S) \alpha, \alpha\rangle\\
    &= \langle E(S)^2 \alpha, \alpha\rangle\\
    &= \langle E(S) \alpha, E(S) \alpha\rangle \geq 0,
  \end{align*}
  so $E_{\alpha, \alpha}$ is a positive measure on $X$.
  Furthermore, if $\|\alpha\| = 1$, then $E_{\alpha, \alpha}$ is a probability measure.
\end{remark}

Let $$(\alpha, \beta) \mapsto \int_X 1 dE_{\alpha, \beta}.$$ Since 
$E_{\alpha + \lambda \alpha', \beta} = E_{\alpha, \beta} + \lambda E_{\alpha', \beta}$ and
$E_{\alpha, \beta + \lambda \beta'} = E_{\alpha, \beta} + \overline{\lambda} E_{\alpha, \beta'}$,
the above is a sesquilinear form on $\mathcal{H}$. In particular, it is bounded
$$\| \int_X dE_{\alpha, \beta}\| \leq \| E_{\alpha, \beta}\| \leq \|\alpha\| \|\beta\|.$$
Suppose $f: X \to \C$ is a bounded $\Omega$-measurable function. Then 
$$(\alpha, \beta) \mapsto \int_X f dE_{\alpha, \beta}$$
is a bounded sesquilinear form:
$$\| \int_X f\, dE_{\alpha, \beta}\| \leq \|f\|_{\infty} \| E_{\alpha, \beta}\| \leq \|f\|_{\infty} \|\alpha\| \|\beta\|.$$
So there exists an $x \in \bh$ such that $\| x\| \leq \| f\|_\infty$ and 
$\langle x \alpha, \beta \rangle = \int_X f\, dE_{\alpha, \beta}$.
If $f = \chi_S$ for $S \in \Omega$, then $x = E(S)$:
$$\int_X \chi_S\, dE_{\alpha, \beta} = E_{\alpha, \beta} (S) = \langle E(S) \alpha, \beta \rangle.$$

\begin{definition}
  Let $E$ be a PVM for $(X, \Omega, \mathcal{H})$ and $f: X \to \C$ be a bounded $\Omega$-measurable 
  function and $x \in \bh$. We call $x$ the integral of $f$ with regards to $E$ if 
  $$\langle x\alpha, \beta \rangle = \int_X f\, dE_{\alpha, \beta},\quad \forall \alpha, \beta \in \mathcal{H}.$$
  We denote it by $x := \int_X f\, dE$.
\end{definition}

\begin{remark}
  Define $B(X, \Omega)$ as the set of all bounded $\Omega$-measurable complex functions on $X$ and endow it with the sup norm.
  If $X$ is a topological space and $\Omega = \mathcal{B}_X$ is the Borel $\sigma$-algebra on $X$,
  then $B(X) = B(X, \mathcal{B}_X)$.
\end{remark}

\begin{proposition}
  Let $E$ be a PVM for $(X, \Omega, \mathcal{H})$. Then 
  $$\rho: B(X, \Omega) \to \bh,\quad f \mapsto \int_X f\, dE.$$
  is a *-homomorphism and contractive. Furthermore:
  \begin{enumerate}
    \item If $(f_n)_n \subseteq B (X, \Omega)$ is an increasing sequence of nonnegative functions 
    and $f = \sup_n f_n \in B (X, \Omega)$, then $\int_X f_n dE \to \int_X f\, dE$ in SOT.
    \item If $X$ is compact and $T_2$, then $\rho (B (X)) \subseteq \rho (C(X))''$.
  \end{enumerate}
\end{proposition}

\begin{myproof}
  We already saw that $\|\rho (f)\| \leq \| f\|_{\infty}$, hence $\rho$ is contractive.
  It is also clear that $\rho$ is linear and $\rho (f)^* = \rho (\overline{f})$.
  Next, we prove multiplicativity: $\rho (\chi_S) = E(S)$ for $S \in \Omega$.
  Then $$\rho (\chi_S) \cdot \rho (\chi_T) = E(S) \cdot E(T) = E(S \cap T) = \rho (\chi_{S \cap T}) = \rho (\chi_S \cdot \chi_T).$$
  Since $\rho$ is linear, it is also multiplicative on simple functions (these are finite linear combinations of characteristic functions). 
  Since each $f \in B (X, \Omega)$ is a uniform limit of a uniformly bounded sequence of simple functions,
  we deduce that $\rho (fg) = \rho (f) \rho (g)$ for all $f, g \in B (X, \Omega)$.
  \begin{enumerate}
    \item Let $f, f_n$ be as in the statement. Since $\rho$ is a *-homomorphism,
    $(\rho(f_n))_n$ is an increasing sequence of positive operators and $\sup_n \| \rho (f_n)\| \leq \sup_{n} \|f\|_{\infty} = \|f\|$.
    By Vigier, there exists $x \in \bh$ such that $\rho(f_n) \xrightarrow{\mathrm{SOT}} x$.
    This $x$ is a natural candidate for $\rho(f)$. Indeed, for $\alpha, \beta \in \mathcal{H}$, we have 
    \begin{align*}
      \langle \rho(f) \alpha, \beta\rangle &= \int_X f\, dE_{\alpha, \beta}\\
      &= \lim_{n \to \infty} \int_X f_n\, dE_{\alpha, \beta}\\
      &= \lim_{n \to \infty} \langle \rho(f_n) \alpha, \beta\rangle,
    \end{align*}
    so $\rho(f_n) \xrightarrow{\mathrm{WOT}} \rho(f)$ and therefore $\rho(f) = x$.
    \item Let $X$ be compact Hausdorff and $a \in \rho(C(X))'$. Take $\alpha, \beta \in \mathcal{H}$.
    Then for all $f \in C(X)$, we have 
    \begin{align*}
      0 &= \langle (a \rho(f) - \rho(f) a)\alpha, \beta\rangle\\
      &= \langle \rho(f) \alpha, a^*\beta\rangle - \langle \rho(f) (a\alpha), \beta\rangle\\
      &= \int_X f\, dE_{\alpha, a^* \beta} - \int_X f\, dE_{a\alpha, \beta},
    \end{align*}
    so by uniqueness from Riesz-Markoff we get $E_{\alpha, a^* \beta} = E_{a\alpha,\beta}$.
    This same calculation backwards tells us that $a$ commutes with all $\rho(g) = \int_X g\, dE$ for $g \in B(X)$, so 
    $\rho(B(X)) \subseteq \rho(C(X))''$ \qedhere
  \end{enumerate}
\end{myproof}

\begin{remark}
  The map $\rho$ is not necessarily isometric.
  However, we can define $E$-null sets 
  $$\{S \in \Omega\ |\ E(S) = 0\},$$
  which gives us an equivalence relation on $B(X, \Omega)$ as follows:
  $f \sim_E g$ if $f(x) = g(s)$ except possibly on some $E$-null set.
  Then we have 
  $$\ker \rho = \{f \in B (X, \Omega)\ |\ f \sim_E 0\}$$ and an essential supremum
  $$\|\rho (f)\| = \| f\|_{\infty} := \inf \{t > 0\ |\ E(\{x \in X\ |\ |f(x)| \geq t\}) = 0\}.$$
  Define $L^\infty (X, E) = \frac{B(X, \Omega)}{\sim_E}$ with norm induced by an essential supremum above.
  Then the map $\rho$ from the above proposition induces an isometric *-isomorphism $\widetilde{\rho}: L^\infty (X, E) \to \bh$.
\end{remark}

Recall that for a commutative $C^*$-algebra $A$ the Gelfand transform 
$$\Gamma: A \to {C} (\sigma(A))$$
is an isometric *-isomorphism.

\begin{theorem}[Spectral theorem]\label{thm:1}
  Let $A \subseteq \bh$ be a commutative $C^*$-algebra and 
  $\mathcal{B}_{\sigma(A)}$ be the Borel $\sigma$-algebra on $\sigma(A)$.
  Then there exists a PVM $E$ for $(\sigma(A), \mathcal{B}_{\sigma(A)}, \mathcal{H})$ such that 
  $$x = \int_{\sigma(A)} \Gamma (x)\, dE$$
  for all $x \in A$.
\end{theorem}

\begin{myproof}
  For all $\alpha, \beta \in \mathcal{H}$ and 
  $$\varphi: C(\sigma(A)) \to \C,\quad f \mapsto \langle \Gamma^{-1} (f) \alpha, \beta\rangle$$
  is a bounded linear functional. Indeed, since $\Gamma$ is an isometry we get
  $$\langle \Gamma^{-1} (f) \alpha, \beta\rangle \leq \| f\|_{\infty} \|  \|\alpha\| \| \beta\|.$$
  By Riesz-Markoff, there exists a unique regular Borel measure $\mu_{\alpha, \beta}$ such that
  $$\langle \Gamma^{-1} (f) \alpha, \beta\rangle = \int_{\sigma(A)} f\, d\mu_{\alpha, \beta}.$$
  We will show that $\mu_{\alpha, \beta} = E_{\alpha, \beta}$ for a PVM $E$.
  For $f, g \in C(\sigma(A))$ we have 
  $$\int_{\sigma(A)} fg\, d\mu_{\alpha, \beta} = \langle \Gamma^{-1}(fg) \alpha, \beta\rangle = \langle \Gamma^{-1} (f) \Gamma(g) \alpha, \beta \rangle = \int_{\sigma(A)} f\, d\mu_{\Gamma^{-1} (g) \alpha, \beta}.$$
  Now we notice that this is equal to 
  $$\langle \Gamma^{-1} (f) \alpha, \Gamma^{-1} (\overline{g}) \beta \rangle = \int_{\sigma(A)} f\, d\mu_{\alpha, \Gamma^{-1} (\overline{g}) \beta}.$$
  From the uniqueness of Riesz-Markoff, we get 
  $$g\, d{\mu_{\alpha, \beta}} = d\mu_{\Gamma^{-1} (g) \alpha, \beta} = d\mu_{\alpha, \Gamma^{-1}(\overline{g})\beta}.$$
  Finally, we have
  \begin{align*}
    \int_{\sigma(A)} f \, d\overline{\mu_{\alpha, \beta}} &= \overline{\int \overline{f}\, d\mu_{\alpha, \beta}}\\
    &= \overline{\langle \Gamma^{-1} (\overline{f}) \alpha, \beta \rangle}\\
    &= \overline{\langle \alpha, \Gamma^{-1} (f) \beta \rangle}\\
    &= \langle \Gamma^{-1} (f) \beta, \alpha\rangle\\
    &= \int_{\sigma(A)} f\, d\mu_{\beta, \alpha}
  \end{align*}
  for all $f \in C(\sigma(A))$, which implies $\overline{\mu_{\alpha, \beta}} = \mu_{\beta, \alpha}$. 
  To each $S \in \mathcal{B}_{\sigma(A)}$ we assign the sesquilinear form 
  $$\mathcal{H} \times \mathcal{H} \to \C,\quad (\alpha, \beta) \mapsto \int_{\sigma(A)} \chi_S \, d\mu_{\alpha, \beta}.$$
  This form is bounded by $\|\alpha\| \|\beta\| = \|\mu_{\alpha, \beta}\|$.
  Thus there exists $E(S) \in \bh$ such that 
  $$\int_{\sigma(A)}\chi_S \, d\mu_{\alpha, \beta} = \langle E(S) \alpha, \beta\rangle.$$
  Now notice that 
  \begin{align*}
    \langle E(S)^* \alpha, \beta \rangle &= \langle \alpha, E(S) \beta\rangle\\
    &= \overline{\langle E(S) \beta, \alpha \rangle}\\
    &= \overline{\int_{\sigma(A)} \chi_S\, d\mu_{\beta, \alpha}}\\
    &= \int_{\sigma(A)} \chi_S\, d\overline{\mu_{\beta, \alpha}}\\
    &= \int_{\sigma(A)} \chi_S d\mu_{\alpha, \beta}\\
    &= \langle E(S) \alpha, \beta\rangle,
  \end{align*}
  so $E(S) = E(S)^*$.
  For any $f \in C(\sigma(A))$, we get 
  \begin{align*}
    \langle \Gamma^{-1} (f) E(S) \alpha, \beta \rangle &= \langle E(S) \alpha, \Gamma^{-1}(\overline{f})\beta\rangle\\
    &= \int \chi_S\, d\mu_{\alpha, \Gamma^{-1} (\overline{f})}\\
    &= \int \chi_S f\, d\mu_{\alpha, \beta}.
  \end{align*}
  By the lemma below, $C(\sigma(A))$ is weak-* dense in $C(\sigma(A))^{**}$.
  Furthermore, the latter set contains $B(\sigma(A))$: indeed, given any $\psi \in C(\sigma(A))^*$,
  we have that $\psi (\cdot) = \int \cdot \, d\mu$ for some measure $\mu$.
  For any $r \in B(\sigma(A))$, we have $r(\psi) = \int_{\sigma(A)} r\, d\mu$.
  Hence, $i: C \to C^{**}$ extends to $\widehat{i}: B \to C^{**}$.
  In particular, for $T \in \mathcal{B}_{\sigma(A)}$, there exists a net $(f_i)_i \subseteq C(\sigma(A))$
  such that $f_i \xrightarrow{\textrm{weak-*}} \chi_T$. As a result,
  $\int_{\sigma(A)} f_i\, d\mu_{\alpha, \beta} \to \int_{\sigma(A)} \chi_T \, d\mu_{\alpha, \beta}$ for all $\alpha, \beta \in \mathcal{H}$,
  so $\Gamma^{-1} (f_i) \xrightarrow{\textrm{WOT}} E(T)$. Now 
  \begin{align*}
    \langle E(T) \cdot E(S) \alpha, \beta\rangle &= \lim_{i} \langle \Gamma^{-1} (f_i) E(S)\alpha, \beta\rangle\\
    &= \lim_i \langle E(S) \alpha, \Gamma^{-1} (\overline{f_i})\beta \rangle\\
    &= \lim_i \int_{\sigma(A)} \chi_S f_i\, d\mu_{\alpha, \beta}\\
    &= \int_{\sigma(A)} \chi_S \cdot \chi_T\, d\mu_{\alpha, \beta}\\
    &= \int_{\sigma(A)} \chi_{S \cap T}\, d\mu_{\alpha, \beta} = \langle E(S \cap T) \alpha, \beta\rangle.
  \end{align*}
  Since $\alpha, \beta$ were arbitrary, we get $E(S) \cdot E(T) = E(S \cap T)$ for all $S, T \in \mathcal{B}_{\sigma(A)}$.
  As a consequence, $E(S)^2 = E(S)$, so $E(S)$ is a projection.
  Obviously, $E(\emptyset) = 0$. Further, 
  $$\langle E(\sigma(A)) \alpha, \beta\rangle = \int_{\sigma(A)} 1\, d\mu_{\alpha, \beta} = \langle \Gamma^{-1} (1) \alpha, \beta\rangle = \langle 1 \alpha, \beta\rangle,$$
  so $E(\sigma(A)) = 1$. Since all $\mu_{\alpha, \beta}$ are $\sigma$-additive, we have 
  \begin{align*}
    \langle E\left(\bigcup_{i = 1} ^\infty S_i\right) \alpha, \beta \rangle &= \mu_{\alpha, \beta} \left(\bigcup_{i = 1} ^\infty S_i\right)\\
    &= \sum_{i = 1} ^\infty \mu_{\alpha, \beta} (S_i)\\
    &= \langle \sum_{i = 1}^\infty E(S_i)\alpha, \beta \rangle
  \end{align*}
  for each sequence $(S_i)_i \subseteq \mathcal{B}_{\sigma(A)}$ of pairwise disjoint sets, so $E\left(\bigcup_{i = 1} ^\infty S_i\right) = \sum_{i = 1}^\infty E(S_i)$.
  We have proved that $E$ is a PVM for $(\sigma(A), \mathcal{B}_{\sigma(A)}, \mathcal{H})$. For any $\alpha, \beta \in \mathcal{H}$, we get 
  $$E_{\alpha, \beta} (S) = \langle E(S)\alpha, \beta\rangle = \int \chi_S \, d\mu_{\alpha, \beta} = \mu_{\alpha, \beta} (S),$$
  so $E_{\alpha, \beta} = \mu_{\alpha, \beta}$ and therefore $\int f\, dE_{\alpha, \beta} = \langle \Gamma^{-1} \alpha, \beta\rangle$.
  But this proves that $x = \int_{\sigma(A)} \Gamma(x)\, dE$ for all $x \in A$.
  Uniqueness: suppose that $E'$ is another such PVM. For $\alpha, \beta \in \mathcal{H}$ and $f \in C(\sigma(A))$, we have 
  $$\int_{\sigma(A)} f\, dE_{\alpha, \beta} = \langle \Gamma^{-1} (f)\alpha, \beta\rangle = \int_{\sigma(A)} f\, dE_{\alpha, \beta}',$$
  which proves that $E_{\alpha, \beta} = E_{\alpha, \beta} '$ as elements in $C(\sigma(A))^*.$
  Thus $$\langle E(S)\alpha, \beta\rangle = E_{\alpha, \beta} (S) = E_{\alpha, \beta} '(S) = \langle E'(S) \alpha, \beta \rangle.$$
  Since $\alpha, \beta$ were arbitrary, $E(S) = E'(S)$. But since $S$ was also arbitrary, $E = E'$.
\end{myproof}

\begin{lemma}[Goldstine's theorem]
  Let $X$ be a Banach space. Then the image of 
  $$\iota: X \to X^{**},\quad x \mapsto (f \mapsto f(x))$$
  is dense in weak-* topology.
\end{lemma}

\begin{myproof}
  Let $\beta \in X^{**}$ and $f_1, \dots, f_r \in X^*$ (WLOG linearly independent).
  Then 
  $$U = \{\alpha \in X^{**}\ |\ |(\alpha - \beta) (f_j)| < \varepsilon,\ j = 1, \dots, r\}.$$
  is a basic open set in weak-* topology in $X^{**}$.
  WLOG assume $X$ is infinitely-dimensional. Consider the linear map 
  $$\Phi: X \to \C^r,\quad x \mapsto (f_1 (x),\dots, f_r (x)).$$
  This map is surjective.
  In particular, there exists $x_{0} \in X$ such that 
  $$\Phi(x_j) = (f_1 (x_0), \dots, f_r (x_0)) = (\rho_0 (f_1), \dots, \rho_0 (f_r)),$$
  hence $\iota (x_0) \in U \cap \iota (X)$.
\end{myproof}

\subsection{Borel functional calculus}

Let $x \in \bh$ be normal ($x^* x = x x^*$) and $A = C^* (x) \subseteq \mathcal{B}(\mathcal{H})$.
Then $\sigma(A) \cong \sigma(x)$. By the spectral theorem, there exists a PVM $E$ for $(\sigma(x), \mathcal{B}_{\sigma(x)}, \mathcal{H})$ 
and $$B (\sigma(x)) \to \bh,\quad f \mapsto \int_{\sigma(x)} f\, dE$$
is a *-homomorphism and a contraction (proposition above).
Furthermore, $f \in C(\sigma(x))$ maps into $\int_{\sigma(x)} f\, dE = \Gamma^{-1} (f)$,
so the above map, when restricted to $C(\sigma(x))$, coincides with $\Gamma^{-1}$.
Furthermore,
If $f = \id \in B(\sigma(x))$, meaning $f(z) = z$ for $z \in \sigma(x)$, then 
$$\int_{\sigma(x)} \id \, dE = \Gamma^{-1} (\id) = x.$$
For $f \in B (\sigma(x))$, define 
$$f(x) := \int_{\sigma(x)} f\, dE \in A''  = W^* (x),$$
which is a vNa generated by $x$.

\begin{definition}
  Let $x \in \bh$ be normal. The mapping 
  $$B (\sigma(x)) \to W^* (x),\quad f \mapsto f(x)$$
  is the Borel functional calculus.
\end{definition}

\begin{theorem}[Spectral mapping theorem]
  Let $A \subseteq \bh$ be a vNa and let $x \in A$ be normal.
  Then the Borel functional calculus has the following properties:
  \begin{enumerate}
    \item The map $$B (\sigma(x)) \to A,\quad f \mapsto f(x)$$
    is a bounded *-homomorphism.
    \item If $f \in C(\sigma(x))$, then this $f(x)$ is the same $f(x)$ as in continuous functional calculus.
    \item For $f \in B (\sigma(x))$, we have $\sigma(f(x)) \subseteq f(\sigma(x))$.
  \end{enumerate}
\end{theorem}

\begin{myproof}
  \begin{enumerate}
    \item This is the above proposition.
    \item Obvious.
    \item For $\lambda \notin f(\sigma (x))$, then $f - \lambda \in \mathcal{B} (\sigma(x))$
    is invertible in $\mathcal{B}(\sigma(x))$, so there exists $g \in \mathcal{B} (\sigma^{-1})$ such that $(f - \lambda) g = \id$.
    By Borel functional calculus, $(f(x) - \lambda I) \cdot g(x) = I$, so $\lambda \notin \sigma(f(x))$. \qedhere
  \end{enumerate}
\end{myproof}

\begin{corollary}
  Every vNa is the norm-closure of the linear span of the projections.
\end{corollary}

\begin{myproof}
  Let $M \subseteq \bh$ be a vNa and $x \in M$. By using $\real x, \imag x \in M_{\sa}$,
  we may WLOG assume $x \in A_{\sa}$. Hence $x$ is normal and for all $f \in B(\sigma(x))$ we have $f(x) \in M$.
  For $S \in \mathcal{B}_{\sigma(x)}$, $\chi_S (x) \in M$ is a projection. Now we can uniformly approximate $\id$ 
  on $\sigma(x)$ by using simple functions. By BFC, $x$ is uniformly approximated by linear combinations of projections.
\end{myproof}

\begin{remark}
  There exist $C^*$-algebras without nontrivial projections.
  For example, for a compact Hausdorff connected $X$, the algebra $C(X)$ only has trivial projections $0$ and $1$.
  There exist noncommutative examples, too.            
\end{remark}

\subsection{Commutative von Neumann algebras}

\begin{definition}
  Let $A \subseteq \mathcal{B}(\mathcal{H})$ be a subalgebra. Vector $\alpha \in \mathcal{H}$ is:
  \begin{enumerate}
    \item cyclic if $A$ if $A \alpha$ is dense in $\mathcal{H}$.
    \item separating for $A$ if $x \alpha = 0$ for $x \in A$ implies $x = 0$.
  \end{enumerate}
\end{definition}

\begin{proposition}
  Let $A \subseteq \bh$ be a subalgebra.
  \begin{enumerate}
    \item If $\alpha \in \mathcal{H}$ is cyclic for $A$, then it is separating for $A'$.
    \item Assume $A$ is a *-subalgebra. Then if $\alpha$ is separating for $A'$, it is cyclic for $A$.
    \item Suppose $W \subseteq \bh$ is a vNa. Then $\alpha$ is cyclic for $M$ iff it is separating for $M'$
    and separating for $M$ iff it is cyclic for $M'$.
  \end{enumerate}
\end{proposition}

\begin{myproof}
  \begin{enumerate}
    \item Let $\alpha$ be cyclic for $A$. Let $y \in A'$ satisfy $y \alpha = 0$.
    Pick any $\beta \in \mathcal{H}$. there exists a sequence $(x_n)_n \subseteq A$ such that $\|x_n \alpha - \beta\| \to 0$.
    Hence $$y \beta = \lim_{n \to \infty} yx_n \alpha = \lim_{n \to \infty} x_n (y\alpha) = 0$$
    and $\alpha$ is separating for $A'$.
    \item Define $\mathcal{K} := (A \alpha)^{\perp} \leq \mathcal{H}$.
    Let $p: \mathcal{H} \to \mathcal{K}$ be the orthogonal projection.
    For $x_1, x_2 \in A$ and $\beta \in \mathcal{K}$ we have 
    $$\langle x_1 \beta, x_2 \alpha\rangle = \langle \beta, x_1 ^* x_2 \alpha \rangle = 0,$$
    so $x_1 \beta \in \mathcal{K}$ and $\mathcal{K}$ is an invariant subspace for $A$.
    But since $A$ is *-closed, $\mathcal{K}$ is reducing and by lemma \ref{lem:1} $p \in A'$.
    Of course, $\alpha \in A \alpha$ and $p\alpha = 0$. Now we use the fact that $\alpha$ is 
    separating for $A'$ and therefore $p = 0$. This implies $\mathcal{K} = (0)$.
    \item This follows immediately from $M = M''$ and the previous two points.
  \end{enumerate}
\end{myproof}

\begin{example}
  Recall $VN (\Gamma) := \lambda (\C [\Gamma])'' \subseteq \mathcal{B} (\ell^2 (\Gamma))$.
  Similarly, we can use the right regular map 
  $$\rho: \Gamma \to \mathcal{B} (\ell^2 (\Gamma)),\quad g \mapsto (\rho_g: \delta_k \mapsto \delta_{kg^{-1}})$$
  to define $VN_{\mathrm{right}} (\Gamma) = \rho(\Gamma)'' \subseteq \mathcal{B} (\ell^2 (\Gamma))$.
  Notice that $\delta_e \in \ell^2 (\Gamma)$ is cyclic for $\lambda (\C [\Gamma])$ as well as $\rho(\C[\Gamma])$.
  This means that it is cyclic for both $VN(\Gamma)$ and $VN_{\mathrm{right}} (\Gamma)$.
  It's easy to see that $VN(\Gamma)' = VN_{\mathrm{right}} (\Gamma)$, so $\delta_e$
  is separating for $VN(\Gamma)$ and $VN_{\mathrm{right}} (\Gamma)$.
\end{example}

\begin{corollary}
  If $A \subseteq \bh$ is commutative, then each cyclic vector for $A$ is also separating for $A$.
\end{corollary}

\begin{myproof}
  If $\alpha \in \mathcal{H}$ is cyclic for $A$, then it is separating for $A'$, 
  but since $A \subseteq A'$ it is also separating for $A$.
\end{myproof}

\begin{theorem}[Classification of commutative vNa's]
  Let $A \subseteq \mathcal{B}(\mathcal{H})$ be a commutative vNa with a cyclic vector $\alpha \in \mathcal{H}$.
  Suppose $A_0 \subseteq A$ is a $C^*$-algebra that is SOT-dense. Then there exists a finite regular positive Borel measure 
  $\mu$ on $\sigma(A_0)$ and an isomorphism $$\widetilde{\Gamma}: A \to L^\infty (\sigma (A_0), \mu) \subseteq \mathcal{B} (L^2 (\sigma(A_0), \mu))$$
  that extends the Gelfand transform $\Gamma: A_0 \to C(\sigma(A_0))$.
  Furthermore, $\widetilde{\Gamma}$ is spacial, that is induced by conjugation with a unitary 
  $U: \mathcal{H} \to L^2 (\sigma(A_0), \mu)$.
\end{theorem}

\begin{myproof}
  Since $A_0$ is a commutative $C^*$-algebra, the Gelfand transform $\Gamma: A_0 \to C(\sigma(A_0))$
  is an isometric *-isomorphism. Define $\varphi_0: A \to \C$ by $x \mapsto \langle x \alpha_0, \alpha_0\rangle$.
  Then $\varphi_0 \Gamma^{-1} : C(\sigma(A_0)) \to \C$ is a bounded linear functional, so by Riesz-Markoff 
  there exists a regular Borel measure $\mu$ on $\sigma(A_0)$ such that 
  $$\varphi_0 \Gamma^{-1} (f) = \int_{\sigma(A_0)} f\, d\mu.$$
  For every positive function $f \in C(\sigma(A_0))$ we have 
  \begin{align*}
    \int_{\sigma(A_0)} f\, d\mu &= \int \sqrt{f}^2\, d\mu = \varphi_0 \Gamma^{-1} (\sqrt{f}^2) = \langle \Gamma^{-1} (\sqrt{f}^2) \alpha_0, \alpha_0 \rangle\\
    &= \langle \Gamma^{-1} (\sqrt{f}) ^2 \alpha_0, \alpha_0\rangle = \langle \Gamma^{-1} (\sqrt{f}) \alpha_0, \Gamma^{-1} (\sqrt{f}) \alpha_0\rangle\\
    &= \| \Gamma^{-1} (\sqrt{f}) \alpha_0\|^2 \geq 0
  \end{align*}
  and $\mu$ is a positive measure. Furthermore, $\mu$ is finite, since 
  $$\mu(\sigma(A_0)) = \varphi(1) = \|\alpha_0\|^2 < \infty.$$
  Now we prove that $\mathrm{supp}\, \mu = \sigma(A_0)$.
  If $\mathrm{supp}\, \mu \subsetneqq \sigma(A_0)$, then there exists $\emptyset \neq S^{\mathrm{open}} \subseteq \sigma(A_0)$
  with $\mu (S) = 0$. Consider a nonnegative $f \in C(\sigma(A_0)) \setminus (0)$ with $f\big|_{\stcomp{S}} = 0$.
  Then $$\| \Gamma^{-1} (\sqrt{f}) \alpha_0 \|^2 = \int_{\sigma(A_0)} f\, d\mu = \int_S f\, d\mu = 0.$$
  We get $\Gamma^{-1} (\sqrt{f}) \alpha_0 = 0$, which by cyclicity of $\alpha_0$ implies $\Gamma^{-1} (\sqrt{f}) = 0$,
  $\sqrt{f} = 0$ and $f = 0$, a contradiction. Define 
  $$U_0 : A_0 \alpha_0 \to C(\sigma(A_0)) \subseteq L^2 (\sigma(A_0), \mu),\quad x \alpha_0 \mapsto \Gamma(x).$$
  Since $\alpha_0$ is separating for $A_0$, this $U_0$ is a well-defined linear map.
  For $x, y \in A_0$, we have 
  \begin{align*}
    \langle U_0 (x \alpha_0), U_0 (y \alpha_0) \rangle &= \langle \Gamma(x), \Gamma(y)\rangle_2 \\
    &= \int_{\sigma (A_0)}  \overline{\Gamma(y)} \Gamma(x)\, d\mu\\
    &= \int_{\sigma (A_0)} \Gamma(y^* x)\, d\mu\\
    &= \varphi(y^* x) = \langle y^* x \alpha_0, \alpha_0 \rangle = \langle x \alpha_0, y \alpha_0\rangle
  \end{align*}
  and so $U_0$ is an isometry! Since $\alpha_0$ is cyclic for $A$ and $A_0$
  is SOT-dense in $A$, $\alpha_0$ is cyclic for $A_0$.
  So $A_0 \alpha_0$ is dense in $\mathcal{H}$ and the image of $U_0$ is the entire $C(\sigma(A_0))$.
  By continuity, $U_0$ extends to a surjective isometry 
  $$U : \mathcal{H} \to L^2 (\sigma(A_0), \mu) = \overline{C(\sigma(A_0), \mu)}^{\langle \cdot, \cdot \rangle_2},$$
  where $U$ is unitary. Next, define 
  $$\widetilde{\Gamma} : A \to \mathcal{B} (L^2 (\sigma(A_0), \mu)),\quad x \mapsto UxU^*.$$
  We claim that $\widetilde{\Gamma}$ is an isometric *-homomorphism. Since $U$ is unitary, the isometric part is obvious and the homomorphism soon follows.
  Now we claim that $\widetilde{\Gamma} (A) = M(L^\infty (\sigma(A_0), \mu))$.
  For $x \in A_0$ and $g \in C(\sigma(A_0))$, we have 
  \begin{align*}
    \widetilde{\Gamma} (x) g &= UxU^* g = U x U^{-1} (\Gamma (\Gamma^{-1} (g)))\\
    &= U x (\Gamma^{-1} (g)\alpha_0)= \Gamma (x \Gamma^{-1} (g))\\ 
    &= \Gamma(x) g = M_{\Gamma(x)} g
  \end{align*}
  and since $C(\sigma (A_0))$ is dense in $L^2 (\sigma(A_0), \mu)$, we get $\widetilde{\Gamma}(x) = M_{\Gamma(x)}$.
  It follows that 
  $$\widetilde{\Gamma} (A_0) = M(C(\sigma (A_0))) \subseteq M(L^\infty (\sigma(A_0), \mu)).$$
  Then we use the fact that $\widetilde{\Gamma}$ is SOT-continuous (by definition) and $M(L^\infty)$ is a vNa (example \ref{ex:1}) to get
  $$\widetilde{\Gamma} (A) = \widetilde{\Gamma} (\overline{A_0} ^{\mathrm{SOT}}) \subseteq \overline{\widetilde{\Gamma} (A_0)}^{\mathrm{SOT}} \subseteq \overline{M(L^\infty (\sigma(A_0), \mu))}^{\mathrm{SOT}} = M(L^\infty (\sigma(A_0), \mu)).$$
  The reverse inclusion is done by nets. Suppose $(\widetilde{\Gamma} (x_i))_i \subseteq \widetilde{\Gamma} (A_0)$
  WOT-converges to $T \in B(L^2 (\sigma(A_0), \mu))$. Then for all $\beta \mu \in \mathcal{H}$ we have 
  \begin{align*}
    \langle TU \beta, U\mu\rangle &= \lim_{i} \langle \widetilde{\Gamma} (x_i) U\beta, U\mu\rangle\\
    &= \lim_i \langle Ux_i U^* U \beta, U\mu \rangle\\
    &= \lim_i \langle x_i \beta, \mu \rangle
  \end{align*} 
  and $(x_i)_i \xrightarrow{\mathrm{WOT}} U^* T U \in \bh$.
  Since $\overline{A_0} ^{\mathrm{WOT}} = A$, we get $x = U^* T U \in A$ and $\widetilde{\Gamma}(x) = T$, so $\overline{\widetilde{\Gamma} (A_0)}^{\mathrm{WOT}} \subseteq \widetilde{\Gamma} (A)$.
  Finally, we ask what is $\overline{M(C(\sigma(A_0)))}^{\mathrm{WOT}}$?
  WOT on that set is generated by seminorms $$|\langle M_g \alpha, \beta\rangle| = \left| \int_{\sigma(A_0)} g \alpha \beta\, d\mu \right|,$$
  where $g \in C(\sigma(A_0))$ and $\alpha, \beta \in L^2 (\sigma(A_0), \mu)$.
  Accordingly, weak-* topology on $L^\infty (\sigma(A_0), \mu)$ is generated by 
  seminorms 
  $$\left| \int_{\sigma(A_0)} g \gamma\, d\mu \right|,$$
  where $\mu \in L^1 (\sigma(A_0), \mu)$ (this is because for a $\sigma$-finite $X$, $(L^1(X))^* = L^\infty (X)$).
  By H√∂lder, $L^1$ function is a product of two $L^2$ functions,
  so these two topologies coincide.
  By Goldstine's theorem, $C(\sigma(A_0))$ are weak-* dense in $L^\infty (\sigma(A_0), \mu)$.
  Then we have 
  $$M(L^\infty (\sigma(A_0), \mu)) = \overline{M(C(\sigma(A_0)))}^{\mathrm{WOT}} = \overline{\widetilde{\Gamma} (A_0)}^{\mathrm{WOT}} \subseteq \widetilde{\Gamma} (A)$$
  and finally $\widetilde{\Gamma} (A) = M(L^\infty (\sigma(A_0), \mu))$.
\end{myproof}

\begin{remark}
  Applying this theorem to $A_0 = A$ we get 
  $$ M(L^{\infty} (\sigma(A), \mu)) = \widetilde{\Gamma} (A) = M(C(\sigma(A))).$$
\end{remark}

The following statement from the above proof is important in its own right.

\begin{lemma}
  $C(\sigma(A_0))$ are weak-* dense in $L^{\infty} (\sigma(A_0), \mu)$.
\end{lemma}

\begin{myproof}
  For any bounded measurable function $f \in B(\sigma(A_0))$, there exists a net $(f_i)_i \subseteq C(\sigma(A_0))$
  such that $f_i \xrightarrow{\mathrm{weak-*}} f$ by Goldstine (see the proof for theorem \ref{thm:1}).
\end{myproof}

In the proof, we used the following theorem.

\begin{theorem}
  Suppose $1 \leq p < \infty$ and $\mu$ is a $\sigma$-finite positive measure on $X$,
  and $\Phi$ is a bounded linear functional on $L^p(X, \mu)$.
  Then there is a unique $g \in L^q (X, \mu)$, where $\frac{1}{p} + \frac{1}{q} = 1$, such that 
  $$\Phi (f) = \int_X fg\, d\mu.$$ Moreover, $\| \Phi\| = \|g\|_{q}$.
\end{theorem}

The theorem tells us that under these conditions, $L^q (X, \mu)$ is isometrically isomorphic to the dual space of $L^{q} (X, \mu)$.
In particular, we used the fact that $(L^1 (X, \mu))^* = L^\infty (X, \mu)$. This is theorem 6.16 in W.Rudin's \emph{Real and complex analysis}.


How crucial is the cyclicity assumption?
Let $A \subseteq \bh$  be a commutative vNa. Pick $0 \neq \alpha \in \mathcal{H}$.
Define $\mathcal{K}:= \overline{A\alpha}$ and let $p: \mathcal{H} \to \mathcal{K}$ be an orthogonal 
projection, so by reducibility of $\mathcal{K}$ we get $p \in A'$. Therefore $pAp = Ap \subseteq \mathcal{B}(\mathcal{H})$
is a commutative vNa with a cyclic vector $\alpha \in \mathcal{K}$.
Then, again by theorem, $Ap \cong L^\infty (X, \mu)$ for some $(X, \mu)$.
By Zorn's lemma, $A \cong L^\infty (Y, \nu)$ for some disjoint union of measure spaces $(Y, \nu)$.


\begin{proposition}
  Let $\mathcal{H}$ be a separable Hilbert space and $A \subseteq \bh$
  a commutative vNa. Then there exists a separating vector for $A$.
\end{proposition}

\begin{myproof}
  By Zorn, there exists a maximal set of unit vectors $(\alpha_k)_k$ such that $A \alpha_k \perp A \alpha_l$
  for $k \neq l$. By maximality, $\sum_k A \alpha_k$ is dense in $\mathcal{H}$.
  Define $\alpha = \sum_{n = 1} ^\infty \frac{1}{2^n} \alpha_n$. We claim that $\alpha$ is separating for $A$.
  Indeed, let $x \in A$ such that $x \alpha = 0$. Then $\sum_{n = 1} ^\infty \frac{1}{2^n} x \alpha_n = 0$.
  By orthogonality, $x\alpha_n = 0$ for all indices $n$. For all $y \in A$, we get 
  $xy \alpha_n = y x \alpha_n = 0$, so $x\big|_{A\alpha_n} = 0$ for all $n$. But since $\sum_n A \alpha_n$ is dense in $A$, we get $x = 0$.
\end{myproof}

\begin{corollary}
  Let $\mathcal{H}$ be a separable Hilbert space and $A \subseteq \bh$
  is a maximal commutative vNa. Then there exists a cyclic vector for $A$.
\end{corollary}

\begin{myproof}
  By the proposition, there exists a separating vector $\alpha$ for $A$, which is then cyclic for 
  $A'$. But since $A$ is maximal, we get $A = A'$.
\end{myproof}

\begin{theorem}
  Let $\mathcal{H}$ be a separable Hilbert space and $A \subseteq \bh$ a commutative 
  vNa. Then there exists a compact Hausdorff space $X$ and a finite regular Borel measure $\mu$ on $X$ such that $A \cong L^\infty (X, \mu)$.
\end{theorem}

\begin{myproof}
  By proposition, there exists a separating vector $\alpha \in \mathcal{H}$ for $A$. 
  Form $\mathcal{K} := \overline{A \alpha}$. Then the algebra $\{x\big|_{\mathcal{K}} \ |\ x \in A\} \subseteq \mathcal{B}(\mathcal{K})$
  is *-isomorphic to $A$, has cyclic vector $\alpha$ and the above theorem applies.
\end{myproof}

\begin{example}
  Let $\Gamma = \quot{\Z}{n\Z}.$ Then the spectrum is $\sigma(VN(\Gamma)) = \{e^{\frac{2k \pi i}{n}}\ |\ 0 \leq k < n\}$
  and $\mu(e^{\frac{2k\pi i}{n}}) = \frac{1}{n}$. Then $$VN(\Gamma) = L^\infty (\sigma(VN(\Gamma)), \mu) \cong \C^n$$
  as an algebra. The generator for $VN(\Gamma)$ is the matrix 
  $$\begin{pmatrix}
    0 & 1 &  & \\
     & \ddots & \ddots &\\
     & & \ddots & 1\\
    1 & &  &0
  \end{pmatrix}.$$
\end{example}

\begin{example}
  Let $\Gamma = \Z$. Then $\mathbb{T}$ is the Pontryagin dual of $\Gamma$,
  so $C^* (\Gamma) = C(\mathbb{T})$ and $VN(\Gamma) = L^\infty (\mathbb{T}, m)$, where $m$ is the normalized Lebesgue measure.
\end{example}

\end{document}